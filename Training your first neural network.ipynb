{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a neural network for Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0\n",
      "Training...\n",
      " Accuracy:33.333333 loss:1.183893\n",
      "Testing...\n",
      "Accuracy:33.333333 loss:1.159990\n",
      "Epoch:1\n",
      "Training...\n",
      " Accuracy:33.333333 loss:1.126927\n",
      "Testing...\n",
      "Accuracy:33.333333 loss:1.099834\n",
      "Epoch:2\n",
      "Training...\n",
      " Accuracy:33.333333 loss:1.069405\n",
      "Testing...\n",
      "Accuracy:33.333333 loss:1.064283\n",
      "Epoch:3\n",
      "Training...\n",
      " Accuracy:55.000000 loss:1.049390\n",
      "Testing...\n",
      "Accuracy:66.666667 loss:1.041232\n",
      "Epoch:4\n",
      "Training...\n",
      " Accuracy:66.666667 loss:1.020936\n",
      "Testing...\n",
      "Accuracy:66.666667 loss:1.023136\n",
      "Epoch:5\n",
      "Training...\n",
      " Accuracy:65.833333 loss:1.072715\n",
      "Testing...\n",
      "Accuracy:63.333333 loss:1.006207\n",
      "Epoch:6\n",
      "Training...\n",
      " Accuracy:65.833333 loss:0.977484\n",
      "Testing...\n",
      "Accuracy:66.666667 loss:0.984448\n",
      "Epoch:7\n",
      "Training...\n",
      " Accuracy:66.666667 loss:0.939556\n",
      "Testing...\n",
      "Accuracy:66.666667 loss:0.962949\n",
      "Epoch:8\n",
      "Training...\n",
      " Accuracy:66.666667 loss:0.949007\n",
      "Testing...\n",
      "Accuracy:66.666667 loss:0.942044\n",
      "Epoch:9\n",
      "Training...\n",
      " Accuracy:66.666667 loss:0.902802\n",
      "Testing...\n",
      "Accuracy:66.666667 loss:0.921105\n",
      "Epoch:10\n",
      "Training...\n",
      " Accuracy:66.666667 loss:0.882713\n",
      "Testing...\n",
      "Accuracy:66.666667 loss:0.899358\n",
      "Epoch:11\n",
      "Training...\n",
      " Accuracy:66.666667 loss:0.874562\n",
      "Testing...\n",
      "Accuracy:66.666667 loss:0.876592\n",
      "Epoch:12\n",
      "Training...\n",
      " Accuracy:66.666667 loss:0.850123\n",
      "Testing...\n",
      "Accuracy:66.666667 loss:0.853496\n",
      "Epoch:13\n",
      "Training...\n",
      " Accuracy:66.666667 loss:0.849282\n",
      "Testing...\n",
      "Accuracy:66.666667 loss:0.829877\n",
      "Epoch:14\n",
      "Training...\n",
      " Accuracy:66.666667 loss:0.771261\n",
      "Testing...\n",
      "Accuracy:66.666667 loss:0.806573\n",
      "Epoch:15\n",
      "Training...\n",
      " Accuracy:66.666667 loss:0.781302\n",
      "Testing...\n",
      "Accuracy:66.666667 loss:0.782822\n",
      "Epoch:16\n",
      "Training...\n",
      " Accuracy:66.666667 loss:0.737666\n",
      "Testing...\n",
      "Accuracy:66.666667 loss:0.759432\n",
      "Epoch:17\n",
      "Training...\n",
      " Accuracy:66.666667 loss:0.738476\n",
      "Testing...\n",
      "Accuracy:66.666667 loss:0.736250\n",
      "Epoch:18\n",
      "Training...\n",
      " Accuracy:66.666667 loss:0.645701\n",
      "Testing...\n",
      "Accuracy:66.666667 loss:0.713882\n",
      "Epoch:19\n",
      "Training...\n",
      " Accuracy:66.666667 loss:0.718643\n",
      "Testing...\n",
      "Accuracy:70.000000 loss:0.692073\n",
      "Epoch:20\n",
      "Training...\n",
      " Accuracy:67.500000 loss:0.672878\n",
      "Testing...\n",
      "Accuracy:70.000000 loss:0.671350\n",
      "Epoch:21\n",
      "Training...\n",
      " Accuracy:67.500000 loss:0.729788\n",
      "Testing...\n",
      "Accuracy:73.333333 loss:0.651491\n",
      "Epoch:22\n",
      "Training...\n",
      " Accuracy:70.833333 loss:0.614706\n",
      "Testing...\n",
      "Accuracy:73.333333 loss:0.632312\n",
      "Epoch:23\n",
      "Training...\n",
      " Accuracy:74.166667 loss:0.614480\n",
      "Testing...\n",
      "Accuracy:76.666667 loss:0.613043\n",
      "Epoch:24\n",
      "Training...\n",
      " Accuracy:82.500000 loss:0.625113\n",
      "Testing...\n",
      "Accuracy:86.666667 loss:0.595311\n",
      "Epoch:25\n",
      "Training...\n",
      " Accuracy:82.500000 loss:0.587408\n",
      "Testing...\n",
      "Accuracy:86.666667 loss:0.579310\n",
      "Epoch:26\n",
      "Training...\n",
      " Accuracy:82.500000 loss:0.563739\n",
      "Testing...\n",
      "Accuracy:80.000000 loss:0.564586\n",
      "Epoch:27\n",
      "Training...\n",
      " Accuracy:79.166667 loss:0.559766\n",
      "Testing...\n",
      "Accuracy:80.000000 loss:0.550620\n",
      "Epoch:28\n",
      "Training...\n",
      " Accuracy:77.500000 loss:0.516986\n",
      "Testing...\n",
      "Accuracy:76.666667 loss:0.537842\n",
      "Epoch:29\n",
      "Training...\n",
      " Accuracy:78.333333 loss:0.440590\n",
      "Testing...\n",
      "Accuracy:83.333333 loss:0.526294\n",
      "Epoch:30\n",
      "Training...\n",
      " Accuracy:78.333333 loss:0.484424\n",
      "Testing...\n",
      "Accuracy:86.666667 loss:0.515529\n",
      "Epoch:31\n",
      "Training...\n",
      " Accuracy:81.666667 loss:0.554113\n",
      "Testing...\n",
      "Accuracy:90.000000 loss:0.505519\n",
      "Epoch:32\n",
      "Training...\n",
      " Accuracy:85.000000 loss:0.497618\n",
      "Testing...\n",
      "Accuracy:90.000000 loss:0.496190\n",
      "Epoch:33\n",
      "Training...\n",
      " Accuracy:85.833333 loss:0.506658\n",
      "Testing...\n",
      "Accuracy:90.000000 loss:0.487085\n",
      "Epoch:34\n",
      "Training...\n",
      " Accuracy:90.000000 loss:0.463138\n",
      "Testing...\n",
      "Accuracy:93.333333 loss:0.478698\n",
      "Epoch:35\n",
      "Training...\n",
      " Accuracy:89.166667 loss:0.527305\n",
      "Testing...\n",
      "Accuracy:93.333333 loss:0.470250\n",
      "Epoch:36\n",
      "Training...\n",
      " Accuracy:90.000000 loss:0.423482\n",
      "Testing...\n",
      "Accuracy:93.333333 loss:0.462193\n",
      "Epoch:37\n",
      "Training...\n",
      " Accuracy:90.833333 loss:0.530843\n",
      "Testing...\n",
      "Accuracy:96.666667 loss:0.454939\n",
      "Epoch:38\n",
      "Training...\n",
      " Accuracy:91.666667 loss:0.424030\n",
      "Testing...\n",
      "Accuracy:96.666667 loss:0.447931\n",
      "Epoch:39\n",
      "Training...\n",
      " Accuracy:91.666667 loss:0.355741\n",
      "Testing...\n",
      "Accuracy:96.666667 loss:0.441367\n",
      "Epoch:40\n",
      "Training...\n",
      " Accuracy:91.666667 loss:0.364539\n",
      "Testing...\n",
      "Accuracy:96.666667 loss:0.434078\n",
      "Epoch:41\n",
      "Training...\n",
      " Accuracy:91.666667 loss:0.360475\n",
      "Testing...\n",
      "Accuracy:96.666667 loss:0.427955\n",
      "Epoch:42\n",
      "Training...\n",
      " Accuracy:91.666667 loss:0.357069\n",
      "Testing...\n",
      "Accuracy:96.666667 loss:0.421334\n",
      "Epoch:43\n",
      "Training...\n",
      " Accuracy:90.833333 loss:0.372383\n",
      "Testing...\n",
      "Accuracy:96.666667 loss:0.415807\n",
      "Epoch:44\n",
      "Training...\n",
      " Accuracy:91.666667 loss:0.419437\n",
      "Testing...\n",
      "Accuracy:96.666667 loss:0.409970\n",
      "Epoch:45\n",
      "Training...\n",
      " Accuracy:93.333333 loss:0.425737\n",
      "Testing...\n",
      "Accuracy:96.666667 loss:0.404986\n",
      "Epoch:46\n",
      "Training...\n",
      " Accuracy:92.500000 loss:0.344922\n",
      "Testing...\n",
      "Accuracy:96.666667 loss:0.398972\n",
      "Epoch:47\n",
      "Training...\n",
      " Accuracy:95.000000 loss:0.377502\n",
      "Testing...\n",
      "Accuracy:96.666667 loss:0.394190\n",
      "Epoch:48\n",
      "Training...\n",
      " Accuracy:94.166667 loss:0.341298\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.388840\n",
      "Epoch:49\n",
      "Training...\n",
      " Accuracy:95.000000 loss:0.429063\n",
      "Testing...\n",
      "Accuracy:96.666667 loss:0.383124\n",
      "Epoch:50\n",
      "Training...\n",
      " Accuracy:94.166667 loss:0.364853\n",
      "Testing...\n",
      "Accuracy:96.666667 loss:0.377507\n",
      "Epoch:51\n",
      "Training...\n",
      " Accuracy:94.166667 loss:0.400936\n",
      "Testing...\n",
      "Accuracy:96.666667 loss:0.372673\n",
      "Epoch:52\n",
      "Training...\n",
      " Accuracy:95.833333 loss:0.332064\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.368482\n",
      "Epoch:53\n",
      "Training...\n",
      " Accuracy:95.000000 loss:0.391471\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.362931\n",
      "Epoch:54\n",
      "Training...\n",
      " Accuracy:95.833333 loss:0.328435\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.358541\n",
      "Epoch:55\n",
      "Training...\n",
      " Accuracy:95.833333 loss:0.337400\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.353475\n",
      "Epoch:56\n",
      "Training...\n",
      " Accuracy:94.166667 loss:0.282194\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.348367\n",
      "Epoch:57\n",
      "Training...\n",
      " Accuracy:95.833333 loss:0.346750\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.344480\n",
      "Epoch:58\n",
      "Training...\n",
      " Accuracy:95.833333 loss:0.441127\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.339942\n",
      "Epoch:59\n",
      "Training...\n",
      " Accuracy:95.833333 loss:0.373592\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.335039\n",
      "Epoch:60\n",
      "Training...\n",
      " Accuracy:95.833333 loss:0.353305\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.329932\n",
      "Epoch:61\n",
      "Training...\n",
      " Accuracy:95.000000 loss:0.377852\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.325548\n",
      "Epoch:62\n",
      "Training...\n",
      " Accuracy:95.833333 loss:0.339675\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.322112\n",
      "Epoch:63\n",
      "Training...\n",
      " Accuracy:95.833333 loss:0.376771\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.318676\n",
      "Epoch:64\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.321569\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.313941\n",
      "Epoch:65\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.279414\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.310285\n",
      "Epoch:66\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.291300\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.304848\n",
      "Epoch:67\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.267841\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.300559\n",
      "Epoch:68\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.296639\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.296304\n",
      "Epoch:69\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.302386\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.291891\n",
      "Epoch:70\n",
      "Training...\n",
      " Accuracy:95.833333 loss:0.253195\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.287999\n",
      "Epoch:71\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.299641\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.283902\n",
      "Epoch:72\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.298331\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.281135\n",
      "Epoch:73\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.278770\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.276769\n",
      "Epoch:74\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.280687\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.273839\n",
      "Epoch:75\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.238659\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.269106\n",
      "Epoch:76\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.275822\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.264706\n",
      "Epoch:77\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.283992\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.261955\n",
      "Epoch:78\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.225715\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.257277\n",
      "Epoch:79\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.264553\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.254612\n",
      "Epoch:80\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.325353\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.252960\n",
      "Epoch:81\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.233008\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.249311\n",
      "Epoch:82\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.253674\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.244336\n",
      "Epoch:83\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.256061\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.241339\n",
      "Epoch:84\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.197340\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.238080\n",
      "Epoch:85\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.196762\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.234798\n",
      "Epoch:86\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.301515\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.232683\n",
      "Epoch:87\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.168062\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.229880\n",
      "Epoch:88\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.243792\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.225163\n",
      "Epoch:89\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.252455\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.223395\n",
      "Epoch:90\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.229575\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.218726\n",
      "Epoch:91\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.214939\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.216681\n",
      "Epoch:92\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.213718\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.215173\n",
      "Epoch:93\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.230683\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.210992\n",
      "Epoch:94\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.162284\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.208886\n",
      "Epoch:95\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.193911\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.205840\n",
      "Epoch:96\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.271072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.202924\n",
      "Epoch:97\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.196374\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.202781\n",
      "Epoch:98\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.228068\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.201109\n",
      "Epoch:99\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.192406\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.195005\n",
      "Epoch:100\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.161021\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.193030\n",
      "Epoch:101\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.237939\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.191338\n",
      "Epoch:102\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.199919\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.189297\n",
      "Epoch:103\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.212877\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.185655\n",
      "Epoch:104\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.170302\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.183819\n",
      "Epoch:105\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.264348\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.182576\n",
      "Epoch:106\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.223429\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.179726\n",
      "Epoch:107\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.156684\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.179502\n",
      "Epoch:108\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.206079\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.176795\n",
      "Epoch:109\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.143537\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.173700\n",
      "Epoch:110\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.209340\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.171440\n",
      "Epoch:111\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.193298\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.169799\n",
      "Epoch:112\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.184206\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.167366\n",
      "Epoch:113\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.275639\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.165708\n",
      "Epoch:114\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.205714\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.162773\n",
      "Epoch:115\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.255550\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.160796\n",
      "Epoch:116\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.137502\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.162293\n",
      "Epoch:117\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.157097\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.161382\n",
      "Epoch:118\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.151530\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.157668\n",
      "Epoch:119\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.186929\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.156212\n",
      "Epoch:120\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.173813\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.152103\n",
      "Epoch:121\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.125518\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.150166\n",
      "Epoch:122\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.107066\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.150803\n",
      "Epoch:123\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.185902\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.150131\n",
      "Epoch:124\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.194345\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.149099\n",
      "Epoch:125\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.121175\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.143794\n",
      "Epoch:126\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.178188\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.144332\n",
      "Epoch:127\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.153891\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.143165\n",
      "Epoch:128\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.159206\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.142990\n",
      "Epoch:129\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.195767\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.140461\n",
      "Epoch:130\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.124801\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.137329\n",
      "Epoch:131\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.117971\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.137273\n",
      "Epoch:132\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.126224\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.137504\n",
      "Epoch:133\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.111034\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.138452\n",
      "Epoch:134\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.131828\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.133719\n",
      "Epoch:135\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.133002\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.130145\n",
      "Epoch:136\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.162930\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.130887\n",
      "Epoch:137\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.081719\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.130032\n",
      "Epoch:138\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.155333\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.129793\n",
      "Epoch:139\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.130582\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.128697\n",
      "Epoch:140\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.128905\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.125233\n",
      "Epoch:141\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.197768\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.123342\n",
      "Epoch:142\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.183184\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.124674\n",
      "Epoch:143\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.130174\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.125219\n",
      "Epoch:144\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.121133\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.125596\n",
      "Epoch:145\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.194303\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.121283\n",
      "Epoch:146\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.105432\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.118003\n",
      "Epoch:147\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.159838\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.118610\n",
      "Epoch:148\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.125326\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.119876\n",
      "Epoch:149\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.166051\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.119644\n",
      "Epoch:150\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.195862\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.117062\n",
      "Epoch:151\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.141983\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.115469\n",
      "Epoch:152\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.188677\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.114503\n",
      "Epoch:153\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.148041\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.115799\n",
      "Epoch:154\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.185649\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.112318\n",
      "Epoch:155\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.125055\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.110217\n",
      "Epoch:156\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.139253\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.108894\n",
      "Epoch:157\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.111150\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.108598\n",
      "Epoch:158\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067917\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.109492\n",
      "Epoch:159\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.123904\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.107486\n",
      "Epoch:160\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.165474\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.108579\n",
      "Epoch:161\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.170697\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.105835\n",
      "Epoch:162\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.096490\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.106840\n",
      "Epoch:163\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.163965\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.105980\n",
      "Epoch:164\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.061599\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.106038\n",
      "Epoch:165\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.144754\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.104557\n",
      "Epoch:166\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.132218\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.101664\n",
      "Epoch:167\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.141235\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.100258\n",
      "Epoch:168\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.124330\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.100116\n",
      "Epoch:169\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.122269\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.100908\n",
      "Epoch:170\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.090286\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.097674\n",
      "Epoch:171\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.133593\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.100435\n",
      "Epoch:172\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.107342\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.099503\n",
      "Epoch:173\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.184375\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.095582\n",
      "Epoch:174\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.117031\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.097656\n",
      "Epoch:175\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.091496\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.097674\n",
      "Epoch:176\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.126233\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.096297\n",
      "Epoch:177\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.093424\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.095944\n",
      "Epoch:178\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.094282\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.095951\n",
      "Epoch:179\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.136482\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.094518\n",
      "Epoch:180\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.066196\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.093910\n",
      "Epoch:181\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.071365\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.090863\n",
      "Epoch:182\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.112583\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.092254\n",
      "Epoch:183\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.125647\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.090752\n",
      "Epoch:184\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.107459\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.093355\n",
      "Epoch:185\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057528\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.088461\n",
      "Epoch:186\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072084\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.089800\n",
      "Epoch:187\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.145162\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.090273\n",
      "Epoch:188\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.063700\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.090797\n",
      "Epoch:189\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.093044\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.087860\n",
      "Epoch:190\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.085780\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.087591\n",
      "Epoch:191\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.113973\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.086743\n",
      "Epoch:192\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.161521\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.085331\n",
      "Epoch:193\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.172544\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.085034\n",
      "Epoch:194\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.162405\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.087086\n",
      "Epoch:195\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.104976\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.087243\n",
      "Epoch:196\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051991\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.082376\n",
      "Epoch:197\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.102552\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.082364\n",
      "Epoch:198\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.095112\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.083250\n",
      "Epoch:199\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.100585\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.083297\n",
      "Epoch:200\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.113712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.081630\n",
      "Epoch:201\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.186763\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.081299\n",
      "Epoch:202\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.133413\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.081897\n",
      "Epoch:203\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127308\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.081334\n",
      "Epoch:204\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.090571\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.083979\n",
      "Epoch:205\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.065414\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.080950\n",
      "Epoch:206\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.115010\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.079433\n",
      "Epoch:207\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.135112\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.078741\n",
      "Epoch:208\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.096874\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.077446\n",
      "Epoch:209\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.155990\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.077820\n",
      "Epoch:210\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067379\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.081071\n",
      "Epoch:211\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.154007\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.077622\n",
      "Epoch:212\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.103568\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.079876\n",
      "Epoch:213\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.136752\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.074203\n",
      "Epoch:214\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.154484\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.073654\n",
      "Epoch:215\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.142447\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.078046\n",
      "Epoch:216\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.092975\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.076900\n",
      "Epoch:217\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.071602\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.076268\n",
      "Epoch:218\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.056949\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.075288\n",
      "Epoch:219\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.143248\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.071675\n",
      "Epoch:220\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.105322\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.075248\n",
      "Epoch:221\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127697\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.077488\n",
      "Epoch:222\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.166953\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.072049\n",
      "Epoch:223\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.173258\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.072192\n",
      "Epoch:224\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073284\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.073727\n",
      "Epoch:225\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.086381\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.073440\n",
      "Epoch:226\n",
      "Training...\n",
      " Accuracy:95.833333 loss:0.057435\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.073678\n",
      "Epoch:227\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048630\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.069815\n",
      "Epoch:228\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.134111\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.069539\n",
      "Epoch:229\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.088201\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.069780\n",
      "Epoch:230\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.089207\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.070344\n",
      "Epoch:231\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.114480\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.071181\n",
      "Epoch:232\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.112282\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.068042\n",
      "Epoch:233\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.126547\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.066399\n",
      "Epoch:234\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.214165\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.067846\n",
      "Epoch:235\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.102352\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.072991\n",
      "Epoch:236\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.183721\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.069441\n",
      "Epoch:237\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.112723\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.070656\n",
      "Epoch:238\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.162615\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.070435\n",
      "Epoch:239\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.108668\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.068967\n",
      "Epoch:240\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.147763\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.067925\n",
      "Epoch:241\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.087655\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.065217\n",
      "Epoch:242\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.162299\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.066928\n",
      "Epoch:243\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048058\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.067636\n",
      "Epoch:244\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.160489\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.065399\n",
      "Epoch:245\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127995\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.066034\n",
      "Epoch:246\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.144017\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.068011\n",
      "Epoch:247\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067960\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.068007\n",
      "Epoch:248\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.161246\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.065692\n",
      "Epoch:249\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.082885\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.065285\n",
      "Epoch:250\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.205615\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.063296\n",
      "Epoch:251\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.192349\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.068068\n",
      "Epoch:252\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057748\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.063545\n",
      "Epoch:253\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.087669\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.060506\n",
      "Epoch:254\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069662\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.060866\n",
      "Epoch:255\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.103411\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.064888\n",
      "Epoch:256\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.130606\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.062421\n",
      "Epoch:257\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.102806\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.062135\n",
      "Epoch:258\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.134524\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.061300\n",
      "Epoch:259\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.157689\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.059626\n",
      "Epoch:260\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064125\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.061129\n",
      "Epoch:261\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.135931\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.064051\n",
      "Epoch:262\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.095196\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.063535\n",
      "Epoch:263\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.115330\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.061097\n",
      "Epoch:264\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.160268\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.059707\n",
      "Epoch:265\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051384\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.058940\n",
      "Epoch:266\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.071080\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.059202\n",
      "Epoch:267\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.158145\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.063350\n",
      "Epoch:268\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.065056\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.060337\n",
      "Epoch:269\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064128\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.062461\n",
      "Epoch:270\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.125859\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.058521\n",
      "Epoch:271\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.148632\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.059402\n",
      "Epoch:272\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.091074\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.061848\n",
      "Epoch:273\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.218046\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.057368\n",
      "Epoch:274\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.152912\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.058192\n",
      "Epoch:275\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.134061\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.058242\n",
      "Epoch:276\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.074063\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.057589\n",
      "Epoch:277\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.100055\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.057595\n",
      "Epoch:278\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.097482\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.054747\n",
      "Epoch:279\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.188812\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.053942\n",
      "Epoch:280\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.063075\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.060370\n",
      "Epoch:281\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.087775\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.060160\n",
      "Epoch:282\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.063480\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.055378\n",
      "Epoch:283\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.198248\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.054175\n",
      "Epoch:284\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.084247\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.056289\n",
      "Epoch:285\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041092\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.057279\n",
      "Epoch:286\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.131865\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.056330\n",
      "Epoch:287\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.201433\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.052107\n",
      "Epoch:288\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.133327\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.055612\n",
      "Epoch:289\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.087579\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.056402\n",
      "Epoch:290\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.095405\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.054391\n",
      "Epoch:291\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.187060\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.052898\n",
      "Epoch:292\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.172983\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.054780\n",
      "Epoch:293\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.179079\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.058618\n",
      "Epoch:294\n",
      "Training...\n",
      " Accuracy:95.833333 loss:0.116973\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.060506\n",
      "Epoch:295\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043677\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.052870\n",
      "Epoch:296\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.112322\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.050731\n",
      "Epoch:297\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.108842\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.050918\n",
      "Epoch:298\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043569\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.055221\n",
      "Epoch:299\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044440\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.055817\n",
      "Epoch:300\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045466\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.053655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:301\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064009\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.053058\n",
      "Epoch:302\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.156769\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.051431\n",
      "Epoch:303\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029437\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.052572\n",
      "Epoch:304\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078798\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.052318\n",
      "Epoch:305\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.169466\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.052003\n",
      "Epoch:306\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.146719\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.049509\n",
      "Epoch:307\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.069371\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.054158\n",
      "Epoch:308\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.127710\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.052678\n",
      "Epoch:309\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.162128\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.051054\n",
      "Epoch:310\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.060660\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.049299\n",
      "Epoch:311\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.092275\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.051875\n",
      "Epoch:312\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.175410\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.050689\n",
      "Epoch:313\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.071796\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.050641\n",
      "Epoch:314\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.185630\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.053726\n",
      "Epoch:315\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023531\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.052379\n",
      "Epoch:316\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.102862\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.051163\n",
      "Epoch:317\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.075833\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.048835\n",
      "Epoch:318\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054023\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.048957\n",
      "Epoch:319\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.122755\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.049202\n",
      "Epoch:320\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.098712\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.052499\n",
      "Epoch:321\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.109931\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.048935\n",
      "Epoch:322\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.170065\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.051135\n",
      "Epoch:323\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.062102\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.049752\n",
      "Epoch:324\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037440\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.046564\n",
      "Epoch:325\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068987\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.048114\n",
      "Epoch:326\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.116113\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.047157\n",
      "Epoch:327\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068788\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.049242\n",
      "Epoch:328\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.074438\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.047594\n",
      "Epoch:329\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.094704\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.047348\n",
      "Epoch:330\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.090408\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.049322\n",
      "Epoch:331\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.174494\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.044306\n",
      "Epoch:332\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.138687\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.048140\n",
      "Epoch:333\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062690\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.049362\n",
      "Epoch:334\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.089746\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.049141\n",
      "Epoch:335\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.058979\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.045644\n",
      "Epoch:336\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035239\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.049000\n",
      "Epoch:337\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057068\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.047301\n",
      "Epoch:338\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053591\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.046447\n",
      "Epoch:339\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.078355\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.046569\n",
      "Epoch:340\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.124016\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.045204\n",
      "Epoch:341\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.090307\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.048288\n",
      "Epoch:342\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.063218\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.048040\n",
      "Epoch:343\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.139467\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.045451\n",
      "Epoch:344\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.070787\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.046321\n",
      "Epoch:345\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068228\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.045305\n",
      "Epoch:346\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.204531\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.042239\n",
      "Epoch:347\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.066892\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.044110\n",
      "Epoch:348\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.138984\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.045051\n",
      "Epoch:349\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.142475\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.047034\n",
      "Epoch:350\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.164862\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.047268\n",
      "Epoch:351\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060477\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.044480\n",
      "Epoch:352\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.108893\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.041884\n",
      "Epoch:353\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.086772\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.044167\n",
      "Epoch:354\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.120295\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.045033\n",
      "Epoch:355\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.101922\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.043245\n",
      "Epoch:356\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055993\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.043903\n",
      "Epoch:357\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.066911\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.048223\n",
      "Epoch:358\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.080845\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.044557\n",
      "Epoch:359\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068967\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.041352\n",
      "Epoch:360\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063734\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.041114\n",
      "Epoch:361\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.078334\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.043830\n",
      "Epoch:362\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044089\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.044243\n",
      "Epoch:363\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057929\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.041340\n",
      "Epoch:364\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.149626\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.040687\n",
      "Epoch:365\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038255\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.043272\n",
      "Epoch:366\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059671\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.044519\n",
      "Epoch:367\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.093020\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.047169\n",
      "Epoch:368\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.112436\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.042453\n",
      "Epoch:369\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043368\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.039866\n",
      "Epoch:370\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.184208\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.040391\n",
      "Epoch:371\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.131410\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.045145\n",
      "Epoch:372\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.118830\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.047525\n",
      "Epoch:373\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.148170\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.041531\n",
      "Epoch:374\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.081993\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.042541\n",
      "Epoch:375\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.086011\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.042575\n",
      "Epoch:376\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.079499\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.042569\n",
      "Epoch:377\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057684\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.041737\n",
      "Epoch:378\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.102882\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.041858\n",
      "Epoch:379\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.070740\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.039631\n",
      "Epoch:380\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.176747\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.037908\n",
      "Epoch:381\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.160442\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.042513\n",
      "Epoch:382\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043967\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.044618\n",
      "Epoch:383\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.101506\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.043408\n",
      "Epoch:384\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.138787\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.040646\n",
      "Epoch:385\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043251\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.039135\n",
      "Epoch:386\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050426\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.040887\n",
      "Epoch:387\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039273\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.039692\n",
      "Epoch:388\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044085\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.040131\n",
      "Epoch:389\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.055248\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.042001\n",
      "Epoch:390\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035645\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.040790\n",
      "Epoch:391\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043278\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.038466\n",
      "Epoch:392\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.089196\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.040765\n",
      "Epoch:393\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.075141\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.039257\n",
      "Epoch:394\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.131978\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.037937\n",
      "Epoch:395\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053864\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.040039\n",
      "Epoch:396\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.178527\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.041052\n",
      "Epoch:397\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050259\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.040763\n",
      "Epoch:398\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059753\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.040049\n",
      "Epoch:399\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.151016\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.039082\n",
      "Epoch:400\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.083302\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.039794\n",
      "Epoch:401\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy:96.666667 loss:0.092658\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.041122\n",
      "Epoch:402\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.127509\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.037509\n",
      "Epoch:403\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.086254\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.037952\n",
      "Epoch:404\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024562\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.037479\n",
      "Epoch:405\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.144186\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.039652\n",
      "Epoch:406\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.037508\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.040257\n",
      "Epoch:407\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.074668\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.036868\n",
      "Epoch:408\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.135752\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.036741\n",
      "Epoch:409\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.091092\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.037344\n",
      "Epoch:410\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.100280\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.039333\n",
      "Epoch:411\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062630\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.042031\n",
      "Epoch:412\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.172808\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.037253\n",
      "Epoch:413\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.066520\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.038153\n",
      "Epoch:414\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.065530\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.037514\n",
      "Epoch:415\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048638\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.038239\n",
      "Epoch:416\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.079811\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.035831\n",
      "Epoch:417\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.097365\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.035995\n",
      "Epoch:418\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.179096\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.036009\n",
      "Epoch:419\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046262\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.038145\n",
      "Epoch:420\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.085699\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.039436\n",
      "Epoch:421\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027864\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.035993\n",
      "Epoch:422\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.161364\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.034354\n",
      "Epoch:423\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.195238\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.034520\n",
      "Epoch:424\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.155202\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.041120\n",
      "Epoch:425\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.091456\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.040472\n",
      "Epoch:426\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066410\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.034338\n",
      "Epoch:427\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069009\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.035905\n",
      "Epoch:428\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.129176\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.034468\n",
      "Epoch:429\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.065986\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.037121\n",
      "Epoch:430\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.089684\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.038626\n",
      "Epoch:431\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.018422\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.033340\n",
      "Epoch:432\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.175566\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.032443\n",
      "Epoch:433\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054657\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.036625\n",
      "Epoch:434\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049634\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.037658\n",
      "Epoch:435\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.130772\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.036566\n",
      "Epoch:436\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033236\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.035299\n",
      "Epoch:437\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044629\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.035587\n",
      "Epoch:438\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.163874\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.033161\n",
      "Epoch:439\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.078804\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.034606\n",
      "Epoch:440\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023156\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.036342\n",
      "Epoch:441\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.018420\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.037128\n",
      "Epoch:442\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.175901\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.034699\n",
      "Epoch:443\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050606\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.033765\n",
      "Epoch:444\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051665\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.037472\n",
      "Epoch:445\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.077584\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.035896\n",
      "Epoch:446\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.179019\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.033983\n",
      "Epoch:447\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.131015\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.034447\n",
      "Epoch:448\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064948\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.035448\n",
      "Epoch:449\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051782\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.035480\n",
      "Epoch:450\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.063829\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.034039\n",
      "Epoch:451\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.153142\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.032105\n",
      "Epoch:452\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042866\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.034283\n",
      "Epoch:453\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.091579\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.031919\n",
      "Epoch:454\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.091310\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.035070\n",
      "Epoch:455\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.159719\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.036476\n",
      "Epoch:456\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.191565\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.038365\n",
      "Epoch:457\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.073849\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.034087\n",
      "Epoch:458\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.144547\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.034203\n",
      "Epoch:459\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.151294\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.032870\n",
      "Epoch:460\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030740\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.035518\n",
      "Epoch:461\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062242\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.032635\n",
      "Epoch:462\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.078608\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.034760\n",
      "Epoch:463\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035841\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.032332\n",
      "Epoch:464\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.105429\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.032509\n",
      "Epoch:465\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.103008\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.033437\n",
      "Epoch:466\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.133112\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.032014\n",
      "Epoch:467\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030216\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.031686\n",
      "Epoch:468\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.083409\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.032943\n",
      "Epoch:469\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037287\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.033229\n",
      "Epoch:470\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.187925\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.032080\n",
      "Epoch:471\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137717\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.032644\n",
      "Epoch:472\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.179877\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.031589\n",
      "Epoch:473\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041290\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.036336\n",
      "Epoch:474\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.086642\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.034075\n",
      "Epoch:475\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.148597\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.029290\n",
      "Epoch:476\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045548\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.030289\n",
      "Epoch:477\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.099186\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.033345\n",
      "Epoch:478\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045508\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.032301\n",
      "Epoch:479\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056625\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.030345\n",
      "Epoch:480\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.129523\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.031030\n",
      "Epoch:481\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023535\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.033127\n",
      "Epoch:482\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.139337\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.031590\n",
      "Epoch:483\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.133924\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.032390\n",
      "Epoch:484\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.010225\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.033227\n",
      "Epoch:485\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.071693\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.032547\n",
      "Epoch:486\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.189998\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.030718\n",
      "Epoch:487\n",
      "Training...\n",
      " Accuracy:95.833333 loss:0.105061\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.035455\n",
      "Epoch:488\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.137516\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.031007\n",
      "Epoch:489\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.071896\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.030748\n",
      "Epoch:490\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068199\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.029243\n",
      "Epoch:491\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137735\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.028604\n",
      "Epoch:492\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027210\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.031542\n",
      "Epoch:493\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.123501\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.033034\n",
      "Epoch:494\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026000\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.031355\n",
      "Epoch:495\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026829\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.031283\n",
      "Epoch:496\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.100694\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.030108\n",
      "Epoch:497\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.097438\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.028222\n",
      "Epoch:498\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063658\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.029508\n",
      "Epoch:499\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.112194\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.030677\n",
      "Epoch:500\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064411\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.031144\n",
      "Epoch:501\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.028539\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.031982\n",
      "Epoch:502\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068925\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.030198\n",
      "Epoch:503\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.190291\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.028633\n",
      "Epoch:504\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063878\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.030249\n",
      "Epoch:505\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.028192\n",
      "Epoch:506\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062803\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.032208\n",
      "Epoch:507\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.157620\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.030690\n",
      "Epoch:508\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024567\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.030154\n",
      "Epoch:509\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073154\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.030864\n",
      "Epoch:510\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034641\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.030907\n",
      "Epoch:511\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059318\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.029676\n",
      "Epoch:512\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.174668\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.029793\n",
      "Epoch:513\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045496\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.031394\n",
      "Epoch:514\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.079564\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.029880\n",
      "Epoch:515\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047256\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.028626\n",
      "Epoch:516\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.070184\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.029620\n",
      "Epoch:517\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.137195\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.027282\n",
      "Epoch:518\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.128085\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.027803\n",
      "Epoch:519\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.075411\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.031051\n",
      "Epoch:520\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.023816\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.028242\n",
      "Epoch:521\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054825\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026277\n",
      "Epoch:522\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.099104\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.028309\n",
      "Epoch:523\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015111\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.027678\n",
      "Epoch:524\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.115006\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.029000\n",
      "Epoch:525\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022472\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.031850\n",
      "Epoch:526\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.166473\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.030308\n",
      "Epoch:527\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045189\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.029103\n",
      "Epoch:528\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.079091\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.029096\n",
      "Epoch:529\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037681\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.029554\n",
      "Epoch:530\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.087886\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.028829\n",
      "Epoch:531\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.188144\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026516\n",
      "Epoch:532\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063247\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.030119\n",
      "Epoch:533\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.117949\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.027742\n",
      "Epoch:534\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.090096\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.029998\n",
      "Epoch:535\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.161664\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025924\n",
      "Epoch:536\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.114050\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025642\n",
      "Epoch:537\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.086198\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.028350\n",
      "Epoch:538\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.014184\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.031543\n",
      "Epoch:539\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.105020\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.028955\n",
      "Epoch:540\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.082614\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026629\n",
      "Epoch:541\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.145714\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025722\n",
      "Epoch:542\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028235\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.028384\n",
      "Epoch:543\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.058914\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.029988\n",
      "Epoch:544\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.039257\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.027891\n",
      "Epoch:545\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046683\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026438\n",
      "Epoch:546\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056600\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026278\n",
      "Epoch:547\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.060037\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.028281\n",
      "Epoch:548\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036439\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.028279\n",
      "Epoch:549\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.061864\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.027578\n",
      "Epoch:550\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038095\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.027074\n",
      "Epoch:551\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.136185\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026450\n",
      "Epoch:552\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049445\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.027916\n",
      "Epoch:553\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062648\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.028040\n",
      "Epoch:554\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.124958\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025373\n",
      "Epoch:555\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042049\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026273\n",
      "Epoch:556\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.156050\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026122\n",
      "Epoch:557\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.089118\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.028336\n",
      "Epoch:558\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.219460\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025825\n",
      "Epoch:559\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.168750\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.028828\n",
      "Epoch:560\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.011996\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.029083\n",
      "Epoch:561\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.040931\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026663\n",
      "Epoch:562\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.060662\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025905\n",
      "Epoch:563\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.058409\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025827\n",
      "Epoch:564\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041855\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026519\n",
      "Epoch:565\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.203137\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024394\n",
      "Epoch:566\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.052368\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.029203\n",
      "Epoch:567\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050222\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026037\n",
      "Epoch:568\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046803\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025642\n",
      "Epoch:569\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019783\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026137\n",
      "Epoch:570\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.083324\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.027976\n",
      "Epoch:571\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.121071\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024205\n",
      "Epoch:572\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051474\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025303\n",
      "Epoch:573\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073998\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025423\n",
      "Epoch:574\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034614\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026588\n",
      "Epoch:575\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022487\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026496\n",
      "Epoch:576\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.070148\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025712\n",
      "Epoch:577\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.132045\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024283\n",
      "Epoch:578\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.162987\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024497\n",
      "Epoch:579\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024004\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024542\n",
      "Epoch:580\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033383\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025696\n",
      "Epoch:581\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039252\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025091\n",
      "Epoch:582\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.089397\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025656\n",
      "Epoch:583\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.029150\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024698\n",
      "Epoch:584\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.116362\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025487\n",
      "Epoch:585\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.120943\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025502\n",
      "Epoch:586\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042330\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.027806\n",
      "Epoch:587\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.175122\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024736\n",
      "Epoch:588\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.184405\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024977\n",
      "Epoch:589\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.136959\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026307\n",
      "Epoch:590\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050411\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.027308\n",
      "Epoch:591\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027102\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026226\n",
      "Epoch:592\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034110\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025540\n",
      "Epoch:593\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.060355\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025263\n",
      "Epoch:594\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034417\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026232\n",
      "Epoch:595\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.009033\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026078\n",
      "Epoch:596\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.070230\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.027214\n",
      "Epoch:597\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040609\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023259\n",
      "Epoch:598\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.180410\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022827\n",
      "Epoch:599\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.094544\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025376\n",
      "Epoch:600\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.111756\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.027023\n",
      "Epoch:601\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.057230\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023299\n",
      "Epoch:602\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023051\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021777\n",
      "Epoch:603\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059263\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021987\n",
      "Epoch:604\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.153689\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024827\n",
      "Epoch:605\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.081400\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026833\n",
      "Epoch:606\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.070622\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023746\n",
      "Epoch:607\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.125702\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021584\n",
      "Epoch:608\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054512\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023933\n",
      "Epoch:609\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026769\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023508\n",
      "Epoch:610\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.171266\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023280\n",
      "Epoch:611\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.082270\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:612\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059499\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023153\n",
      "Epoch:613\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034233\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023081\n",
      "Epoch:614\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064412\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023489\n",
      "Epoch:615\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.140404\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024370\n",
      "Epoch:616\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.006898\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023486\n",
      "Epoch:617\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.139007\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022738\n",
      "Epoch:618\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.143651\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024125\n",
      "Epoch:619\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.108719\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024738\n",
      "Epoch:620\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041596\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024458\n",
      "Epoch:621\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073535\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024340\n",
      "Epoch:622\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041367\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022631\n",
      "Epoch:623\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037476\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024267\n",
      "Epoch:624\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053641\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024332\n",
      "Epoch:625\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018024\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024554\n",
      "Epoch:626\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054454\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022121\n",
      "Epoch:627\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028501\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021651\n",
      "Epoch:628\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052352\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023325\n",
      "Epoch:629\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.152991\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024129\n",
      "Epoch:630\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.083286\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.024640\n",
      "Epoch:631\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.185053\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022672\n",
      "Epoch:632\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032185\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.025550\n",
      "Epoch:633\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054062\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026331\n",
      "Epoch:634\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.066367\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021876\n",
      "Epoch:635\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.104532\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021327\n",
      "Epoch:636\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041872\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022963\n",
      "Epoch:637\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061914\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.026342\n",
      "Epoch:638\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.069510\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023584\n",
      "Epoch:639\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046744\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021516\n",
      "Epoch:640\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061975\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021548\n",
      "Epoch:641\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024375\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021071\n",
      "Epoch:642\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.071542\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021450\n",
      "Epoch:643\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062897\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022056\n",
      "Epoch:644\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063481\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022911\n",
      "Epoch:645\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053471\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021317\n",
      "Epoch:646\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.079482\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021937\n",
      "Epoch:647\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015324\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021287\n",
      "Epoch:648\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.142045\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021743\n",
      "Epoch:649\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038351\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022585\n",
      "Epoch:650\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.085814\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023827\n",
      "Epoch:651\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053986\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023804\n",
      "Epoch:652\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066489\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022578\n",
      "Epoch:653\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.176835\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020175\n",
      "Epoch:654\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.007202\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021059\n",
      "Epoch:655\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137605\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022580\n",
      "Epoch:656\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.075180\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023693\n",
      "Epoch:657\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.093852\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022755\n",
      "Epoch:658\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024289\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020985\n",
      "Epoch:659\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.154119\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020802\n",
      "Epoch:660\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045625\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022201\n",
      "Epoch:661\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.163140\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023893\n",
      "Epoch:662\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026399\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020238\n",
      "Epoch:663\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041439\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021293\n",
      "Epoch:664\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044777\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022430\n",
      "Epoch:665\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030236\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022671\n",
      "Epoch:666\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.012959\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020124\n",
      "Epoch:667\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.083340\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020377\n",
      "Epoch:668\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042449\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019344\n",
      "Epoch:669\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.181128\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020632\n",
      "Epoch:670\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.032538\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023878\n",
      "Epoch:671\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137247\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022221\n",
      "Epoch:672\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.131032\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021476\n",
      "Epoch:673\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.062979\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023329\n",
      "Epoch:674\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.147904\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021213\n",
      "Epoch:675\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.158324\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022333\n",
      "Epoch:676\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054468\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021381\n",
      "Epoch:677\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.163413\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020597\n",
      "Epoch:678\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048273\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023274\n",
      "Epoch:679\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.030817\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023610\n",
      "Epoch:680\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042067\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021658\n",
      "Epoch:681\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.134916\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020984\n",
      "Epoch:682\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020301\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020006\n",
      "Epoch:683\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026187\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020054\n",
      "Epoch:684\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019118\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020869\n",
      "Epoch:685\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.066857\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022566\n",
      "Epoch:686\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.126773\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020901\n",
      "Epoch:687\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045113\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019358\n",
      "Epoch:688\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.093924\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019042\n",
      "Epoch:689\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034743\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020069\n",
      "Epoch:690\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029289\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.023869\n",
      "Epoch:691\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.058660\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021911\n",
      "Epoch:692\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.054597\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019081\n",
      "Epoch:693\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037411\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018789\n",
      "Epoch:694\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.165631\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018484\n",
      "Epoch:695\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054741\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021837\n",
      "Epoch:696\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057101\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021720\n",
      "Epoch:697\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034070\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019388\n",
      "Epoch:698\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049284\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018990\n",
      "Epoch:699\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.159854\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020236\n",
      "Epoch:700\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.085457\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021654\n",
      "Epoch:701\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.029782\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020256\n",
      "Epoch:702\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.074495\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019160\n",
      "Epoch:703\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043662\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019530\n",
      "Epoch:704\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.111129\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019410\n",
      "Epoch:705\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.081591\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020627\n",
      "Epoch:706\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023474\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022762\n",
      "Epoch:707\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028261\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020890\n",
      "Epoch:708\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048105\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019982\n",
      "Epoch:709\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056802\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020051\n",
      "Epoch:710\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033582\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020917\n",
      "Epoch:711\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.154511\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018722\n",
      "Epoch:712\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.168128\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021978\n",
      "Epoch:713\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047930\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021845\n",
      "Epoch:714\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.057024\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019287\n",
      "Epoch:715\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054653\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018045\n",
      "Epoch:716\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.126006\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018105\n",
      "Epoch:717\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021207\n",
      "Epoch:718\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049907\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021654\n",
      "Epoch:719\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.020264\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019421\n",
      "Epoch:720\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020099\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018179\n",
      "Epoch:721\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055201\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018313\n",
      "Epoch:722\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.135399\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018753\n",
      "Epoch:723\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.103075\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019355\n",
      "Epoch:724\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.072794\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022936\n",
      "Epoch:725\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.101505\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021180\n",
      "Epoch:726\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047870\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018295\n",
      "Epoch:727\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036152\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018860\n",
      "Epoch:728\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.094508\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019508\n",
      "Epoch:729\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037560\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017205\n",
      "Epoch:730\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040155\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018211\n",
      "Epoch:731\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043543\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018630\n",
      "Epoch:732\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.160089\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018556\n",
      "Epoch:733\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047476\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018786\n",
      "Epoch:734\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051778\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.022030\n",
      "Epoch:735\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.076755\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020151\n",
      "Epoch:736\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069409\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017862\n",
      "Epoch:737\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052216\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018081\n",
      "Epoch:738\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.180937\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017741\n",
      "Epoch:739\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020376\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020822\n",
      "Epoch:740\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017827\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021193\n",
      "Epoch:741\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.094259\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020085\n",
      "Epoch:742\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.071914\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017849\n",
      "Epoch:743\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.114320\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017016\n",
      "Epoch:744\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016510\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018497\n",
      "Epoch:745\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038974\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017708\n",
      "Epoch:746\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062554\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019507\n",
      "Epoch:747\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.052957\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019454\n",
      "Epoch:748\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048848\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018074\n",
      "Epoch:749\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.021515\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018548\n",
      "Epoch:750\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.079458\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019106\n",
      "Epoch:751\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.065386\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018278\n",
      "Epoch:752\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.172350\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016058\n",
      "Epoch:753\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137927\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017940\n",
      "Epoch:754\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.174755\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019338\n",
      "Epoch:755\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.012519\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019865\n",
      "Epoch:756\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.033384\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018217\n",
      "Epoch:757\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010823\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017213\n",
      "Epoch:758\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.074835\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018175\n",
      "Epoch:759\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.084687\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018206\n",
      "Epoch:760\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.084522\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018203\n",
      "Epoch:761\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.156203\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018983\n",
      "Epoch:762\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029687\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018727\n",
      "Epoch:763\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.087860\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016902\n",
      "Epoch:764\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.080510\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016420\n",
      "Epoch:765\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051596\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017418\n",
      "Epoch:766\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.053380\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019911\n",
      "Epoch:767\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.096220\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019521\n",
      "Epoch:768\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.030559\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016430\n",
      "Epoch:769\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.164626\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015528\n",
      "Epoch:770\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073974\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018532\n",
      "Epoch:771\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.125658\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.021796\n",
      "Epoch:772\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.044241\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020744\n",
      "Epoch:773\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036536\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019109\n",
      "Epoch:774\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.057083\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018349\n",
      "Epoch:775\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.163359\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016515\n",
      "Epoch:776\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073563\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018052\n",
      "Epoch:777\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.059310\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019563\n",
      "Epoch:778\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050260\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016648\n",
      "Epoch:779\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073848\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016412\n",
      "Epoch:780\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053663\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018316\n",
      "Epoch:781\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.052774\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016786\n",
      "Epoch:782\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055605\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016352\n",
      "Epoch:783\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030427\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016579\n",
      "Epoch:784\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.135771\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017338\n",
      "Epoch:785\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.161321\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018827\n",
      "Epoch:786\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.025398\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019738\n",
      "Epoch:787\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.170458\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017754\n",
      "Epoch:788\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.058297\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017240\n",
      "Epoch:789\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.075838\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018199\n",
      "Epoch:790\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040554\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016388\n",
      "Epoch:791\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.205421\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016060\n",
      "Epoch:792\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040190\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019017\n",
      "Epoch:793\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034181\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017698\n",
      "Epoch:794\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060082\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016685\n",
      "Epoch:795\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049739\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016382\n",
      "Epoch:796\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073591\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016307\n",
      "Epoch:797\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.161804\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016883\n",
      "Epoch:798\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.004509\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020142\n",
      "Epoch:799\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.170013\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018110\n",
      "Epoch:800\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049183\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017236\n",
      "Epoch:801\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.143463\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015261\n",
      "Epoch:802\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045432\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017758\n",
      "Epoch:803\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.112887\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019376\n",
      "Epoch:804\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046909\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018338\n",
      "Epoch:805\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.050831\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015625\n",
      "Epoch:806\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035385\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014702\n",
      "Epoch:807\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.156055\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016130\n",
      "Epoch:808\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015677\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018423\n",
      "Epoch:809\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073699\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017522\n",
      "Epoch:810\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042119\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017363\n",
      "Epoch:811\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.167475\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016791\n",
      "Epoch:812\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.171783\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015182\n",
      "Epoch:813\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.180706\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016691\n",
      "Epoch:814\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.177065\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017390\n",
      "Epoch:815\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.025072\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019335\n",
      "Epoch:816\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051222\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017902\n",
      "Epoch:817\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.065333\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017738\n",
      "Epoch:818\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055606\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015731\n",
      "Epoch:819\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.171733\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015178\n",
      "Epoch:820\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.162349\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017996\n",
      "Epoch:821\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.039048\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017411\n",
      "Epoch:822\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048438\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:823\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.021322\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017770\n",
      "Epoch:824\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062630\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016529\n",
      "Epoch:825\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064634\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015587\n",
      "Epoch:826\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022235\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015171\n",
      "Epoch:827\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.018522\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015258\n",
      "Epoch:828\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.083704\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015237\n",
      "Epoch:829\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.140788\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015836\n",
      "Epoch:830\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.119806\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015753\n",
      "Epoch:831\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.152410\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016594\n",
      "Epoch:832\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073483\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.019564\n",
      "Epoch:833\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.049578\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016010\n",
      "Epoch:834\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031451\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014682\n",
      "Epoch:835\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.084326\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014324\n",
      "Epoch:836\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.173924\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015713\n",
      "Epoch:837\n",
      "Training...\n",
      " Accuracy:95.000000 loss:0.085162\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.020130\n",
      "Epoch:838\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.184082\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014723\n",
      "Epoch:839\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054801\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015870\n",
      "Epoch:840\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037279\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015600\n",
      "Epoch:841\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.077416\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015942\n",
      "Epoch:842\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.164841\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015389\n",
      "Epoch:843\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039852\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016521\n",
      "Epoch:844\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.076656\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016705\n",
      "Epoch:845\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041596\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016415\n",
      "Epoch:846\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064655\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015117\n",
      "Epoch:847\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.161287\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014476\n",
      "Epoch:848\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.079885\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016923\n",
      "Epoch:849\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.079721\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016452\n",
      "Epoch:850\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.042616\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017014\n",
      "Epoch:851\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.042993\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016047\n",
      "Epoch:852\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.101695\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015347\n",
      "Epoch:853\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044293\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016345\n",
      "Epoch:854\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.079363\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015980\n",
      "Epoch:855\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015735\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015423\n",
      "Epoch:856\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031367\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015924\n",
      "Epoch:857\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.066403\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016277\n",
      "Epoch:858\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017424\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014886\n",
      "Epoch:859\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033244\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014779\n",
      "Epoch:860\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.008162\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014286\n",
      "Epoch:861\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137534\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014717\n",
      "Epoch:862\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.150238\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015160\n",
      "Epoch:863\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.101704\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.018747\n",
      "Epoch:864\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059396\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015170\n",
      "Epoch:865\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.176857\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013909\n",
      "Epoch:866\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.141684\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015123\n",
      "Epoch:867\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.079280\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015915\n",
      "Epoch:868\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053180\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016413\n",
      "Epoch:869\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044644\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.017137\n",
      "Epoch:870\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.056490\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015012\n",
      "Epoch:871\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.161922\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013872\n",
      "Epoch:872\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.019241\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016029\n",
      "Epoch:873\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037713\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015304\n",
      "Epoch:874\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072238\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014344\n",
      "Epoch:875\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.188912\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013044\n",
      "Epoch:876\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062438\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016111\n",
      "Epoch:877\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.038377\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015397\n",
      "Epoch:878\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.154635\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014377\n",
      "Epoch:879\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.070671\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014263\n",
      "Epoch:880\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049241\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016467\n",
      "Epoch:881\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.031084\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016093\n",
      "Epoch:882\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025043\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014458\n",
      "Epoch:883\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052738\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014986\n",
      "Epoch:884\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036413\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015284\n",
      "Epoch:885\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035479\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014253\n",
      "Epoch:886\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.188397\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013674\n",
      "Epoch:887\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057470\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016702\n",
      "Epoch:888\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021768\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015964\n",
      "Epoch:889\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056327\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014707\n",
      "Epoch:890\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012249\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014736\n",
      "Epoch:891\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068451\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015829\n",
      "Epoch:892\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.028043\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014611\n",
      "Epoch:893\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050434\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013951\n",
      "Epoch:894\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041571\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014270\n",
      "Epoch:895\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050036\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015085\n",
      "Epoch:896\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062993\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014782\n",
      "Epoch:897\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012700\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014969\n",
      "Epoch:898\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057653\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015262\n",
      "Epoch:899\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039405\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014050\n",
      "Epoch:900\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.046180\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015106\n",
      "Epoch:901\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.175075\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013706\n",
      "Epoch:902\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068395\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016293\n",
      "Epoch:903\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.120780\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013267\n",
      "Epoch:904\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048530\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014240\n",
      "Epoch:905\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057452\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016068\n",
      "Epoch:906\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057332\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014947\n",
      "Epoch:907\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.158030\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013886\n",
      "Epoch:908\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061007\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015987\n",
      "Epoch:909\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048239\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013498\n",
      "Epoch:910\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061507\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013573\n",
      "Epoch:911\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025074\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014866\n",
      "Epoch:912\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026739\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014995\n",
      "Epoch:913\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048862\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014343\n",
      "Epoch:914\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.058731\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015745\n",
      "Epoch:915\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.061252\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015058\n",
      "Epoch:916\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.132215\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012492\n",
      "Epoch:917\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.058381\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014160\n",
      "Epoch:918\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.089335\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014680\n",
      "Epoch:919\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061289\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013064\n",
      "Epoch:920\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.167899\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013619\n",
      "Epoch:921\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.165478\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015004\n",
      "Epoch:922\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043469\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015945\n",
      "Epoch:923\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015514\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013561\n",
      "Epoch:924\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.166495\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012243\n",
      "Epoch:925\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040466\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014536\n",
      "Epoch:926\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036154\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.016053\n",
      "Epoch:927\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026703\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013121\n",
      "Epoch:928\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078531\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013558\n",
      "Epoch:929\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.065680\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013360\n",
      "Epoch:930\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014667\n",
      "Epoch:931\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016421\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014769\n",
      "Epoch:932\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.153975\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013687\n",
      "Epoch:933\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029947\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014933\n",
      "Epoch:934\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.145435\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014418\n",
      "Epoch:935\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.071191\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014534\n",
      "Epoch:936\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026906\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013499\n",
      "Epoch:937\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030206\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012734\n",
      "Epoch:938\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.021500\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013250\n",
      "Epoch:939\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.117685\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013834\n",
      "Epoch:940\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.119606\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014552\n",
      "Epoch:941\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.141165\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014801\n",
      "Epoch:942\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.038646\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013707\n",
      "Epoch:943\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.128975\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012616\n",
      "Epoch:944\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061083\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013237\n",
      "Epoch:945\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.158678\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013056\n",
      "Epoch:946\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.080588\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014076\n",
      "Epoch:947\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060542\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013863\n",
      "Epoch:948\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034083\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013921\n",
      "Epoch:949\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061691\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012955\n",
      "Epoch:950\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037873\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012319\n",
      "Epoch:951\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.056915\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013918\n",
      "Epoch:952\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.130671\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.015119\n",
      "Epoch:953\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.135744\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014197\n",
      "Epoch:954\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015948\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013660\n",
      "Epoch:955\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042570\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013006\n",
      "Epoch:956\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062389\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013711\n",
      "Epoch:957\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.075292\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013883\n",
      "Epoch:958\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.036232\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013446\n",
      "Epoch:959\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052358\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012460\n",
      "Epoch:960\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.106068\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014592\n",
      "Epoch:961\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.090298\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012282\n",
      "Epoch:962\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.133683\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013258\n",
      "Epoch:963\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031685\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013609\n",
      "Epoch:964\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062057\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012452\n",
      "Epoch:965\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.104409\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012183\n",
      "Epoch:966\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051409\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014437\n",
      "Epoch:967\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044042\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012696\n",
      "Epoch:968\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.188824\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011828\n",
      "Epoch:969\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.085950\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014655\n",
      "Epoch:970\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025194\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013554\n",
      "Epoch:971\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031795\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012698\n",
      "Epoch:972\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.029688\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012873\n",
      "Epoch:973\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053111\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012012\n",
      "Epoch:974\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.093716\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013777\n",
      "Epoch:975\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.082063\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013860\n",
      "Epoch:976\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015785\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012837\n",
      "Epoch:977\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032153\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012544\n",
      "Epoch:978\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.066014\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012307\n",
      "Epoch:979\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053660\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013122\n",
      "Epoch:980\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030355\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011526\n",
      "Epoch:981\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068574\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012094\n",
      "Epoch:982\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.083662\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013554\n",
      "Epoch:983\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.082512\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012963\n",
      "Epoch:984\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046549\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013803\n",
      "Epoch:985\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048150\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012641\n",
      "Epoch:986\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.067163\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011979\n",
      "Epoch:987\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032046\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013858\n",
      "Epoch:988\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033495\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014385\n",
      "Epoch:989\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.010303\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012845\n",
      "Epoch:990\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.070943\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012115\n",
      "Epoch:991\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016421\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013910\n",
      "Epoch:992\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.071013\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013024\n",
      "Epoch:993\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.196031\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011481\n",
      "Epoch:994\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.174828\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012837\n",
      "Epoch:995\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063720\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012980\n",
      "Epoch:996\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.154130\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012720\n",
      "Epoch:997\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016324\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014209\n",
      "Epoch:998\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019840\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012556\n",
      "Epoch:999\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050940\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011872\n",
      "Epoch:1000\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.103316\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013367\n",
      "Epoch:1001\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022744\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012855\n",
      "Epoch:1002\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064909\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012019\n",
      "Epoch:1003\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.094983\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011538\n",
      "Epoch:1004\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.157531\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012701\n",
      "Epoch:1005\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051398\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013354\n",
      "Epoch:1006\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046270\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013116\n",
      "Epoch:1007\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015890\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013061\n",
      "Epoch:1008\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.134151\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012180\n",
      "Epoch:1009\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050041\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012481\n",
      "Epoch:1010\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.095481\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013235\n",
      "Epoch:1011\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078023\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011851\n",
      "Epoch:1012\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050516\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010895\n",
      "Epoch:1013\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020237\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011041\n",
      "Epoch:1014\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.104043\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011600\n",
      "Epoch:1015\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.066630\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.014290\n",
      "Epoch:1016\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057180\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012728\n",
      "Epoch:1017\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051407\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011515\n",
      "Epoch:1018\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.150558\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010591\n",
      "Epoch:1019\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016524\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011402\n",
      "Epoch:1020\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.021794\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012524\n",
      "Epoch:1021\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.038461\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011885\n",
      "Epoch:1022\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052148\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011405\n",
      "Epoch:1023\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019787\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011597\n",
      "Epoch:1024\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.074624\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012177\n",
      "Epoch:1025\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054820\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011821\n",
      "Epoch:1026\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.086012\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011197\n",
      "Epoch:1027\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.073448\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011897\n",
      "Epoch:1028\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.129057\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011472\n",
      "Epoch:1029\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048439\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012556\n",
      "Epoch:1030\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.152721\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012676\n",
      "Epoch:1031\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034236\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011937\n",
      "Epoch:1032\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016741\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011335\n",
      "Epoch:1033\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.144459\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011043\n",
      "Epoch:1034\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.027015\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012786\n",
      "Epoch:1035\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.056441\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1036\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.085012\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011633\n",
      "Epoch:1037\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127551\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011424\n",
      "Epoch:1038\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012765\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012457\n",
      "Epoch:1039\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038015\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012625\n",
      "Epoch:1040\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.206999\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011228\n",
      "Epoch:1041\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057277\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012516\n",
      "Epoch:1042\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061489\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011923\n",
      "Epoch:1043\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030125\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011219\n",
      "Epoch:1044\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046811\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010827\n",
      "Epoch:1045\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.161099\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010686\n",
      "Epoch:1046\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.140364\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012182\n",
      "Epoch:1047\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.160991\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012581\n",
      "Epoch:1048\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.041240\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012810\n",
      "Epoch:1049\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.107021\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012447\n",
      "Epoch:1050\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059942\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011822\n",
      "Epoch:1051\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067039\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011138\n",
      "Epoch:1052\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059851\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011792\n",
      "Epoch:1053\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044997\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011691\n",
      "Epoch:1054\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048000\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011986\n",
      "Epoch:1055\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038458\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011129\n",
      "Epoch:1056\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064862\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012143\n",
      "Epoch:1057\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.161317\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011708\n",
      "Epoch:1058\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.058606\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012258\n",
      "Epoch:1059\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.163888\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010556\n",
      "Epoch:1060\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.063647\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012555\n",
      "Epoch:1061\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036376\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012057\n",
      "Epoch:1062\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.063653\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011867\n",
      "Epoch:1063\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035718\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011116\n",
      "Epoch:1064\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022361\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010347\n",
      "Epoch:1065\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044932\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010326\n",
      "Epoch:1066\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063827\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010879\n",
      "Epoch:1067\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060541\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011785\n",
      "Epoch:1068\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.093127\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012240\n",
      "Epoch:1069\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021460\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012045\n",
      "Epoch:1070\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054717\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010811\n",
      "Epoch:1071\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032586\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010427\n",
      "Epoch:1072\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.120167\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010710\n",
      "Epoch:1073\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037335\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012365\n",
      "Epoch:1074\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.116386\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012862\n",
      "Epoch:1075\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040770\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010899\n",
      "Epoch:1076\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.149722\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009953\n",
      "Epoch:1077\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.070215\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011377\n",
      "Epoch:1078\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.119789\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012642\n",
      "Epoch:1079\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032841\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012084\n",
      "Epoch:1080\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051412\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011102\n",
      "Epoch:1081\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.117459\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010086\n",
      "Epoch:1082\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068624\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011255\n",
      "Epoch:1083\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.071753\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011894\n",
      "Epoch:1084\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.083577\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012445\n",
      "Epoch:1085\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034700\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011607\n",
      "Epoch:1086\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064803\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010916\n",
      "Epoch:1087\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.052786\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010317\n",
      "Epoch:1088\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.021094\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010677\n",
      "Epoch:1089\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045407\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010896\n",
      "Epoch:1090\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.058945\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011278\n",
      "Epoch:1091\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068448\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010951\n",
      "Epoch:1092\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.067420\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011101\n",
      "Epoch:1093\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.144210\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010131\n",
      "Epoch:1094\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039232\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012094\n",
      "Epoch:1095\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127279\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012856\n",
      "Epoch:1096\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042939\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012046\n",
      "Epoch:1097\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053459\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012458\n",
      "Epoch:1098\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.047458\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009761\n",
      "Epoch:1099\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053019\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010819\n",
      "Epoch:1100\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.171223\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011491\n",
      "Epoch:1101\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.061595\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013567\n",
      "Epoch:1102\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062315\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011309\n",
      "Epoch:1103\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023072\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010268\n",
      "Epoch:1104\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.154094\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010401\n",
      "Epoch:1105\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031799\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012011\n",
      "Epoch:1106\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.063025\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011308\n",
      "Epoch:1107\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.207071\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010424\n",
      "Epoch:1108\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.059329\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012637\n",
      "Epoch:1109\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.136318\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011331\n",
      "Epoch:1110\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.008927\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010523\n",
      "Epoch:1111\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.140124\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010549\n",
      "Epoch:1112\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028634\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012423\n",
      "Epoch:1113\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039628\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011667\n",
      "Epoch:1114\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067225\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010568\n",
      "Epoch:1115\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015493\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010596\n",
      "Epoch:1116\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053573\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011279\n",
      "Epoch:1117\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039365\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010406\n",
      "Epoch:1118\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029918\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011272\n",
      "Epoch:1119\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054299\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011237\n",
      "Epoch:1120\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.136354\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010512\n",
      "Epoch:1121\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019604\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011516\n",
      "Epoch:1122\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.109885\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010832\n",
      "Epoch:1123\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.144924\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010887\n",
      "Epoch:1124\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.051974\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011219\n",
      "Epoch:1125\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.076054\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011148\n",
      "Epoch:1126\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019486\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009566\n",
      "Epoch:1127\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060377\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010872\n",
      "Epoch:1128\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051892\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011068\n",
      "Epoch:1129\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.055688\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010709\n",
      "Epoch:1130\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.018710\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010421\n",
      "Epoch:1131\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.101797\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010192\n",
      "Epoch:1132\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.008776\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010359\n",
      "Epoch:1133\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.194430\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010510\n",
      "Epoch:1134\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032930\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010690\n",
      "Epoch:1135\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027355\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011180\n",
      "Epoch:1136\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056442\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011089\n",
      "Epoch:1137\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062355\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009986\n",
      "Epoch:1138\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026252\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010372\n",
      "Epoch:1139\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068619\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010841\n",
      "Epoch:1140\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033609\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010192\n",
      "Epoch:1141\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051234\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010249\n",
      "Epoch:1142\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.021894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010341\n",
      "Epoch:1143\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023966\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010913\n",
      "Epoch:1144\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.169853\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009190\n",
      "Epoch:1145\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073465\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010271\n",
      "Epoch:1146\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137796\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011781\n",
      "Epoch:1147\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072253\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.013162\n",
      "Epoch:1148\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062638\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010526\n",
      "Epoch:1149\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034122\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009735\n",
      "Epoch:1150\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039550\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009447\n",
      "Epoch:1151\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053246\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009424\n",
      "Epoch:1152\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.050140\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010760\n",
      "Epoch:1153\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066354\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011422\n",
      "Epoch:1154\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066192\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010195\n",
      "Epoch:1155\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034094\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010091\n",
      "Epoch:1156\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.119206\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009549\n",
      "Epoch:1157\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013541\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010171\n",
      "Epoch:1158\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031667\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011487\n",
      "Epoch:1159\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039608\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009636\n",
      "Epoch:1160\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.091335\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009734\n",
      "Epoch:1161\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.079717\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011853\n",
      "Epoch:1162\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059474\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011354\n",
      "Epoch:1163\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.120298\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009032\n",
      "Epoch:1164\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048867\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009641\n",
      "Epoch:1165\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.058980\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010718\n",
      "Epoch:1166\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059446\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010581\n",
      "Epoch:1167\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.133344\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010164\n",
      "Epoch:1168\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056687\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010184\n",
      "Epoch:1169\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.110961\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009543\n",
      "Epoch:1170\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.130658\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010293\n",
      "Epoch:1171\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.091700\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011644\n",
      "Epoch:1172\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053175\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010367\n",
      "Epoch:1173\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.048089\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010666\n",
      "Epoch:1174\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050751\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010275\n",
      "Epoch:1175\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.174865\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009637\n",
      "Epoch:1176\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021709\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011090\n",
      "Epoch:1177\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.085385\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010376\n",
      "Epoch:1178\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059085\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009579\n",
      "Epoch:1179\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.163827\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008458\n",
      "Epoch:1180\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027460\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010548\n",
      "Epoch:1181\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.157440\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010058\n",
      "Epoch:1182\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059768\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011209\n",
      "Epoch:1183\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025015\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009791\n",
      "Epoch:1184\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.066924\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009990\n",
      "Epoch:1185\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.094329\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009063\n",
      "Epoch:1186\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045714\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010317\n",
      "Epoch:1187\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.080732\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009922\n",
      "Epoch:1188\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036655\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010331\n",
      "Epoch:1189\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.237502\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009094\n",
      "Epoch:1190\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028810\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011557\n",
      "Epoch:1191\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039546\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010945\n",
      "Epoch:1192\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049854\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009286\n",
      "Epoch:1193\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.067248\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008955\n",
      "Epoch:1194\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.166597\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009055\n",
      "Epoch:1195\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.007268\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009862\n",
      "Epoch:1196\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127677\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010120\n",
      "Epoch:1197\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035727\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011103\n",
      "Epoch:1198\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039486\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009804\n",
      "Epoch:1199\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068070\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009389\n",
      "Epoch:1200\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057630\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009487\n",
      "Epoch:1201\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.175189\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009535\n",
      "Epoch:1202\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050648\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.012238\n",
      "Epoch:1203\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054032\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010777\n",
      "Epoch:1204\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.116970\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010230\n",
      "Epoch:1205\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016025\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008993\n",
      "Epoch:1206\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.152977\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009585\n",
      "Epoch:1207\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034552\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009952\n",
      "Epoch:1208\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.029033\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009865\n",
      "Epoch:1209\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024605\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009434\n",
      "Epoch:1210\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051601\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010160\n",
      "Epoch:1211\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042028\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009707\n",
      "Epoch:1212\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027520\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009935\n",
      "Epoch:1213\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.141632\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008537\n",
      "Epoch:1214\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042233\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009120\n",
      "Epoch:1215\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064440\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010446\n",
      "Epoch:1216\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.164355\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010563\n",
      "Epoch:1217\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048198\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010193\n",
      "Epoch:1218\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049940\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009548\n",
      "Epoch:1219\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.135676\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008466\n",
      "Epoch:1220\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.007062\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009827\n",
      "Epoch:1221\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035582\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010228\n",
      "Epoch:1222\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.117713\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009105\n",
      "Epoch:1223\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.173019\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009506\n",
      "Epoch:1224\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.165188\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011033\n",
      "Epoch:1225\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.157274\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010039\n",
      "Epoch:1226\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045272\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010645\n",
      "Epoch:1227\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046049\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009126\n",
      "Epoch:1228\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.176997\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008408\n",
      "Epoch:1229\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.052220\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010660\n",
      "Epoch:1230\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.163111\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010398\n",
      "Epoch:1231\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.165897\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010035\n",
      "Epoch:1232\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.055748\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010673\n",
      "Epoch:1233\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.137965\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009889\n",
      "Epoch:1234\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.052835\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008187\n",
      "Epoch:1235\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.220003\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007995\n",
      "Epoch:1236\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.108889\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010446\n",
      "Epoch:1237\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.010236\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010315\n",
      "Epoch:1238\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.142919\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008627\n",
      "Epoch:1239\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062826\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1240\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.072667\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009446\n",
      "Epoch:1241\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.075456\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009336\n",
      "Epoch:1242\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.082980\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008811\n",
      "Epoch:1243\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050535\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009923\n",
      "Epoch:1244\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056437\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009472\n",
      "Epoch:1245\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.181250\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008062\n",
      "Epoch:1246\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.131402\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009471\n",
      "Epoch:1247\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035504\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009767\n",
      "Epoch:1248\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.060628\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009212\n",
      "Epoch:1249\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061080\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008816\n",
      "Epoch:1250\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015296\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010086\n",
      "Epoch:1251\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046667\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009710\n",
      "Epoch:1252\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049162\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009068\n",
      "Epoch:1253\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037476\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008411\n",
      "Epoch:1254\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045284\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009036\n",
      "Epoch:1255\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020555\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010685\n",
      "Epoch:1256\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.121062\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009154\n",
      "Epoch:1257\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054368\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009413\n",
      "Epoch:1258\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022162\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008448\n",
      "Epoch:1259\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053430\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008495\n",
      "Epoch:1260\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031230\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008619\n",
      "Epoch:1261\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027247\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009261\n",
      "Epoch:1262\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050425\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008575\n",
      "Epoch:1263\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.081795\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008923\n",
      "Epoch:1264\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031665\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008341\n",
      "Epoch:1265\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059167\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009130\n",
      "Epoch:1266\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.065794\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009654\n",
      "Epoch:1267\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033217\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008452\n",
      "Epoch:1268\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.138300\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009119\n",
      "Epoch:1269\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018445\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010851\n",
      "Epoch:1270\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051807\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009892\n",
      "Epoch:1271\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.106729\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008691\n",
      "Epoch:1272\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052564\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007784\n",
      "Epoch:1273\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.129667\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008320\n",
      "Epoch:1274\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045530\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010080\n",
      "Epoch:1275\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064258\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010049\n",
      "Epoch:1276\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013535\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008545\n",
      "Epoch:1277\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056989\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008231\n",
      "Epoch:1278\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.131002\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008727\n",
      "Epoch:1279\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.077739\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011156\n",
      "Epoch:1280\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053749\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008806\n",
      "Epoch:1281\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010532\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008313\n",
      "Epoch:1282\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.112344\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008960\n",
      "Epoch:1283\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.127483\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009319\n",
      "Epoch:1284\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026469\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009365\n",
      "Epoch:1285\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.116620\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009106\n",
      "Epoch:1286\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.142665\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008811\n",
      "Epoch:1287\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035824\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009713\n",
      "Epoch:1288\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.203988\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008996\n",
      "Epoch:1289\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.071538\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.011306\n",
      "Epoch:1290\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.094921\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009264\n",
      "Epoch:1291\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019307\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007641\n",
      "Epoch:1292\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.173246\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007544\n",
      "Epoch:1293\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.025710\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009231\n",
      "Epoch:1294\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.029710\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009865\n",
      "Epoch:1295\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056311\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009463\n",
      "Epoch:1296\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040656\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009668\n",
      "Epoch:1297\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.142771\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008990\n",
      "Epoch:1298\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053411\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009177\n",
      "Epoch:1299\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.103156\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009104\n",
      "Epoch:1300\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053653\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007471\n",
      "Epoch:1301\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063019\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008092\n",
      "Epoch:1302\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068745\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009103\n",
      "Epoch:1303\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073042\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008527\n",
      "Epoch:1304\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.172528\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007666\n",
      "Epoch:1305\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.081975\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009511\n",
      "Epoch:1306\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048405\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008867\n",
      "Epoch:1307\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044712\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008313\n",
      "Epoch:1308\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049241\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009170\n",
      "Epoch:1309\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039461\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009056\n",
      "Epoch:1310\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.162175\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007919\n",
      "Epoch:1311\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.098738\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009686\n",
      "Epoch:1312\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.164448\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008502\n",
      "Epoch:1313\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.055483\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009352\n",
      "Epoch:1314\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.059943\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008056\n",
      "Epoch:1315\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.078694\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008648\n",
      "Epoch:1316\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010996\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008354\n",
      "Epoch:1317\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031367\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008498\n",
      "Epoch:1318\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.190455\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008092\n",
      "Epoch:1319\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.049481\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.010179\n",
      "Epoch:1320\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.125527\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008771\n",
      "Epoch:1321\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068958\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008842\n",
      "Epoch:1322\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047341\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008628\n",
      "Epoch:1323\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048235\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008205\n",
      "Epoch:1324\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073128\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007784\n",
      "Epoch:1325\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019848\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009643\n",
      "Epoch:1326\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.150564\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009265\n",
      "Epoch:1327\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066572\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009584\n",
      "Epoch:1328\n",
      "Training...\n",
      " Accuracy:99.166667 loss:0.054954\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008003\n",
      "Epoch:1329\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025966\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007996\n",
      "Epoch:1330\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.061173\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008404\n",
      "Epoch:1331\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046856\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008879\n",
      "Epoch:1332\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023785\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009011\n",
      "Epoch:1333\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060986\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008470\n",
      "Epoch:1334\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035472\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007882\n",
      "Epoch:1335\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018388\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007856\n",
      "Epoch:1336\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.077841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007938\n",
      "Epoch:1337\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044964\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009394\n",
      "Epoch:1338\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.056028\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009275\n",
      "Epoch:1339\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.126635\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009050\n",
      "Epoch:1340\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.134591\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009149\n",
      "Epoch:1341\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048306\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008582\n",
      "Epoch:1342\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043969\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009023\n",
      "Epoch:1343\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.086977\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007862\n",
      "Epoch:1344\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039255\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008614\n",
      "Epoch:1345\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.150077\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008634\n",
      "Epoch:1346\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.080301\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009098\n",
      "Epoch:1347\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.058187\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008235\n",
      "Epoch:1348\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047174\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007723\n",
      "Epoch:1349\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.136813\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007581\n",
      "Epoch:1350\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.067833\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008717\n",
      "Epoch:1351\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.111788\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008404\n",
      "Epoch:1352\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.124434\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008689\n",
      "Epoch:1353\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.112809\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008849\n",
      "Epoch:1354\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019974\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009648\n",
      "Epoch:1355\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054602\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008875\n",
      "Epoch:1356\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.122735\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007573\n",
      "Epoch:1357\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050453\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007758\n",
      "Epoch:1358\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037625\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009300\n",
      "Epoch:1359\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.167804\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008427\n",
      "Epoch:1360\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137740\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007620\n",
      "Epoch:1361\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030794\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007922\n",
      "Epoch:1362\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044555\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008555\n",
      "Epoch:1363\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047702\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009260\n",
      "Epoch:1364\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.152520\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007747\n",
      "Epoch:1365\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.135269\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008283\n",
      "Epoch:1366\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.098185\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008297\n",
      "Epoch:1367\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032020\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009382\n",
      "Epoch:1368\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062951\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009725\n",
      "Epoch:1369\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022033\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007763\n",
      "Epoch:1370\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.137968\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007282\n",
      "Epoch:1371\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.077348\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007821\n",
      "Epoch:1372\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037948\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008970\n",
      "Epoch:1373\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.105403\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009227\n",
      "Epoch:1374\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022719\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007379\n",
      "Epoch:1375\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.172269\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007244\n",
      "Epoch:1376\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.053196\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009700\n",
      "Epoch:1377\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047805\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008333\n",
      "Epoch:1378\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066325\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008479\n",
      "Epoch:1379\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.009356\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007713\n",
      "Epoch:1380\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.212251\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007481\n",
      "Epoch:1381\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.084447\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009382\n",
      "Epoch:1382\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.087228\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008419\n",
      "Epoch:1383\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.171344\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007218\n",
      "Epoch:1384\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.060637\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008086\n",
      "Epoch:1385\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030859\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007736\n",
      "Epoch:1386\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069202\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007543\n",
      "Epoch:1387\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078528\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008010\n",
      "Epoch:1388\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036760\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007604\n",
      "Epoch:1389\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037419\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007217\n",
      "Epoch:1390\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022582\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007850\n",
      "Epoch:1391\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.042431\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008255\n",
      "Epoch:1392\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.078256\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008288\n",
      "Epoch:1393\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.060978\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007766\n",
      "Epoch:1394\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.009482\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007341\n",
      "Epoch:1395\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059623\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007486\n",
      "Epoch:1396\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.164031\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008147\n",
      "Epoch:1397\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.098639\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009604\n",
      "Epoch:1398\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025229\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007540\n",
      "Epoch:1399\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049860\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007715\n",
      "Epoch:1400\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.075271\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007354\n",
      "Epoch:1401\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.076987\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007043\n",
      "Epoch:1402\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.036623\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008863\n",
      "Epoch:1403\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061559\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008248\n",
      "Epoch:1404\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.115001\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006976\n",
      "Epoch:1405\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020459\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007709\n",
      "Epoch:1406\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019420\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008465\n",
      "Epoch:1407\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048102\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008525\n",
      "Epoch:1408\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066020\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008219\n",
      "Epoch:1409\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.140171\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007067\n",
      "Epoch:1410\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.046182\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008636\n",
      "Epoch:1411\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.146611\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007189\n",
      "Epoch:1412\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043612\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007728\n",
      "Epoch:1413\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053507\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009130\n",
      "Epoch:1414\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.070673\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008303\n",
      "Epoch:1415\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.151507\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007595\n",
      "Epoch:1416\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.083445\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007819\n",
      "Epoch:1417\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054528\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008433\n",
      "Epoch:1418\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061255\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007890\n",
      "Epoch:1419\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044125\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007173\n",
      "Epoch:1420\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.056964\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007360\n",
      "Epoch:1421\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046710\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007593\n",
      "Epoch:1422\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059554\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007932\n",
      "Epoch:1423\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.181700\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007931\n",
      "Epoch:1424\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.172994\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008198\n",
      "Epoch:1425\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.079971\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008804\n",
      "Epoch:1426\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041794\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007339\n",
      "Epoch:1427\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.060056\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007390\n",
      "Epoch:1428\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.007903\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007898\n",
      "Epoch:1429\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.148785\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008224\n",
      "Epoch:1430\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052367\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008256\n",
      "Epoch:1431\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.162341\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008127\n",
      "Epoch:1432\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046927\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007860\n",
      "Epoch:1433\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011320\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008401\n",
      "Epoch:1434\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047602\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1435\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028177\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007635\n",
      "Epoch:1436\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046306\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007248\n",
      "Epoch:1437\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.031564\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007486\n",
      "Epoch:1438\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.131611\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007538\n",
      "Epoch:1439\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.014715\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008155\n",
      "Epoch:1440\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050911\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007929\n",
      "Epoch:1441\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.146482\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007959\n",
      "Epoch:1442\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044891\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007567\n",
      "Epoch:1443\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.164725\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007480\n",
      "Epoch:1444\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.139839\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007317\n",
      "Epoch:1445\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024976\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007851\n",
      "Epoch:1446\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.047031\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008233\n",
      "Epoch:1447\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039097\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008906\n",
      "Epoch:1448\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047672\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007643\n",
      "Epoch:1449\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020009\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007511\n",
      "Epoch:1450\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038345\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007190\n",
      "Epoch:1451\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.149011\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006609\n",
      "Epoch:1452\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.068383\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007116\n",
      "Epoch:1453\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.145219\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007571\n",
      "Epoch:1454\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040080\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009042\n",
      "Epoch:1455\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.124777\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008190\n",
      "Epoch:1456\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062744\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007604\n",
      "Epoch:1457\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.154311\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006528\n",
      "Epoch:1458\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.180927\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006633\n",
      "Epoch:1459\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.143227\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008830\n",
      "Epoch:1460\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.075301\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009051\n",
      "Epoch:1461\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054137\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007571\n",
      "Epoch:1462\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053006\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007613\n",
      "Epoch:1463\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.089291\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006798\n",
      "Epoch:1464\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.075487\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007866\n",
      "Epoch:1465\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.126639\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006927\n",
      "Epoch:1466\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024510\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006908\n",
      "Epoch:1467\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026190\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007079\n",
      "Epoch:1468\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046362\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007950\n",
      "Epoch:1469\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.067321\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007748\n",
      "Epoch:1470\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.131880\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006587\n",
      "Epoch:1471\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040685\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007593\n",
      "Epoch:1472\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137381\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008483\n",
      "Epoch:1473\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.157427\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007549\n",
      "Epoch:1474\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.131191\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007605\n",
      "Epoch:1475\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018268\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007995\n",
      "Epoch:1476\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.149923\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007809\n",
      "Epoch:1477\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.138412\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007358\n",
      "Epoch:1478\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043071\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008073\n",
      "Epoch:1479\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.007473\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007033\n",
      "Epoch:1480\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.055350\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006601\n",
      "Epoch:1481\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042264\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006964\n",
      "Epoch:1482\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019946\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007926\n",
      "Epoch:1483\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.005438\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007042\n",
      "Epoch:1484\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054066\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007322\n",
      "Epoch:1485\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053369\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007997\n",
      "Epoch:1486\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025606\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007323\n",
      "Epoch:1487\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.157403\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006520\n",
      "Epoch:1488\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024704\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007786\n",
      "Epoch:1489\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046115\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007607\n",
      "Epoch:1490\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.148469\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006901\n",
      "Epoch:1491\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050170\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007822\n",
      "Epoch:1492\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040673\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007969\n",
      "Epoch:1493\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034395\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006973\n",
      "Epoch:1494\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.081765\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006880\n",
      "Epoch:1495\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037657\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007144\n",
      "Epoch:1496\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.108504\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007081\n",
      "Epoch:1497\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.037256\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006661\n",
      "Epoch:1498\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.147234\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007066\n",
      "Epoch:1499\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049902\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008442\n",
      "Epoch:1500\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.112027\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007781\n",
      "Epoch:1501\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068025\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006466\n",
      "Epoch:1502\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.053233\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006699\n",
      "Epoch:1503\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.083627\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006703\n",
      "Epoch:1504\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025804\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007489\n",
      "Epoch:1505\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054413\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007352\n",
      "Epoch:1506\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042100\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007671\n",
      "Epoch:1507\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.108246\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007757\n",
      "Epoch:1508\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.143927\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006445\n",
      "Epoch:1509\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.179460\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006660\n",
      "Epoch:1510\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019073\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007659\n",
      "Epoch:1511\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026096\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007236\n",
      "Epoch:1512\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011435\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006442\n",
      "Epoch:1513\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.158521\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006503\n",
      "Epoch:1514\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062871\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007920\n",
      "Epoch:1515\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.056808\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007796\n",
      "Epoch:1516\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.126179\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006298\n",
      "Epoch:1517\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.072227\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006628\n",
      "Epoch:1518\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.006303\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008694\n",
      "Epoch:1519\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.133984\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008139\n",
      "Epoch:1520\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072369\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007496\n",
      "Epoch:1521\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046956\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006518\n",
      "Epoch:1522\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.060408\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006251\n",
      "Epoch:1523\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.179588\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006595\n",
      "Epoch:1524\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025925\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007946\n",
      "Epoch:1525\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059860\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007982\n",
      "Epoch:1526\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036738\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007416\n",
      "Epoch:1527\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045131\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007432\n",
      "Epoch:1528\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035964\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006854\n",
      "Epoch:1529\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069450\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007504\n",
      "Epoch:1530\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017596\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007537\n",
      "Epoch:1531\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040604\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006885\n",
      "Epoch:1532\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.094869\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007114\n",
      "Epoch:1533\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068144\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008488\n",
      "Epoch:1534\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.125128\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006971\n",
      "Epoch:1535\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.188556\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007596\n",
      "Epoch:1536\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.133629\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1537\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033243\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006819\n",
      "Epoch:1538\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048265\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006685\n",
      "Epoch:1539\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064835\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006448\n",
      "Epoch:1540\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137951\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006289\n",
      "Epoch:1541\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034227\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007156\n",
      "Epoch:1542\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.082617\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006744\n",
      "Epoch:1543\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027034\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007309\n",
      "Epoch:1544\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016483\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006776\n",
      "Epoch:1545\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.043966\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006964\n",
      "Epoch:1546\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057091\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007845\n",
      "Epoch:1547\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.092776\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006989\n",
      "Epoch:1548\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.148081\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006753\n",
      "Epoch:1549\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038358\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007625\n",
      "Epoch:1550\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.144180\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006859\n",
      "Epoch:1551\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.051635\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007856\n",
      "Epoch:1552\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.079939\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008121\n",
      "Epoch:1553\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.084622\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006769\n",
      "Epoch:1554\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.044439\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005791\n",
      "Epoch:1555\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018199\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007100\n",
      "Epoch:1556\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.120951\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007196\n",
      "Epoch:1557\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020757\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007062\n",
      "Epoch:1558\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.146091\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006366\n",
      "Epoch:1559\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029768\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007519\n",
      "Epoch:1560\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.052303\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006902\n",
      "Epoch:1561\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.010607\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007465\n",
      "Epoch:1562\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036662\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006403\n",
      "Epoch:1563\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011224\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006098\n",
      "Epoch:1564\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.067863\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006699\n",
      "Epoch:1565\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.184237\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006469\n",
      "Epoch:1566\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.140468\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008167\n",
      "Epoch:1567\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020558\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008664\n",
      "Epoch:1568\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.092346\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007172\n",
      "Epoch:1569\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041912\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005763\n",
      "Epoch:1570\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.126519\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006081\n",
      "Epoch:1571\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.031677\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007242\n",
      "Epoch:1572\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.028085\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007559\n",
      "Epoch:1573\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127119\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006756\n",
      "Epoch:1574\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047154\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007709\n",
      "Epoch:1575\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.155644\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006399\n",
      "Epoch:1576\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033894\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007269\n",
      "Epoch:1577\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.151011\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007241\n",
      "Epoch:1578\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038919\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006966\n",
      "Epoch:1579\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038358\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006496\n",
      "Epoch:1580\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028911\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006354\n",
      "Epoch:1581\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.207113\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006656\n",
      "Epoch:1582\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033403\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.009002\n",
      "Epoch:1583\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.087910\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008198\n",
      "Epoch:1584\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021146\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006797\n",
      "Epoch:1585\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.155012\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006553\n",
      "Epoch:1586\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.066348\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006682\n",
      "Epoch:1587\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064937\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006652\n",
      "Epoch:1588\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068495\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006905\n",
      "Epoch:1589\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030754\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006160\n",
      "Epoch:1590\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.158358\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006173\n",
      "Epoch:1591\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048346\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007386\n",
      "Epoch:1592\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.065958\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007713\n",
      "Epoch:1593\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.149583\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006542\n",
      "Epoch:1594\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.085076\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006902\n",
      "Epoch:1595\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030997\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006976\n",
      "Epoch:1596\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.133614\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006269\n",
      "Epoch:1597\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035633\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007299\n",
      "Epoch:1598\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.114077\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007694\n",
      "Epoch:1599\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.115277\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007137\n",
      "Epoch:1600\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043441\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006458\n",
      "Epoch:1601\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043688\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006328\n",
      "Epoch:1602\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.083331\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006796\n",
      "Epoch:1603\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.189771\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006063\n",
      "Epoch:1604\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022021\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007117\n",
      "Epoch:1605\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.161356\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006620\n",
      "Epoch:1606\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030281\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007075\n",
      "Epoch:1607\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027586\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.008136\n",
      "Epoch:1608\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059233\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007464\n",
      "Epoch:1609\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.066608\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005921\n",
      "Epoch:1610\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064414\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006012\n",
      "Epoch:1611\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.076422\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007204\n",
      "Epoch:1612\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051389\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007101\n",
      "Epoch:1613\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.001987\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006939\n",
      "Epoch:1614\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013546\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006406\n",
      "Epoch:1615\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051918\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006182\n",
      "Epoch:1616\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057652\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006206\n",
      "Epoch:1617\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.120664\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006023\n",
      "Epoch:1618\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042458\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006732\n",
      "Epoch:1619\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048339\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007717\n",
      "Epoch:1620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      " Accuracy:98.333333 loss:0.057388\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007484\n",
      "Epoch:1621\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.055523\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006402\n",
      "Epoch:1622\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.122514\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005747\n",
      "Epoch:1623\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.057058\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006744\n",
      "Epoch:1624\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.120717\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006952\n",
      "Epoch:1625\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.148790\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007581\n",
      "Epoch:1626\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016268\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006670\n",
      "Epoch:1627\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057846\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006350\n",
      "Epoch:1628\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048129\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005967\n",
      "Epoch:1629\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037720\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006383\n",
      "Epoch:1630\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.175844\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006016\n",
      "Epoch:1631\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040116\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006729\n",
      "Epoch:1632\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044079\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006987\n",
      "Epoch:1633\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016270\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007332\n",
      "Epoch:1634\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025702\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006560\n",
      "Epoch:1635\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.078195\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006021\n",
      "Epoch:1636\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.005870\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005823\n",
      "Epoch:1637\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.075481\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006396\n",
      "Epoch:1638\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054023\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006550\n",
      "Epoch:1639\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.112700\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006369\n",
      "Epoch:1640\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054273\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007369\n",
      "Epoch:1641\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045383\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006647\n",
      "Epoch:1642\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025571\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006067\n",
      "Epoch:1643\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.086791\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005724\n",
      "Epoch:1644\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013544\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006505\n",
      "Epoch:1645\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.128019\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006618\n",
      "Epoch:1646\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.152439\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006138\n",
      "Epoch:1647\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.095071\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007446\n",
      "Epoch:1648\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039066\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006233\n",
      "Epoch:1649\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.089550\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005776\n",
      "Epoch:1650\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.162487\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006640\n",
      "Epoch:1651\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.123820\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007191\n",
      "Epoch:1652\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037802\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006877\n",
      "Epoch:1653\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.048297\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006426\n",
      "Epoch:1654\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033326\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006986\n",
      "Epoch:1655\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016610\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007803\n",
      "Epoch:1656\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.122517\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006564\n",
      "Epoch:1657\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.124288\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006036\n",
      "Epoch:1658\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026187\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006828\n",
      "Epoch:1659\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035015\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006717\n",
      "Epoch:1660\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.065685\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006382\n",
      "Epoch:1661\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031495\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006567\n",
      "Epoch:1662\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044606\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005984\n",
      "Epoch:1663\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036413\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005638\n",
      "Epoch:1664\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018138\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005498\n",
      "Epoch:1665\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044617\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006163\n",
      "Epoch:1666\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045795\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007188\n",
      "Epoch:1667\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.091008\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006018\n",
      "Epoch:1668\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042950\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006298\n",
      "Epoch:1669\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.113764\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005839\n",
      "Epoch:1670\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046483\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006824\n",
      "Epoch:1671\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.004540\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006630\n",
      "Epoch:1672\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.165091\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005896\n",
      "Epoch:1673\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066689\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007048\n",
      "Epoch:1674\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.160444\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005796\n",
      "Epoch:1675\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027673\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006912\n",
      "Epoch:1676\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.011906\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006172\n",
      "Epoch:1677\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023780\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006442\n",
      "Epoch:1678\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063152\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006846\n",
      "Epoch:1679\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.094520\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006055\n",
      "Epoch:1680\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033680\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005317\n",
      "Epoch:1681\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012954\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005418\n",
      "Epoch:1682\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.169345\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006517\n",
      "Epoch:1683\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.158505\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006959\n",
      "Epoch:1684\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051991\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007046\n",
      "Epoch:1685\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048444\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005963\n",
      "Epoch:1686\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.007251\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006497\n",
      "Epoch:1687\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.078036\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006633\n",
      "Epoch:1688\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021495\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006627\n",
      "Epoch:1689\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032064\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005913\n",
      "Epoch:1690\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.142172\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005882\n",
      "Epoch:1691\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013304\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006345\n",
      "Epoch:1692\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011787\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006704\n",
      "Epoch:1693\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.153351\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006336\n",
      "Epoch:1694\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069489\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006395\n",
      "Epoch:1695\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019372\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005809\n",
      "Epoch:1696\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.186563\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005476\n",
      "Epoch:1697\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.127141\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006137\n",
      "Epoch:1698\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044284\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006632\n",
      "Epoch:1699\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031752\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006762\n",
      "Epoch:1700\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040098\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005664\n",
      "Epoch:1701\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.058693\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006439\n",
      "Epoch:1702\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.009667\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006496\n",
      "Epoch:1703\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028655\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006511\n",
      "Epoch:1704\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032557\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006334\n",
      "Epoch:1705\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.134554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005371\n",
      "Epoch:1706\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068082\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006379\n",
      "Epoch:1707\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050871\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006765\n",
      "Epoch:1708\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.109224\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006645\n",
      "Epoch:1709\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.005477\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006271\n",
      "Epoch:1710\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053141\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006696\n",
      "Epoch:1711\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047664\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005995\n",
      "Epoch:1712\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.163552\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005951\n",
      "Epoch:1713\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054629\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006954\n",
      "Epoch:1714\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.140982\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006217\n",
      "Epoch:1715\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.136789\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006625\n",
      "Epoch:1716\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.115489\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005984\n",
      "Epoch:1717\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.018035\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006551\n",
      "Epoch:1718\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.156625\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006599\n",
      "Epoch:1719\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020450\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006425\n",
      "Epoch:1720\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050614\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005662\n",
      "Epoch:1721\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.049388\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005558\n",
      "Epoch:1722\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.015026\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006557\n",
      "Epoch:1723\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053494\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006961\n",
      "Epoch:1724\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059563\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005445\n",
      "Epoch:1725\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044889\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005346\n",
      "Epoch:1726\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.107356\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006335\n",
      "Epoch:1727\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053043\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007407\n",
      "Epoch:1728\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.087370\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006489\n",
      "Epoch:1729\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.163853\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005550\n",
      "Epoch:1730\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022092\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006762\n",
      "Epoch:1731\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.125199\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006226\n",
      "Epoch:1732\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038374\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005857\n",
      "Epoch:1733\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.115208\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006237\n",
      "Epoch:1734\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.065112\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006844\n",
      "Epoch:1735\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.121273\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006682\n",
      "Epoch:1736\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046821\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005239\n",
      "Epoch:1737\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.124980\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005690\n",
      "Epoch:1738\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.149191\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005898\n",
      "Epoch:1739\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049146\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006774\n",
      "Epoch:1740\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030427\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005944\n",
      "Epoch:1741\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.133167\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005899\n",
      "Epoch:1742\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.000794\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006183\n",
      "Epoch:1743\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.160124\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005741\n",
      "Epoch:1744\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.058578\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007067\n",
      "Epoch:1745\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.009109\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006262\n",
      "Epoch:1746\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053867\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005732\n",
      "Epoch:1747\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048178\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005899\n",
      "Epoch:1748\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013464\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006476\n",
      "Epoch:1749\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057457\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006654\n",
      "Epoch:1750\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057251\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006218\n",
      "Epoch:1751\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010366\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005294\n",
      "Epoch:1752\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022641\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005356\n",
      "Epoch:1753\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010130\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005588\n",
      "Epoch:1754\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.129182\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005424\n",
      "Epoch:1755\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.172387\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006785\n",
      "Epoch:1756\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026875\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007509\n",
      "Epoch:1757\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057891\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005813\n",
      "Epoch:1758\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026504\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005897\n",
      "Epoch:1759\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022470\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005620\n",
      "Epoch:1760\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012814\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005553\n",
      "Epoch:1761\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042893\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006425\n",
      "Epoch:1762\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073634\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005826\n",
      "Epoch:1763\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038273\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005860\n",
      "Epoch:1764\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056645\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006348\n",
      "Epoch:1765\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.142339\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005750\n",
      "Epoch:1766\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.212122\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005675\n",
      "Epoch:1767\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.108340\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007698\n",
      "Epoch:1768\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.012807\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005371\n",
      "Epoch:1769\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027091\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005331\n",
      "Epoch:1770\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.069429\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005535\n",
      "Epoch:1771\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042126\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005925\n",
      "Epoch:1772\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.145940\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005560\n",
      "Epoch:1773\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049114\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006013\n",
      "Epoch:1774\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.086977\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005494\n",
      "Epoch:1775\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.060761\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006480\n",
      "Epoch:1776\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050751\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006154\n",
      "Epoch:1777\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028231\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006346\n",
      "Epoch:1778\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069985\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006246\n",
      "Epoch:1779\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012225\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005328\n",
      "Epoch:1780\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.129450\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005178\n",
      "Epoch:1781\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.122589\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006686\n",
      "Epoch:1782\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.007359\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005420\n",
      "Epoch:1783\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.039360\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005387\n",
      "Epoch:1784\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056705\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006090\n",
      "Epoch:1785\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032344\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005808\n",
      "Epoch:1786\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012620\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005278\n",
      "Epoch:1787\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.096223\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005168\n",
      "Epoch:1788\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.061029\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006333\n",
      "Epoch:1789\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.118518\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006159\n",
      "Epoch:1790\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037755\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006171\n",
      "Epoch:1791\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.114087\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005769\n",
      "Epoch:1792\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044315\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005787\n",
      "Epoch:1793\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.058654\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005450\n",
      "Epoch:1794\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.116817\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005066\n",
      "Epoch:1795\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.007335\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005894\n",
      "Epoch:1796\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035245\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006071\n",
      "Epoch:1797\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127104\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006010\n",
      "Epoch:1798\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030964\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007306\n",
      "Epoch:1799\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.090515\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006178\n",
      "Epoch:1800\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.014324\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004877\n",
      "Epoch:1801\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026471\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005293\n",
      "Epoch:1802\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.144898\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005909\n",
      "Epoch:1803\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.148779\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1804\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.073037\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006614\n",
      "Epoch:1805\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057565\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005272\n",
      "Epoch:1806\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.012681\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005159\n",
      "Epoch:1807\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043178\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005676\n",
      "Epoch:1808\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.184910\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006680\n",
      "Epoch:1809\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055494\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005280\n",
      "Epoch:1810\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.052740\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005231\n",
      "Epoch:1811\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040107\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005390\n",
      "Epoch:1812\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.072925\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006486\n",
      "Epoch:1813\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067005\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006647\n",
      "Epoch:1814\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.171265\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005179\n",
      "Epoch:1815\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025214\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005626\n",
      "Epoch:1816\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.087221\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005959\n",
      "Epoch:1817\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017971\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005551\n",
      "Epoch:1818\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.035127\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005700\n",
      "Epoch:1819\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040788\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005663\n",
      "Epoch:1820\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044327\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005793\n",
      "Epoch:1821\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016128\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005390\n",
      "Epoch:1822\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064950\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005950\n",
      "Epoch:1823\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.124150\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005340\n",
      "Epoch:1824\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019427\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005841\n",
      "Epoch:1825\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.118147\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005960\n",
      "Epoch:1826\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059463\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005556\n",
      "Epoch:1827\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.114716\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005308\n",
      "Epoch:1828\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052877\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005666\n",
      "Epoch:1829\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046905\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005289\n",
      "Epoch:1830\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.127107\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005501\n",
      "Epoch:1831\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027474\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006263\n",
      "Epoch:1832\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023166\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005677\n",
      "Epoch:1833\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.154783\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005575\n",
      "Epoch:1834\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053845\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005538\n",
      "Epoch:1835\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030791\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005574\n",
      "Epoch:1836\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035283\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005780\n",
      "Epoch:1837\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028930\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006469\n",
      "Epoch:1838\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067708\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006231\n",
      "Epoch:1839\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.195922\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005111\n",
      "Epoch:1840\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.058738\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005915\n",
      "Epoch:1841\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.119968\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006262\n",
      "Epoch:1842\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.014873\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005563\n",
      "Epoch:1843\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.125696\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004822\n",
      "Epoch:1844\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.121948\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005277\n",
      "Epoch:1845\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.141059\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006263\n",
      "Epoch:1846\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.099189\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006388\n",
      "Epoch:1847\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050709\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006124\n",
      "Epoch:1848\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.058704\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005603\n",
      "Epoch:1849\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045623\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005768\n",
      "Epoch:1850\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042517\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005168\n",
      "Epoch:1851\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016817\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005435\n",
      "Epoch:1852\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043167\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006317\n",
      "Epoch:1853\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044118\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006118\n",
      "Epoch:1854\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.076523\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005652\n",
      "Epoch:1855\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.126658\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005254\n",
      "Epoch:1856\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.008934\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005981\n",
      "Epoch:1857\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037296\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005696\n",
      "Epoch:1858\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033817\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005537\n",
      "Epoch:1859\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.063209\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005398\n",
      "Epoch:1860\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037894\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006023\n",
      "Epoch:1861\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.007754\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005679\n",
      "Epoch:1862\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032915\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005581\n",
      "Epoch:1863\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034273\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005184\n",
      "Epoch:1864\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.116231\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004875\n",
      "Epoch:1865\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.067744\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005385\n",
      "Epoch:1866\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023858\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005927\n",
      "Epoch:1867\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.144465\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005347\n",
      "Epoch:1868\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.149087\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005329\n",
      "Epoch:1869\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.153218\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005732\n",
      "Epoch:1870\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032038\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006164\n",
      "Epoch:1871\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035503\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005371\n",
      "Epoch:1872\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.154366\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004878\n",
      "Epoch:1873\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.116999\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005150\n",
      "Epoch:1874\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.003155\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006551\n",
      "Epoch:1875\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047042\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005855\n",
      "Epoch:1876\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036457\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005224\n",
      "Epoch:1877\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012378\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005745\n",
      "Epoch:1878\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.123262\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005763\n",
      "Epoch:1879\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045247\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006345\n",
      "Epoch:1880\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.014090\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005123\n",
      "Epoch:1881\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.039804\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004655\n",
      "Epoch:1882\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.014691\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005368\n",
      "Epoch:1883\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018744\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005851\n",
      "Epoch:1884\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.081668\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005768\n",
      "Epoch:1885\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021242\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005121\n",
      "Epoch:1886\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044554\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005091\n",
      "Epoch:1887\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.031134\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005333\n",
      "Epoch:1888\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044468\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005538\n",
      "Epoch:1889\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033925\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006127\n",
      "Epoch:1890\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035728\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005161\n",
      "Epoch:1891\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.021217\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005101\n",
      "Epoch:1892\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033510\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005211\n",
      "Epoch:1893\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.007587\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005396\n",
      "Epoch:1894\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034346\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005883\n",
      "Epoch:1895\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.011798\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005170\n",
      "Epoch:1896\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017421\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005515\n",
      "Epoch:1897\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.153246\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004804\n",
      "Epoch:1898\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.052669\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005819\n",
      "Epoch:1899\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.006394\n",
      "Testing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:100.000000 loss:0.005739\n",
      "Epoch:1900\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017355\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005806\n",
      "Epoch:1901\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040267\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005281\n",
      "Epoch:1902\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.149368\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005076\n",
      "Epoch:1903\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.111700\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005553\n",
      "Epoch:1904\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.141582\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005892\n",
      "Epoch:1905\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034909\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005739\n",
      "Epoch:1906\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.138355\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006357\n",
      "Epoch:1907\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018548\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006040\n",
      "Epoch:1908\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064760\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005670\n",
      "Epoch:1909\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037023\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004877\n",
      "Epoch:1910\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023606\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005217\n",
      "Epoch:1911\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057824\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005530\n",
      "Epoch:1912\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042255\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005340\n",
      "Epoch:1913\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.022161\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005968\n",
      "Epoch:1914\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.143969\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005905\n",
      "Epoch:1915\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026887\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005580\n",
      "Epoch:1916\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.121133\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004990\n",
      "Epoch:1917\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.082647\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005190\n",
      "Epoch:1918\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035787\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005421\n",
      "Epoch:1919\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044375\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006267\n",
      "Epoch:1920\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.058144\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006041\n",
      "Epoch:1921\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050465\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005252\n",
      "Epoch:1922\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043140\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005113\n",
      "Epoch:1923\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.066042\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005019\n",
      "Epoch:1924\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.006907\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004909\n",
      "Epoch:1925\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.134462\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004910\n",
      "Epoch:1926\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.165678\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005171\n",
      "Epoch:1927\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.112496\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007028\n",
      "Epoch:1928\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.065991\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005250\n",
      "Epoch:1929\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067306\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005457\n",
      "Epoch:1930\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066327\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005143\n",
      "Epoch:1931\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056476\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004857\n",
      "Epoch:1932\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.132355\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005051\n",
      "Epoch:1933\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051691\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006365\n",
      "Epoch:1934\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034440\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005596\n",
      "Epoch:1935\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041602\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005183\n",
      "Epoch:1936\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027340\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005565\n",
      "Epoch:1937\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.156400\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005213\n",
      "Epoch:1938\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017336\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005533\n",
      "Epoch:1939\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.143220\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005082\n",
      "Epoch:1940\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057693\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005940\n",
      "Epoch:1941\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.175325\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004935\n",
      "Epoch:1942\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.151358\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004959\n",
      "Epoch:1943\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062877\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006387\n",
      "Epoch:1944\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013621\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005344\n",
      "Epoch:1945\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030033\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004967\n",
      "Epoch:1946\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.085332\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004838\n",
      "Epoch:1947\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.029340\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004726\n",
      "Epoch:1948\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048483\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005798\n",
      "Epoch:1949\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032414\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005068\n",
      "Epoch:1950\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.062008\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004928\n",
      "Epoch:1951\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023667\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005727\n",
      "Epoch:1952\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030524\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005617\n",
      "Epoch:1953\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068003\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005437\n",
      "Epoch:1954\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.006182\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004748\n",
      "Epoch:1955\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068074\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004520\n",
      "Epoch:1956\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.169208\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005583\n",
      "Epoch:1957\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.087481\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006844\n",
      "Epoch:1958\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045886\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005072\n",
      "Epoch:1959\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020567\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004726\n",
      "Epoch:1960\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025775\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004946\n",
      "Epoch:1961\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013203\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005088\n",
      "Epoch:1962\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019443\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005992\n",
      "Epoch:1963\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.105110\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005432\n",
      "Epoch:1964\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034269\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004813\n",
      "Epoch:1965\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.145004\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004988\n",
      "Epoch:1966\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.066537\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005720\n",
      "Epoch:1967\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032225\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005033\n",
      "Epoch:1968\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030867\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004926\n",
      "Epoch:1969\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046396\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004568\n",
      "Epoch:1970\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.140782\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005008\n",
      "Epoch:1971\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.164278\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005263\n",
      "Epoch:1972\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.145610\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005584\n",
      "Epoch:1973\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039982\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005255\n",
      "Epoch:1974\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022281\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005581\n",
      "Epoch:1975\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049340\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005263\n",
      "Epoch:1976\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.121788\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004614\n",
      "Epoch:1977\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.204303\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004719\n",
      "Epoch:1978\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018075\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007638\n",
      "Epoch:1979\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137410\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005742\n",
      "Epoch:1980\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032119\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005769\n",
      "Epoch:1981\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049007\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005465\n",
      "Epoch:1982\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050693\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005104\n",
      "Epoch:1983\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.042541\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004487\n",
      "Epoch:1984\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030251\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005336\n",
      "Epoch:1985\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059923\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005660\n",
      "Epoch:1986\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036372\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005063\n",
      "Epoch:1987\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030219\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004943\n",
      "Epoch:1988\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036097\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004915\n",
      "Epoch:1989\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063134\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004976\n",
      "Epoch:1990\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.074868\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005372\n",
      "Epoch:1991\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027366\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005077\n",
      "Epoch:1992\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045766\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005366\n",
      "Epoch:1993\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.072487\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004999\n",
      "Epoch:1994\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.021457\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005508\n",
      "Epoch:1995\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.156540\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004904\n",
      "Epoch:1996\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.115892\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005254\n",
      "Epoch:1997\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078141\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005806\n",
      "Epoch:1998\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.014758\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004932\n",
      "Epoch:1999\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.158194\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004974\n",
      "Epoch:2000\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049591\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006358\n",
      "Epoch:2001\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043305\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004719\n",
      "Epoch:2002\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012136\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004788\n",
      "Epoch:2003\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127644\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2004\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.164516\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005465\n",
      "Epoch:2005\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.134867\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005566\n",
      "Epoch:2006\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.152156\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004997\n",
      "Epoch:2007\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048402\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005270\n",
      "Epoch:2008\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039221\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005443\n",
      "Epoch:2009\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050610\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005681\n",
      "Epoch:2010\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.116330\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004922\n",
      "Epoch:2011\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066971\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005460\n",
      "Epoch:2012\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037145\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004577\n",
      "Epoch:2013\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137556\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004589\n",
      "Epoch:2014\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030414\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004965\n",
      "Epoch:2015\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.003303\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005834\n",
      "Epoch:2016\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041352\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005181\n",
      "Epoch:2017\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042054\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004733\n",
      "Epoch:2018\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.100447\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004742\n",
      "Epoch:2019\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.167939\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004937\n",
      "Epoch:2020\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.080002\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005625\n",
      "Epoch:2021\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.203830\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004927\n",
      "Epoch:2022\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041325\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005850\n",
      "Epoch:2023\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.008849\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005018\n",
      "Epoch:2024\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043809\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004958\n",
      "Epoch:2025\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047368\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004528\n",
      "Epoch:2026\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013443\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004603\n",
      "Epoch:2027\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039255\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004420\n",
      "Epoch:2028\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.151342\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004503\n",
      "Epoch:2029\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043340\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006291\n",
      "Epoch:2030\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059643\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006108\n",
      "Epoch:2031\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.089508\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005013\n",
      "Epoch:2032\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.128775\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004685\n",
      "Epoch:2033\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.087459\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005133\n",
      "Epoch:2034\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.074600\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005215\n",
      "Epoch:2035\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061053\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005203\n",
      "Epoch:2036\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048656\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005085\n",
      "Epoch:2037\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.037874\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004516\n",
      "Epoch:2038\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062581\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004954\n",
      "Epoch:2039\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013911\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005428\n",
      "Epoch:2040\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.076597\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005750\n",
      "Epoch:2041\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.089046\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004793\n",
      "Epoch:2042\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.082991\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004194\n",
      "Epoch:2043\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043173\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004911\n",
      "Epoch:2044\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050580\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006307\n",
      "Epoch:2045\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038142\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004959\n",
      "Epoch:2046\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061052\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004628\n",
      "Epoch:2047\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053785\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004492\n",
      "Epoch:2048\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038275\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004326\n",
      "Epoch:2049\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.165661\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004137\n",
      "Epoch:2050\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019373\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005693\n",
      "Epoch:2051\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.120652\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005776\n",
      "Epoch:2052\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.114411\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005700\n",
      "Epoch:2053\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034674\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004298\n",
      "Epoch:2054\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.223998\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004357\n",
      "Epoch:2055\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127915\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006260\n",
      "Epoch:2056\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024577\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005415\n",
      "Epoch:2057\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.032763\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004453\n",
      "Epoch:2058\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020316\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004689\n",
      "Epoch:2059\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.040305\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004653\n",
      "Epoch:2060\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.116678\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005419\n",
      "Epoch:2061\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.098476\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005204\n",
      "Epoch:2062\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053070\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004342\n",
      "Epoch:2063\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.136832\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004320\n",
      "Epoch:2064\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.173298\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005190\n",
      "Epoch:2065\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.081553\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005340\n",
      "Epoch:2066\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059636\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004614\n",
      "Epoch:2067\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.053775\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004450\n",
      "Epoch:2068\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.092183\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005255\n",
      "Epoch:2069\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.144670\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004760\n",
      "Epoch:2070\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.164400\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005014\n",
      "Epoch:2071\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042708\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005525\n",
      "Epoch:2072\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022510\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005491\n",
      "Epoch:2073\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019592\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005419\n",
      "Epoch:2074\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.078829\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004329\n",
      "Epoch:2075\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067950\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005062\n",
      "Epoch:2076\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021436\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006056\n",
      "Epoch:2077\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.118607\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005286\n",
      "Epoch:2078\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078251\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004897\n",
      "Epoch:2079\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022754\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004162\n",
      "Epoch:2080\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.179399\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004242\n",
      "Epoch:2081\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.180661\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005307\n",
      "Epoch:2082\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.014323\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.007340\n",
      "Epoch:2083\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044080\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005864\n",
      "Epoch:2084\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017097\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004579\n",
      "Epoch:2085\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.008413\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004357\n",
      "Epoch:2086\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042325\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004907\n",
      "Epoch:2087\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057001\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005646\n",
      "Epoch:2088\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.075201\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004842\n",
      "Epoch:2089\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.030775\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004505\n",
      "Epoch:2090\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.075544\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004944\n",
      "Epoch:2091\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064101\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004912\n",
      "Epoch:2092\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034075\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004375\n",
      "Epoch:2093\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.008503\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004812\n",
      "Epoch:2094\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064600\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004914\n",
      "Epoch:2095\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.028759\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004533\n",
      "Epoch:2096\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.139237\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004247\n",
      "Epoch:2097\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.150187\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005334\n",
      "Epoch:2098\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051504\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005554\n",
      "Epoch:2099\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067967\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004811\n",
      "Epoch:2100\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037074\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004492\n",
      "Epoch:2101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      " Accuracy:97.500000 loss:0.180546\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004268\n",
      "Epoch:2102\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.143434\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004687\n",
      "Epoch:2103\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.003190\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005480\n",
      "Epoch:2104\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.061253\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005228\n",
      "Epoch:2105\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049760\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004257\n",
      "Epoch:2106\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041582\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004555\n",
      "Epoch:2107\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046934\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004917\n",
      "Epoch:2108\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064247\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004871\n",
      "Epoch:2109\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023916\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005205\n",
      "Epoch:2110\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032773\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005143\n",
      "Epoch:2111\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039450\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004605\n",
      "Epoch:2112\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.160366\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004238\n",
      "Epoch:2113\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031615\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005759\n",
      "Epoch:2114\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.120427\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005010\n",
      "Epoch:2115\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.105725\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004525\n",
      "Epoch:2116\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072504\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005076\n",
      "Epoch:2117\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072605\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004735\n",
      "Epoch:2118\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034954\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004288\n",
      "Epoch:2119\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020178\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004567\n",
      "Epoch:2120\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.058776\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004529\n",
      "Epoch:2121\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067608\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004938\n",
      "Epoch:2122\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022467\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004543\n",
      "Epoch:2123\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017443\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004868\n",
      "Epoch:2124\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.125182\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004881\n",
      "Epoch:2125\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.146920\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005293\n",
      "Epoch:2126\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027435\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004802\n",
      "Epoch:2127\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.067159\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004248\n",
      "Epoch:2128\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.045454\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004565\n",
      "Epoch:2129\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.089714\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005317\n",
      "Epoch:2130\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137531\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004681\n",
      "Epoch:2131\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050169\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004771\n",
      "Epoch:2132\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036705\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005405\n",
      "Epoch:2133\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052647\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005213\n",
      "Epoch:2134\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.128110\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004057\n",
      "Epoch:2135\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050329\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004567\n",
      "Epoch:2136\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050618\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.006121\n",
      "Epoch:2137\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042288\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004897\n",
      "Epoch:2138\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.009154\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004280\n",
      "Epoch:2139\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039344\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004743\n",
      "Epoch:2140\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056597\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004825\n",
      "Epoch:2141\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.121616\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004742\n",
      "Epoch:2142\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.146564\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004890\n",
      "Epoch:2143\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022844\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005221\n",
      "Epoch:2144\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060699\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004637\n",
      "Epoch:2145\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035791\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004259\n",
      "Epoch:2146\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.014860\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004501\n",
      "Epoch:2147\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059806\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004703\n",
      "Epoch:2148\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011504\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004500\n",
      "Epoch:2149\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040726\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004570\n",
      "Epoch:2150\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.173112\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004543\n",
      "Epoch:2151\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.153706\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004732\n",
      "Epoch:2152\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022458\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005813\n",
      "Epoch:2153\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020385\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005452\n",
      "Epoch:2154\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029007\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004109\n",
      "Epoch:2155\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.163217\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004061\n",
      "Epoch:2156\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025306\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005465\n",
      "Epoch:2157\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017868\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005568\n",
      "Epoch:2158\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016718\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005147\n",
      "Epoch:2159\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.151697\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004361\n",
      "Epoch:2160\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037206\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004770\n",
      "Epoch:2161\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.145725\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004978\n",
      "Epoch:2162\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049198\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004968\n",
      "Epoch:2163\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027211\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004097\n",
      "Epoch:2164\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.156430\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004289\n",
      "Epoch:2165\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041921\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005757\n",
      "Epoch:2166\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053246\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005589\n",
      "Epoch:2167\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.177768\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004462\n",
      "Epoch:2168\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012614\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004830\n",
      "Epoch:2169\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015282\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005060\n",
      "Epoch:2170\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.014715\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004864\n",
      "Epoch:2171\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.151038\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004510\n",
      "Epoch:2172\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050140\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004854\n",
      "Epoch:2173\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.136627\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004887\n",
      "Epoch:2174\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.094196\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005649\n",
      "Epoch:2175\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.125555\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004789\n",
      "Epoch:2176\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.120204\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004447\n",
      "Epoch:2177\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061136\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005067\n",
      "Epoch:2178\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073504\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004680\n",
      "Epoch:2179\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.119212\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005375\n",
      "Epoch:2180\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022295\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005586\n",
      "Epoch:2181\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.116445\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004693\n",
      "Epoch:2182\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053105\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005001\n",
      "Epoch:2183\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072064\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004268\n",
      "Epoch:2184\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062687\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003995\n",
      "Epoch:2185\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.009412\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004869\n",
      "Epoch:2186\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.113049\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005110\n",
      "Epoch:2187\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.102443\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005413\n",
      "Epoch:2188\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018726\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004440\n",
      "Epoch:2189\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.134066\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004269\n",
      "Epoch:2190\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050520\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004634\n",
      "Epoch:2191\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035840\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004935\n",
      "Epoch:2192\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.155046\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004238\n",
      "Epoch:2193\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.109374\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004582\n",
      "Epoch:2194\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046851\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005457\n",
      "Epoch:2195\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037362\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2196\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.005013\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004200\n",
      "Epoch:2197\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022023\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004975\n",
      "Epoch:2198\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028974\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004772\n",
      "Epoch:2199\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035792\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004747\n",
      "Epoch:2200\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016202\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004479\n",
      "Epoch:2201\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016962\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004339\n",
      "Epoch:2202\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069517\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004966\n",
      "Epoch:2203\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.143221\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004588\n",
      "Epoch:2204\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027784\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004398\n",
      "Epoch:2205\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.089465\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004546\n",
      "Epoch:2206\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023351\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004412\n",
      "Epoch:2207\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031000\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004340\n",
      "Epoch:2208\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.156136\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004013\n",
      "Epoch:2209\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.151272\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004868\n",
      "Epoch:2210\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042712\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005736\n",
      "Epoch:2211\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015206\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004743\n",
      "Epoch:2212\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031364\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004351\n",
      "Epoch:2213\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.009817\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004008\n",
      "Epoch:2214\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045181\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004289\n",
      "Epoch:2215\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.158530\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004575\n",
      "Epoch:2216\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.080680\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005336\n",
      "Epoch:2217\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.144742\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004390\n",
      "Epoch:2218\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.155896\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004659\n",
      "Epoch:2219\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.133147\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005013\n",
      "Epoch:2220\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022914\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004471\n",
      "Epoch:2221\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.008224\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004543\n",
      "Epoch:2222\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.182457\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004230\n",
      "Epoch:2223\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060999\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004558\n",
      "Epoch:2224\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.156810\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003987\n",
      "Epoch:2225\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022904\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005020\n",
      "Epoch:2226\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.142864\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005186\n",
      "Epoch:2227\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.141097\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004672\n",
      "Epoch:2228\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.134771\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004642\n",
      "Epoch:2229\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032579\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005158\n",
      "Epoch:2230\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.094912\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005157\n",
      "Epoch:2231\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026099\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004191\n",
      "Epoch:2232\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.148670\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004820\n",
      "Epoch:2233\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032129\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004437\n",
      "Epoch:2234\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027027\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004378\n",
      "Epoch:2235\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052825\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004324\n",
      "Epoch:2236\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.117927\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004182\n",
      "Epoch:2237\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.110973\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004492\n",
      "Epoch:2238\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011770\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005269\n",
      "Epoch:2239\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.012962\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004516\n",
      "Epoch:2240\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026813\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004362\n",
      "Epoch:2241\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057888\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004303\n",
      "Epoch:2242\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017889\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005026\n",
      "Epoch:2243\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024243\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005022\n",
      "Epoch:2244\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.114373\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004747\n",
      "Epoch:2245\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062367\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004619\n",
      "Epoch:2246\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038344\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004182\n",
      "Epoch:2247\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052108\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004633\n",
      "Epoch:2248\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036070\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004498\n",
      "Epoch:2249\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049054\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004128\n",
      "Epoch:2250\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052431\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004188\n",
      "Epoch:2251\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.147222\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004374\n",
      "Epoch:2252\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.029014\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005567\n",
      "Epoch:2253\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.097102\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004626\n",
      "Epoch:2254\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.010107\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004038\n",
      "Epoch:2255\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.044385\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004049\n",
      "Epoch:2256\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.021155\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004946\n",
      "Epoch:2257\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.133128\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004866\n",
      "Epoch:2258\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.129486\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004601\n",
      "Epoch:2259\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.139698\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004473\n",
      "Epoch:2260\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055086\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004430\n",
      "Epoch:2261\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.105563\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004557\n",
      "Epoch:2262\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.171434\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004046\n",
      "Epoch:2263\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053915\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004323\n",
      "Epoch:2264\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127920\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004657\n",
      "Epoch:2265\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.055478\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004575\n",
      "Epoch:2266\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025693\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003797\n",
      "Epoch:2267\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.199357\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003792\n",
      "Epoch:2268\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013574\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004949\n",
      "Epoch:2269\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.119159\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004604\n",
      "Epoch:2270\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.088149\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004774\n",
      "Epoch:2271\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.148032\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003918\n",
      "Epoch:2272\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.122671\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003891\n",
      "Epoch:2273\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.077720\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005154\n",
      "Epoch:2274\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021754\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004879\n",
      "Epoch:2275\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.143595\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004168\n",
      "Epoch:2276\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.061656\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004963\n",
      "Epoch:2277\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037668\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004789\n",
      "Epoch:2278\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.168619\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004058\n",
      "Epoch:2279\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037168\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004606\n",
      "Epoch:2280\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.087899\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005394\n",
      "Epoch:2281\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.151123\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003563\n",
      "Epoch:2282\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033667\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004011\n",
      "Epoch:2283\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028701\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004935\n",
      "Epoch:2284\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.011331\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004695\n",
      "Epoch:2285\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.100049\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004356\n",
      "Epoch:2286\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028939\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004518\n",
      "Epoch:2287\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.165511\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004679\n",
      "Epoch:2288\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016774\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004927\n",
      "Epoch:2289\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033212\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004705\n",
      "Epoch:2290\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.164609\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003876\n",
      "Epoch:2291\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037445\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004736\n",
      "Epoch:2292\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.136960\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004623\n",
      "Epoch:2293\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067532\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005111\n",
      "Epoch:2294\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068556\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004520\n",
      "Epoch:2295\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004201\n",
      "Epoch:2296\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.157721\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004177\n",
      "Epoch:2297\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.146442\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004022\n",
      "Epoch:2298\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024960\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005151\n",
      "Epoch:2299\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039433\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004688\n",
      "Epoch:2300\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030705\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004270\n",
      "Epoch:2301\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.128336\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004240\n",
      "Epoch:2302\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.070251\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004401\n",
      "Epoch:2303\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.065492\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004748\n",
      "Epoch:2304\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046798\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004543\n",
      "Epoch:2305\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.021774\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004274\n",
      "Epoch:2306\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023628\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003952\n",
      "Epoch:2307\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019972\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004163\n",
      "Epoch:2308\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.214265\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004353\n",
      "Epoch:2309\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.085515\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005254\n",
      "Epoch:2310\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017874\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004039\n",
      "Epoch:2311\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022505\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003870\n",
      "Epoch:2312\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063892\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004282\n",
      "Epoch:2313\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010103\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005065\n",
      "Epoch:2314\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030988\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004526\n",
      "Epoch:2315\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041620\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003706\n",
      "Epoch:2316\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025831\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003933\n",
      "Epoch:2317\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.120662\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003844\n",
      "Epoch:2318\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.109787\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004690\n",
      "Epoch:2319\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037053\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004157\n",
      "Epoch:2320\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.113047\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004097\n",
      "Epoch:2321\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.005774\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004277\n",
      "Epoch:2322\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025501\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004096\n",
      "Epoch:2323\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069502\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004214\n",
      "Epoch:2324\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012918\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004826\n",
      "Epoch:2325\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.005632\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004800\n",
      "Epoch:2326\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.008956\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004306\n",
      "Epoch:2327\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041501\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004082\n",
      "Epoch:2328\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.014320\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004995\n",
      "Epoch:2329\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025055\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004797\n",
      "Epoch:2330\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.121380\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004023\n",
      "Epoch:2331\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069794\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004335\n",
      "Epoch:2332\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057939\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004878\n",
      "Epoch:2333\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043073\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005181\n",
      "Epoch:2334\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.091826\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004242\n",
      "Epoch:2335\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051040\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004048\n",
      "Epoch:2336\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.011957\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003938\n",
      "Epoch:2337\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127216\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004413\n",
      "Epoch:2338\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.125817\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004713\n",
      "Epoch:2339\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.103733\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005040\n",
      "Epoch:2340\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.131078\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004976\n",
      "Epoch:2341\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.052303\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004957\n",
      "Epoch:2342\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.166092\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003891\n",
      "Epoch:2343\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.117056\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004170\n",
      "Epoch:2344\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028448\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004499\n",
      "Epoch:2345\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.097074\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004870\n",
      "Epoch:2346\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020550\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005166\n",
      "Epoch:2347\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049777\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004775\n",
      "Epoch:2348\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.115910\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003970\n",
      "Epoch:2349\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.122006\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003964\n",
      "Epoch:2350\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.105421\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004474\n",
      "Epoch:2351\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.130914\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005504\n",
      "Epoch:2352\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.194942\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003702\n",
      "Epoch:2353\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016490\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004351\n",
      "Epoch:2354\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020919\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004468\n",
      "Epoch:2355\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.056982\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004449\n",
      "Epoch:2356\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047781\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004141\n",
      "Epoch:2357\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041523\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004135\n",
      "Epoch:2358\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.145691\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003854\n",
      "Epoch:2359\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064635\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004729\n",
      "Epoch:2360\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.005339\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005014\n",
      "Epoch:2361\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.147550\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004488\n",
      "Epoch:2362\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011761\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004136\n",
      "Epoch:2363\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.156209\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004158\n",
      "Epoch:2364\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045345\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004772\n",
      "Epoch:2365\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.089529\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004617\n",
      "Epoch:2366\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.159124\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003674\n",
      "Epoch:2367\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046999\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004228\n",
      "Epoch:2368\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056300\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004651\n",
      "Epoch:2369\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.093299\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004063\n",
      "Epoch:2370\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052205\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004518\n",
      "Epoch:2371\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034622\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004491\n",
      "Epoch:2372\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.072235\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004399\n",
      "Epoch:2373\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018434\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003719\n",
      "Epoch:2374\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053843\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003842\n",
      "Epoch:2375\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017694\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004217\n",
      "Epoch:2376\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.135408\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004473\n",
      "Epoch:2377\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041854\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004568\n",
      "Epoch:2378\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036493\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004279\n",
      "Epoch:2379\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012413\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003863\n",
      "Epoch:2380\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044611\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004043\n",
      "Epoch:2381\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035374\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004544\n",
      "Epoch:2382\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021828\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004523\n",
      "Epoch:2383\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043949\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004060\n",
      "Epoch:2384\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036476\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004435\n",
      "Epoch:2385\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.088893\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004211\n",
      "Epoch:2386\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049308\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003897\n",
      "Epoch:2387\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023193\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003820\n",
      "Epoch:2388\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.037759\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003856\n",
      "Epoch:2389\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.151112\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004647\n",
      "Epoch:2390\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.137655\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004694\n",
      "Epoch:2391\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013793\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004274\n",
      "Epoch:2392\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.150023\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004026\n",
      "Epoch:2393\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.178662\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004064\n",
      "Epoch:2394\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068283\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004948\n",
      "Epoch:2395\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061766\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003908\n",
      "Epoch:2396\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.021889\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004013\n",
      "Epoch:2397\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043996\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004421\n",
      "Epoch:2398\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.072109\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004507\n",
      "Epoch:2399\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032682\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003976\n",
      "Epoch:2400\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004225\n",
      "Epoch:2401\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050426\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004144\n",
      "Epoch:2402\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.063698\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004202\n",
      "Epoch:2403\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.009192\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003967\n",
      "Epoch:2404\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013090\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004029\n",
      "Epoch:2405\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.001493\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004073\n",
      "Epoch:2406\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042695\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004129\n",
      "Epoch:2407\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054988\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004504\n",
      "Epoch:2408\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.056496\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004143\n",
      "Epoch:2409\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.122360\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003559\n",
      "Epoch:2410\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024964\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004536\n",
      "Epoch:2411\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035789\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004302\n",
      "Epoch:2412\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035566\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004819\n",
      "Epoch:2413\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017732\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004311\n",
      "Epoch:2414\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048871\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003978\n",
      "Epoch:2415\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.062142\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003578\n",
      "Epoch:2416\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137331\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004255\n",
      "Epoch:2417\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.140215\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005182\n",
      "Epoch:2418\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033509\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004692\n",
      "Epoch:2419\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.138060\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003683\n",
      "Epoch:2420\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041927\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004313\n",
      "Epoch:2421\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033811\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004271\n",
      "Epoch:2422\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.071859\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003965\n",
      "Epoch:2423\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.082697\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003821\n",
      "Epoch:2424\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062363\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004050\n",
      "Epoch:2425\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016711\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004245\n",
      "Epoch:2426\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049621\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004080\n",
      "Epoch:2427\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.108436\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003809\n",
      "Epoch:2428\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019867\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004150\n",
      "Epoch:2429\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031020\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004043\n",
      "Epoch:2430\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068555\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004077\n",
      "Epoch:2431\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.086212\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003989\n",
      "Epoch:2432\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.172747\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003832\n",
      "Epoch:2433\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042446\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005323\n",
      "Epoch:2434\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.055969\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004658\n",
      "Epoch:2435\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031492\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003973\n",
      "Epoch:2436\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027009\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003806\n",
      "Epoch:2437\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013211\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004074\n",
      "Epoch:2438\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.155626\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004012\n",
      "Epoch:2439\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010113\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004363\n",
      "Epoch:2440\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052989\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004299\n",
      "Epoch:2441\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.115310\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003867\n",
      "Epoch:2442\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.133958\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004105\n",
      "Epoch:2443\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022348\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004808\n",
      "Epoch:2444\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.148940\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004220\n",
      "Epoch:2445\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036326\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004358\n",
      "Epoch:2446\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053995\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004675\n",
      "Epoch:2447\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060843\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004339\n",
      "Epoch:2448\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054949\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003848\n",
      "Epoch:2449\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013711\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003676\n",
      "Epoch:2450\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.014721\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003826\n",
      "Epoch:2451\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043883\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004175\n",
      "Epoch:2452\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.076328\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004160\n",
      "Epoch:2453\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.038838\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003700\n",
      "Epoch:2454\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.109296\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004033\n",
      "Epoch:2455\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.078781\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005113\n",
      "Epoch:2456\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022951\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003709\n",
      "Epoch:2457\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.117138\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003644\n",
      "Epoch:2458\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.133987\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003843\n",
      "Epoch:2459\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.122664\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004288\n",
      "Epoch:2460\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.098891\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005023\n",
      "Epoch:2461\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.139359\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003814\n",
      "Epoch:2462\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060151\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004316\n",
      "Epoch:2463\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045881\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004125\n",
      "Epoch:2464\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046176\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004333\n",
      "Epoch:2465\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.111132\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004080\n",
      "Epoch:2466\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035496\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004168\n",
      "Epoch:2467\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.090299\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004298\n",
      "Epoch:2468\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072817\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004240\n",
      "Epoch:2469\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072733\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004040\n",
      "Epoch:2470\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027098\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003588\n",
      "Epoch:2471\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013140\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003750\n",
      "Epoch:2472\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040698\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003879\n",
      "Epoch:2473\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.007740\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004524\n",
      "Epoch:2474\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.138763\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004478\n",
      "Epoch:2475\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033642\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004859\n",
      "Epoch:2476\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.133096\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004006\n",
      "Epoch:2477\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027439\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004273\n",
      "Epoch:2478\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.077087\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004146\n",
      "Epoch:2479\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.121831\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003737\n",
      "Epoch:2480\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041955\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003793\n",
      "Epoch:2481\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012476\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003884\n",
      "Epoch:2482\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022459\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004005\n",
      "Epoch:2483\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048862\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004093\n",
      "Epoch:2484\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030465\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003679\n",
      "Epoch:2485\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.077446\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003864\n",
      "Epoch:2486\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.014945\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003571\n",
      "Epoch:2487\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030427\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003580\n",
      "Epoch:2488\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051135\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004031\n",
      "Epoch:2489\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056554\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004060\n",
      "Epoch:2490\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047941\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004169\n",
      "Epoch:2491\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048213\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003728\n",
      "Epoch:2492\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.179481\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003475\n",
      "Epoch:2493\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047201\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004355\n",
      "Epoch:2494\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.151627\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004284\n",
      "Epoch:2495\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023890\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003845\n",
      "Epoch:2496\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062635\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003868\n",
      "Epoch:2497\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052895\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003527\n",
      "Epoch:2498\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030082\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004008\n",
      "Epoch:2499\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.097214\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004665\n",
      "Epoch:2500\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046761\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004568\n",
      "Epoch:2501\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060961\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2502\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.107775\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003631\n",
      "Epoch:2503\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028617\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004500\n",
      "Epoch:2504\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064566\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004497\n",
      "Epoch:2505\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013752\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003674\n",
      "Epoch:2506\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027441\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003628\n",
      "Epoch:2507\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.077762\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003964\n",
      "Epoch:2508\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049343\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004013\n",
      "Epoch:2509\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020464\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003874\n",
      "Epoch:2510\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.008207\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003834\n",
      "Epoch:2511\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.145543\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004072\n",
      "Epoch:2512\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.069346\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004748\n",
      "Epoch:2513\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.111899\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004379\n",
      "Epoch:2514\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062943\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003704\n",
      "Epoch:2515\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.162618\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003343\n",
      "Epoch:2516\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.157689\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004091\n",
      "Epoch:2517\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031265\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005771\n",
      "Epoch:2518\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049984\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004723\n",
      "Epoch:2519\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.126652\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003600\n",
      "Epoch:2520\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.208071\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003587\n",
      "Epoch:2521\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.014491\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.005558\n",
      "Epoch:2522\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050182\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004790\n",
      "Epoch:2523\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069689\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003682\n",
      "Epoch:2524\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027021\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003705\n",
      "Epoch:2525\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022372\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004404\n",
      "Epoch:2526\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046444\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004028\n",
      "Epoch:2527\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.121436\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004221\n",
      "Epoch:2528\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025561\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003805\n",
      "Epoch:2529\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.121895\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003704\n",
      "Epoch:2530\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044019\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004560\n",
      "Epoch:2531\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042195\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004271\n",
      "Epoch:2532\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.056434\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004103\n",
      "Epoch:2533\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027617\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003935\n",
      "Epoch:2534\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.119857\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003613\n",
      "Epoch:2535\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.114902\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004077\n",
      "Epoch:2536\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025066\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004537\n",
      "Epoch:2537\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040481\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004069\n",
      "Epoch:2538\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053800\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004079\n",
      "Epoch:2539\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042164\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003664\n",
      "Epoch:2540\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024129\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004137\n",
      "Epoch:2541\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.105564\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003818\n",
      "Epoch:2542\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.164052\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003948\n",
      "Epoch:2543\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.100069\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003979\n",
      "Epoch:2544\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.162181\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004140\n",
      "Epoch:2545\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.141425\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004105\n",
      "Epoch:2546\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.144165\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004474\n",
      "Epoch:2547\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047934\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004469\n",
      "Epoch:2548\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027154\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003704\n",
      "Epoch:2549\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.075944\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003899\n",
      "Epoch:2550\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045668\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003684\n",
      "Epoch:2551\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018778\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003551\n",
      "Epoch:2552\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028074\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003717\n",
      "Epoch:2553\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.101062\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003900\n",
      "Epoch:2554\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051087\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004536\n",
      "Epoch:2555\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.170862\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004012\n",
      "Epoch:2556\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.009790\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004085\n",
      "Epoch:2557\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.009205\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003940\n",
      "Epoch:2558\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.103030\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003848\n",
      "Epoch:2559\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025789\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003671\n",
      "Epoch:2560\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.161096\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003754\n",
      "Epoch:2561\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.002487\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004153\n",
      "Epoch:2562\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.146157\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003823\n",
      "Epoch:2563\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050167\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004180\n",
      "Epoch:2564\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.058952\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004150\n",
      "Epoch:2565\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020594\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003742\n",
      "Epoch:2566\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055601\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003805\n",
      "Epoch:2567\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.036370\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003974\n",
      "Epoch:2568\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057733\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004657\n",
      "Epoch:2569\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040444\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004188\n",
      "Epoch:2570\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.029161\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003333\n",
      "Epoch:2571\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042971\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003675\n",
      "Epoch:2572\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035209\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004046\n",
      "Epoch:2573\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.109427\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003707\n",
      "Epoch:2574\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022426\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003845\n",
      "Epoch:2575\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.052581\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003711\n",
      "Epoch:2576\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063128\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003532\n",
      "Epoch:2577\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.092825\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003992\n",
      "Epoch:2578\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025396\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003653\n",
      "Epoch:2579\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.058228\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003542\n",
      "Epoch:2580\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.083042\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004224\n",
      "Epoch:2581\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037262\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004029\n",
      "Epoch:2582\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033973\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004111\n",
      "Epoch:2583\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.005330\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003806\n",
      "Epoch:2584\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.075177\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004269\n",
      "Epoch:2585\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049746\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003813\n",
      "Epoch:2586\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034673\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003822\n",
      "Epoch:2587\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015555\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003630\n",
      "Epoch:2588\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024300\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004003\n",
      "Epoch:2589\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021265\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003941\n",
      "Epoch:2590\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039121\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003705\n",
      "Epoch:2591\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.115705\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003936\n",
      "Epoch:2592\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.074535\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004275\n",
      "Epoch:2593\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029228\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003546\n",
      "Epoch:2594\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.111333\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003499\n",
      "Epoch:2595\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.063494\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2596\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031997\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004297\n",
      "Epoch:2597\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051033\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004485\n",
      "Epoch:2598\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.003559\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003455\n",
      "Epoch:2599\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.180176\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003282\n",
      "Epoch:2600\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022497\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004348\n",
      "Epoch:2601\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060878\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004871\n",
      "Epoch:2602\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.140045\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003560\n",
      "Epoch:2603\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.106164\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003922\n",
      "Epoch:2604\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012522\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004341\n",
      "Epoch:2605\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.155631\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004417\n",
      "Epoch:2606\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.148792\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004042\n",
      "Epoch:2607\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.110952\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003898\n",
      "Epoch:2608\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.058755\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003866\n",
      "Epoch:2609\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.105505\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003840\n",
      "Epoch:2610\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.028842\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004106\n",
      "Epoch:2611\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019658\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003589\n",
      "Epoch:2612\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016157\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003568\n",
      "Epoch:2613\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023716\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003583\n",
      "Epoch:2614\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.134107\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004029\n",
      "Epoch:2615\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068720\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004533\n",
      "Epoch:2616\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032854\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003774\n",
      "Epoch:2617\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024248\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003549\n",
      "Epoch:2618\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028641\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004310\n",
      "Epoch:2619\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021667\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004178\n",
      "Epoch:2620\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032136\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003711\n",
      "Epoch:2621\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059637\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003394\n",
      "Epoch:2622\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030609\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003581\n",
      "Epoch:2623\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.131248\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003673\n",
      "Epoch:2624\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073008\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004322\n",
      "Epoch:2625\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034152\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003603\n",
      "Epoch:2626\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.039972\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003717\n",
      "Epoch:2627\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024246\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004297\n",
      "Epoch:2628\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020729\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004651\n",
      "Epoch:2629\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046929\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004051\n",
      "Epoch:2630\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.128941\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003334\n",
      "Epoch:2631\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.085504\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003476\n",
      "Epoch:2632\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031951\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003695\n",
      "Epoch:2633\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.125314\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004081\n",
      "Epoch:2634\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045025\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003970\n",
      "Epoch:2635\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044614\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003563\n",
      "Epoch:2636\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015351\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003709\n",
      "Epoch:2637\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.139928\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003505\n",
      "Epoch:2638\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.119963\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003996\n",
      "Epoch:2639\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050726\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004761\n",
      "Epoch:2640\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039176\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003661\n",
      "Epoch:2641\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.144521\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003697\n",
      "Epoch:2642\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024219\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004290\n",
      "Epoch:2643\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018873\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003491\n",
      "Epoch:2644\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.042529\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003502\n",
      "Epoch:2645\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021923\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004395\n",
      "Epoch:2646\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.075467\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004181\n",
      "Epoch:2647\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.061056\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004294\n",
      "Epoch:2648\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.139969\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003645\n",
      "Epoch:2649\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.186696\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003571\n",
      "Epoch:2650\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.118019\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004364\n",
      "Epoch:2651\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063034\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004132\n",
      "Epoch:2652\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.061090\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004433\n",
      "Epoch:2653\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.128808\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003720\n",
      "Epoch:2654\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056052\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003684\n",
      "Epoch:2655\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.102629\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003933\n",
      "Epoch:2656\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.061826\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004609\n",
      "Epoch:2657\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066650\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004207\n",
      "Epoch:2658\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052642\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003344\n",
      "Epoch:2659\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068559\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003517\n",
      "Epoch:2660\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035338\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003831\n",
      "Epoch:2661\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012711\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004304\n",
      "Epoch:2662\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032229\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003839\n",
      "Epoch:2663\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051635\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003261\n",
      "Epoch:2664\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010077\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003524\n",
      "Epoch:2665\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.083024\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003731\n",
      "Epoch:2666\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031223\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004067\n",
      "Epoch:2667\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.092554\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004437\n",
      "Epoch:2668\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067667\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004449\n",
      "Epoch:2669\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.111968\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003555\n",
      "Epoch:2670\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026994\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003779\n",
      "Epoch:2671\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016778\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003644\n",
      "Epoch:2672\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.097310\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003901\n",
      "Epoch:2673\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.119011\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003289\n",
      "Epoch:2674\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027185\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003700\n",
      "Epoch:2675\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035938\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003891\n",
      "Epoch:2676\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.114495\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003606\n",
      "Epoch:2677\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031882\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004033\n",
      "Epoch:2678\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032756\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2679\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.150349\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003264\n",
      "Epoch:2680\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.001087\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004164\n",
      "Epoch:2681\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016856\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004297\n",
      "Epoch:2682\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.097985\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003895\n",
      "Epoch:2683\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055905\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003514\n",
      "Epoch:2684\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137907\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003827\n",
      "Epoch:2685\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054197\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004167\n",
      "Epoch:2686\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.084235\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003724\n",
      "Epoch:2687\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053032\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003678\n",
      "Epoch:2688\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.122355\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003295\n",
      "Epoch:2689\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.097862\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004203\n",
      "Epoch:2690\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.110195\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004198\n",
      "Epoch:2691\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.076979\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003677\n",
      "Epoch:2692\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046276\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004107\n",
      "Epoch:2693\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038900\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003457\n",
      "Epoch:2694\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.078575\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003980\n",
      "Epoch:2695\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037045\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003455\n",
      "Epoch:2696\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064394\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003472\n",
      "Epoch:2697\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025988\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003869\n",
      "Epoch:2698\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030576\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003920\n",
      "Epoch:2699\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023812\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003521\n",
      "Epoch:2700\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047394\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003749\n",
      "Epoch:2701\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045508\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004153\n",
      "Epoch:2702\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035920\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003814\n",
      "Epoch:2703\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031679\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003927\n",
      "Epoch:2704\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036971\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003702\n",
      "Epoch:2705\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.112085\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004012\n",
      "Epoch:2706\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.138523\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003645\n",
      "Epoch:2707\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.084863\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004211\n",
      "Epoch:2708\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050840\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003610\n",
      "Epoch:2709\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.067047\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003509\n",
      "Epoch:2710\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052131\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003675\n",
      "Epoch:2711\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037391\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003422\n",
      "Epoch:2712\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.095008\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003160\n",
      "Epoch:2713\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028223\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004514\n",
      "Epoch:2714\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.089966\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004927\n",
      "Epoch:2715\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.058061\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004404\n",
      "Epoch:2716\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.147282\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003323\n",
      "Epoch:2717\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.105278\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003658\n",
      "Epoch:2718\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.076716\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004432\n",
      "Epoch:2719\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048732\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004076\n",
      "Epoch:2720\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.123295\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003614\n",
      "Epoch:2721\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044728\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003593\n",
      "Epoch:2722\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.009833\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003218\n",
      "Epoch:2723\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072912\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003742\n",
      "Epoch:2724\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012899\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003530\n",
      "Epoch:2725\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.007164\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003470\n",
      "Epoch:2726\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053742\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003575\n",
      "Epoch:2727\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035566\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003959\n",
      "Epoch:2728\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019057\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003942\n",
      "Epoch:2729\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.041363\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003487\n",
      "Epoch:2730\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028357\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003934\n",
      "Epoch:2731\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048570\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003731\n",
      "Epoch:2732\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.136928\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003688\n",
      "Epoch:2733\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039043\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003958\n",
      "Epoch:2734\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.065347\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003801\n",
      "Epoch:2735\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040718\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003784\n",
      "Epoch:2736\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048889\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003542\n",
      "Epoch:2737\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.058123\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003615\n",
      "Epoch:2738\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067467\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003849\n",
      "Epoch:2739\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.006086\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003808\n",
      "Epoch:2740\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.128590\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003454\n",
      "Epoch:2741\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052103\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003966\n",
      "Epoch:2742\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.104348\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004587\n",
      "Epoch:2743\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.095573\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003579\n",
      "Epoch:2744\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.081977\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003537\n",
      "Epoch:2745\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.117408\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003038\n",
      "Epoch:2746\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.058345\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003436\n",
      "Epoch:2747\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026366\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004343\n",
      "Epoch:2748\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.119973\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003925\n",
      "Epoch:2749\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.008216\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003360\n",
      "Epoch:2750\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055626\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003258\n",
      "Epoch:2751\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.065174\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003332\n",
      "Epoch:2752\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.029627\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004208\n",
      "Epoch:2753\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051958\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003600\n",
      "Epoch:2754\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.113245\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003439\n",
      "Epoch:2755\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.147811\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003641\n",
      "Epoch:2756\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.161475\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004263\n",
      "Epoch:2757\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016422\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003924\n",
      "Epoch:2758\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016782\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003514\n",
      "Epoch:2759\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015502\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003424\n",
      "Epoch:2760\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011809\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003483\n",
      "Epoch:2761\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054160\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004185\n",
      "Epoch:2762\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.137536\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004058\n",
      "Epoch:2763\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035167\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003643\n",
      "Epoch:2764\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025870\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003380\n",
      "Epoch:2765\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045201\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003432\n",
      "Epoch:2766\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041740\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003909\n",
      "Epoch:2767\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042064\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004015\n",
      "Epoch:2768\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.008519\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003772\n",
      "Epoch:2769\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.151157\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2770\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021246\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004201\n",
      "Epoch:2771\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.112132\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003675\n",
      "Epoch:2772\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025479\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003660\n",
      "Epoch:2773\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016530\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003631\n",
      "Epoch:2774\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073899\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003584\n",
      "Epoch:2775\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064058\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003927\n",
      "Epoch:2776\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056459\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003801\n",
      "Epoch:2777\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024795\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003525\n",
      "Epoch:2778\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.152033\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003568\n",
      "Epoch:2779\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029968\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004681\n",
      "Epoch:2780\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.132519\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003744\n",
      "Epoch:2781\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025249\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003774\n",
      "Epoch:2782\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037675\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003338\n",
      "Epoch:2783\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015915\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003443\n",
      "Epoch:2784\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039541\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003614\n",
      "Epoch:2785\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013798\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003643\n",
      "Epoch:2786\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025423\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003582\n",
      "Epoch:2787\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.134908\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003603\n",
      "Epoch:2788\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051893\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003686\n",
      "Epoch:2789\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.125332\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003485\n",
      "Epoch:2790\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.138084\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003965\n",
      "Epoch:2791\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031003\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004627\n",
      "Epoch:2792\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.108901\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003530\n",
      "Epoch:2793\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.071266\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003524\n",
      "Epoch:2794\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025846\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004031\n",
      "Epoch:2795\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.126906\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003869\n",
      "Epoch:2796\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060448\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003572\n",
      "Epoch:2797\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.088424\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003418\n",
      "Epoch:2798\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.069864\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003289\n",
      "Epoch:2799\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049400\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004161\n",
      "Epoch:2800\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024846\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003708\n",
      "Epoch:2801\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.082668\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003404\n",
      "Epoch:2802\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.036910\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003117\n",
      "Epoch:2803\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137852\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003941\n",
      "Epoch:2804\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041080\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004095\n",
      "Epoch:2805\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.130621\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004012\n",
      "Epoch:2806\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.134256\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003467\n",
      "Epoch:2807\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025365\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003594\n",
      "Epoch:2808\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040475\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003643\n",
      "Epoch:2809\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.108721\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003682\n",
      "Epoch:2810\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044475\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003295\n",
      "Epoch:2811\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053549\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002966\n",
      "Epoch:2812\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030886\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003660\n",
      "Epoch:2813\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015470\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004368\n",
      "Epoch:2814\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013357\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003648\n",
      "Epoch:2815\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.061148\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003294\n",
      "Epoch:2816\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015833\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004025\n",
      "Epoch:2817\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037945\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004136\n",
      "Epoch:2818\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.058148\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003612\n",
      "Epoch:2819\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.116272\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003268\n",
      "Epoch:2820\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.076004\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003704\n",
      "Epoch:2821\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019562\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003924\n",
      "Epoch:2822\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.079244\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003522\n",
      "Epoch:2823\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029765\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003475\n",
      "Epoch:2824\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030429\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003677\n",
      "Epoch:2825\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.159938\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003469\n",
      "Epoch:2826\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055272\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003481\n",
      "Epoch:2827\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.148307\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003915\n",
      "Epoch:2828\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020784\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003986\n",
      "Epoch:2829\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051082\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003616\n",
      "Epoch:2830\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030746\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003432\n",
      "Epoch:2831\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018026\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003845\n",
      "Epoch:2832\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051785\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003706\n",
      "Epoch:2833\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.121084\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003872\n",
      "Epoch:2834\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021160\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003831\n",
      "Epoch:2835\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043735\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003395\n",
      "Epoch:2836\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.055319\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003554\n",
      "Epoch:2837\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056374\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003236\n",
      "Epoch:2838\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052206\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003725\n",
      "Epoch:2839\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.014324\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003564\n",
      "Epoch:2840\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059122\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003553\n",
      "Epoch:2841\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.165656\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003448\n",
      "Epoch:2842\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016213\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003788\n",
      "Epoch:2843\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.003922\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004011\n",
      "Epoch:2844\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040039\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003692\n",
      "Epoch:2845\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.132466\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003165\n",
      "Epoch:2846\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.028260\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004115\n",
      "Epoch:2847\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.073137\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003740\n",
      "Epoch:2848\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.080634\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003072\n",
      "Epoch:2849\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.123604\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003226\n",
      "Epoch:2850\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.103323\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003631\n",
      "Epoch:2851\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021695\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004493\n",
      "Epoch:2852\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.115419\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003752\n",
      "Epoch:2853\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.109492\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003396\n",
      "Epoch:2854\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036898\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003752\n",
      "Epoch:2855\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.113782\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004531\n",
      "Epoch:2856\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015530\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003962\n",
      "Epoch:2857\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.166706\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003537\n",
      "Epoch:2858\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026987\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003890\n",
      "Epoch:2859\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036916\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003442\n",
      "Epoch:2860\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069092\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003421\n",
      "Epoch:2861\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.115399\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003400\n",
      "Epoch:2862\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063109\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004168\n",
      "Epoch:2863\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030963\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003451\n",
      "Epoch:2864\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.113778\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003420\n",
      "Epoch:2865\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020138\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003865\n",
      "Epoch:2866\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.182129\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003930\n",
      "Epoch:2867\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.117675\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003986\n",
      "Epoch:2868\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022900\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003224\n",
      "Epoch:2869\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048223\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003166\n",
      "Epoch:2870\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057316\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003473\n",
      "Epoch:2871\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019002\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003599\n",
      "Epoch:2872\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031208\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003741\n",
      "Epoch:2873\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054971\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003273\n",
      "Epoch:2874\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040565\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003657\n",
      "Epoch:2875\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.029235\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003917\n",
      "Epoch:2876\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041129\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004291\n",
      "Epoch:2877\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036864\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003409\n",
      "Epoch:2878\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003534\n",
      "Epoch:2879\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013197\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003297\n",
      "Epoch:2880\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.014717\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003564\n",
      "Epoch:2881\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038152\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004082\n",
      "Epoch:2882\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047062\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003798\n",
      "Epoch:2883\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.122616\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002992\n",
      "Epoch:2884\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.066671\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003507\n",
      "Epoch:2885\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030061\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004034\n",
      "Epoch:2886\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039822\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003871\n",
      "Epoch:2887\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.134156\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003520\n",
      "Epoch:2888\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.100325\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003878\n",
      "Epoch:2889\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017856\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003491\n",
      "Epoch:2890\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038841\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003353\n",
      "Epoch:2891\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054065\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003385\n",
      "Epoch:2892\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054744\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003191\n",
      "Epoch:2893\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048408\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003235\n",
      "Epoch:2894\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.071443\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003095\n",
      "Epoch:2895\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039852\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003680\n",
      "Epoch:2896\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026852\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004320\n",
      "Epoch:2897\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.108690\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003423\n",
      "Epoch:2898\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.060520\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003559\n",
      "Epoch:2899\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.066785\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003414\n",
      "Epoch:2900\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040890\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003701\n",
      "Epoch:2901\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.018263\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003224\n",
      "Epoch:2902\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.083536\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003062\n",
      "Epoch:2903\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040489\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003468\n",
      "Epoch:2904\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.111079\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003731\n",
      "Epoch:2905\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078160\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004277\n",
      "Epoch:2906\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.086494\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003173\n",
      "Epoch:2907\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.005158\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004059\n",
      "Epoch:2908\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.130755\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003930\n",
      "Epoch:2909\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.014851\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004044\n",
      "Epoch:2910\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057098\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003653\n",
      "Epoch:2911\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062835\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003096\n",
      "Epoch:2912\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.153823\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002932\n",
      "Epoch:2913\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.015631\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003834\n",
      "Epoch:2914\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019475\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003854\n",
      "Epoch:2915\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062166\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003631\n",
      "Epoch:2916\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023235\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003327\n",
      "Epoch:2917\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013581\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003214\n",
      "Epoch:2918\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016337\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003442\n",
      "Epoch:2919\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.007556\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003290\n",
      "Epoch:2920\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.078780\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003320\n",
      "Epoch:2921\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046298\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003481\n",
      "Epoch:2922\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039036\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003980\n",
      "Epoch:2923\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013805\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003585\n",
      "Epoch:2924\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.170295\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003152\n",
      "Epoch:2925\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044559\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003375\n",
      "Epoch:2926\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043593\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003686\n",
      "Epoch:2927\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045646\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003810\n",
      "Epoch:2928\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.129338\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002938\n",
      "Epoch:2929\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.029066\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004003\n",
      "Epoch:2930\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.141912\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003773\n",
      "Epoch:2931\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.003046\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003370\n",
      "Epoch:2932\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.058568\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003393\n",
      "Epoch:2933\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035228\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003860\n",
      "Epoch:2934\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041855\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003340\n",
      "Epoch:2935\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050228\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003301\n",
      "Epoch:2936\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033147\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003351\n",
      "Epoch:2937\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.021330\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003542\n",
      "Epoch:2938\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.002685\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003637\n",
      "Epoch:2939\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025331\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003805\n",
      "Epoch:2940\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.093854\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003659\n",
      "Epoch:2941\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018776\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003962\n",
      "Epoch:2942\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055906\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003665\n",
      "Epoch:2943\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.142962\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003458\n",
      "Epoch:2944\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.104319\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003650\n",
      "Epoch:2945\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.143588\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003766\n",
      "Epoch:2946\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.119866\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003892\n",
      "Epoch:2947\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036012\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003641\n",
      "Epoch:2948\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015934\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002951\n",
      "Epoch:2949\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.030295\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003120\n",
      "Epoch:2950\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017368\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003816\n",
      "Epoch:2951\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.004774\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003653\n",
      "Epoch:2952\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013964\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003692\n",
      "Epoch:2953\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020077\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003837\n",
      "Epoch:2954\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030820\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003474\n",
      "Epoch:2955\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028215\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003414\n",
      "Epoch:2956\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046798\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003584\n",
      "Epoch:2957\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020356\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003968\n",
      "Epoch:2958\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.056231\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003648\n",
      "Epoch:2959\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.005950\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003395\n",
      "Epoch:2960\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.006246\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003251\n",
      "Epoch:2961\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.119279\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003113\n",
      "Epoch:2962\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003350\n",
      "Epoch:2963\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.070149\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003726\n",
      "Epoch:2964\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037815\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003043\n",
      "Epoch:2965\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044844\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003121\n",
      "Epoch:2966\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044508\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003183\n",
      "Epoch:2967\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.010769\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003354\n",
      "Epoch:2968\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.052313\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004273\n",
      "Epoch:2969\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.109093\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003190\n",
      "Epoch:2970\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018773\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003766\n",
      "Epoch:2971\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.146552\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003672\n",
      "Epoch:2972\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053779\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004144\n",
      "Epoch:2973\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.065776\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003667\n",
      "Epoch:2974\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.136576\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003241\n",
      "Epoch:2975\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.086784\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003705\n",
      "Epoch:2976\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.176148\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002906\n",
      "Epoch:2977\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069754\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003515\n",
      "Epoch:2978\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.074068\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004358\n",
      "Epoch:2979\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.072476\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003587\n",
      "Epoch:2980\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029690\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003388\n",
      "Epoch:2981\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.115682\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003264\n",
      "Epoch:2982\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041046\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003350\n",
      "Epoch:2983\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.126574\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003830\n",
      "Epoch:2984\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031345\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004374\n",
      "Epoch:2985\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.065700\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003396\n",
      "Epoch:2986\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061697\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002957\n",
      "Epoch:2987\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032743\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003703\n",
      "Epoch:2988\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.112388\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003282\n",
      "Epoch:2989\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137106\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003826\n",
      "Epoch:2990\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.102218\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004228\n",
      "Epoch:2991\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.079427\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004106\n",
      "Epoch:2992\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050040\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003169\n",
      "Epoch:2993\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.021128\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003393\n",
      "Epoch:2994\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.127466\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003812\n",
      "Epoch:2995\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.141629\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003407\n",
      "Epoch:2996\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.058634\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003619\n",
      "Epoch:2997\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026288\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003159\n",
      "Epoch:2998\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.006423\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002997\n",
      "Epoch:2999\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.120774\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003062\n",
      "Epoch:3000\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041785\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004032\n",
      "Epoch:3001\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.122580\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004345\n",
      "Epoch:3002\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.170801\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004157\n",
      "Epoch:3003\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032706\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003160\n",
      "Epoch:3004\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.122596\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002901\n",
      "Epoch:3005\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019385\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003626\n",
      "Epoch:3006\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036367\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003624\n",
      "Epoch:3007\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052652\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003274\n",
      "Epoch:3008\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.066399\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003098\n",
      "Epoch:3009\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028633\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003747\n",
      "Epoch:3010\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057999\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004144\n",
      "Epoch:3011\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054837\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003464\n",
      "Epoch:3012\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021927\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003298\n",
      "Epoch:3013\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.051109\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003093\n",
      "Epoch:3014\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.134557\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003554\n",
      "Epoch:3015\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064455\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004399\n",
      "Epoch:3016\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020749\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003685\n",
      "Epoch:3017\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040071\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002949\n",
      "Epoch:3018\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.146771\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002987\n",
      "Epoch:3019\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062214\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004155\n",
      "Epoch:3020\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.104515\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003332\n",
      "Epoch:3021\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018579\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003379\n",
      "Epoch:3022\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.100935\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003124\n",
      "Epoch:3023\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016245\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003815\n",
      "Epoch:3024\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.127056\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003163\n",
      "Epoch:3025\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.121234\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003411\n",
      "Epoch:3026\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033179\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004041\n",
      "Epoch:3027\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037886\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003379\n",
      "Epoch:3028\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020687\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003386\n",
      "Epoch:3029\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.133452\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003341\n",
      "Epoch:3030\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035680\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003435\n",
      "Epoch:3031\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051579\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003470\n",
      "Epoch:3032\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068491\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003378\n",
      "Epoch:3033\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.134628\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003083\n",
      "Epoch:3034\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049468\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003619\n",
      "Epoch:3035\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.002846\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003367\n",
      "Epoch:3036\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025040\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003736\n",
      "Epoch:3037\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038482\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003665\n",
      "Epoch:3038\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025802\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003714\n",
      "Epoch:3039\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.009933\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003717\n",
      "Epoch:3040\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127904\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003405\n",
      "Epoch:3041\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017762\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004178\n",
      "Epoch:3042\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048437\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003746\n",
      "Epoch:3043\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041191\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003038\n",
      "Epoch:3044\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013906\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3045\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040268\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003199\n",
      "Epoch:3046\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051125\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003791\n",
      "Epoch:3047\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.134831\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003195\n",
      "Epoch:3048\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061708\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003083\n",
      "Epoch:3049\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019971\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003551\n",
      "Epoch:3050\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032492\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003871\n",
      "Epoch:3051\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024340\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003393\n",
      "Epoch:3052\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057925\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003081\n",
      "Epoch:3053\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.080303\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003017\n",
      "Epoch:3054\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.141779\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003311\n",
      "Epoch:3055\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.014339\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004644\n",
      "Epoch:3056\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.070035\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003901\n",
      "Epoch:3057\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019827\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002944\n",
      "Epoch:3058\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.080105\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003075\n",
      "Epoch:3059\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032900\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003002\n",
      "Epoch:3060\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016751\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003243\n",
      "Epoch:3061\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059227\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003511\n",
      "Epoch:3062\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035706\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003962\n",
      "Epoch:3063\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.109408\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003362\n",
      "Epoch:3064\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.103642\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003127\n",
      "Epoch:3065\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030880\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003679\n",
      "Epoch:3066\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.101671\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003633\n",
      "Epoch:3067\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078558\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004020\n",
      "Epoch:3068\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024300\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003026\n",
      "Epoch:3069\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032239\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002952\n",
      "Epoch:3070\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036171\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003202\n",
      "Epoch:3071\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046579\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003801\n",
      "Epoch:3072\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.099488\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003542\n",
      "Epoch:3073\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.154275\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002788\n",
      "Epoch:3074\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044813\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003353\n",
      "Epoch:3075\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.105615\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003641\n",
      "Epoch:3076\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.073527\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004079\n",
      "Epoch:3077\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036302\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003763\n",
      "Epoch:3078\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028853\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003344\n",
      "Epoch:3079\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.085944\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003379\n",
      "Epoch:3080\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047689\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003170\n",
      "Epoch:3081\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063881\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003290\n",
      "Epoch:3082\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025758\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003568\n",
      "Epoch:3083\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028300\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003189\n",
      "Epoch:3084\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.111503\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003566\n",
      "Epoch:3085\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.099429\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003715\n",
      "Epoch:3086\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020952\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003772\n",
      "Epoch:3087\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042941\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003371\n",
      "Epoch:3088\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.143158\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003195\n",
      "Epoch:3089\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023605\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004141\n",
      "Epoch:3090\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029421\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003610\n",
      "Epoch:3091\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.014005\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003278\n",
      "Epoch:3092\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.137719\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002937\n",
      "Epoch:3093\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027516\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003806\n",
      "Epoch:3094\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054916\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003645\n",
      "Epoch:3095\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.154773\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002706\n",
      "Epoch:3096\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030755\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003521\n",
      "Epoch:3097\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034492\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004008\n",
      "Epoch:3098\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057262\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003360\n",
      "Epoch:3099\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.074288\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002813\n",
      "Epoch:3100\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063764\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003097\n",
      "Epoch:3101\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022072\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003298\n",
      "Epoch:3102\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.078113\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002997\n",
      "Epoch:3103\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042919\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003378\n",
      "Epoch:3104\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047720\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003436\n",
      "Epoch:3105\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024069\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002805\n",
      "Epoch:3106\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.073997\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002828\n",
      "Epoch:3107\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.106855\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003604\n",
      "Epoch:3108\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.003239\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003003\n",
      "Epoch:3109\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011195\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003014\n",
      "Epoch:3110\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037186\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003474\n",
      "Epoch:3111\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.107399\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003607\n",
      "Epoch:3112\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037247\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003903\n",
      "Epoch:3113\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050430\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003672\n",
      "Epoch:3114\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.018396\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002991\n",
      "Epoch:3115\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017679\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003204\n",
      "Epoch:3116\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.038447\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003515\n",
      "Epoch:3117\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.093523\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003421\n",
      "Epoch:3118\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.077535\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002810\n",
      "Epoch:3119\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.006261\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003640\n",
      "Epoch:3120\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046550\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003813\n",
      "Epoch:3121\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034615\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003608\n",
      "Epoch:3122\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046805\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003042\n",
      "Epoch:3123\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.107216\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002943\n",
      "Epoch:3124\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.102148\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003651\n",
      "Epoch:3125\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.109819\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004318\n",
      "Epoch:3126\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059141\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003785\n",
      "Epoch:3127\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.014935\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003159\n",
      "Epoch:3128\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026515\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002912\n",
      "Epoch:3129\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.134953\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003250\n",
      "Epoch:3130\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037903\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3131\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.063375\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003599\n",
      "Epoch:3132\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029791\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003215\n",
      "Epoch:3133\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040924\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002875\n",
      "Epoch:3134\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054261\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003473\n",
      "Epoch:3135\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032119\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003000\n",
      "Epoch:3136\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.071001\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003421\n",
      "Epoch:3137\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.081686\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003112\n",
      "Epoch:3138\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.121024\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002918\n",
      "Epoch:3139\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043146\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003600\n",
      "Epoch:3140\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.077431\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004133\n",
      "Epoch:3141\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.142236\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003326\n",
      "Epoch:3142\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.107095\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003311\n",
      "Epoch:3143\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012161\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002895\n",
      "Epoch:3144\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069340\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003264\n",
      "Epoch:3145\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.004850\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003493\n",
      "Epoch:3146\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037534\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003684\n",
      "Epoch:3147\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.098706\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003616\n",
      "Epoch:3148\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.126482\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004101\n",
      "Epoch:3149\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.005577\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003103\n",
      "Epoch:3150\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.113265\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002641\n",
      "Epoch:3151\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.108174\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003326\n",
      "Epoch:3152\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.137882\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004285\n",
      "Epoch:3153\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.018842\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003794\n",
      "Epoch:3154\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.152349\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003103\n",
      "Epoch:3155\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043110\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003028\n",
      "Epoch:3156\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038204\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003666\n",
      "Epoch:3157\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029845\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003560\n",
      "Epoch:3158\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030068\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003062\n",
      "Epoch:3159\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043709\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003582\n",
      "Epoch:3160\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.129939\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003995\n",
      "Epoch:3161\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.117238\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002925\n",
      "Epoch:3162\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.002078\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003745\n",
      "Epoch:3163\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.112828\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003562\n",
      "Epoch:3164\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.063858\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003508\n",
      "Epoch:3165\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020139\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003438\n",
      "Epoch:3166\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.002667\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003243\n",
      "Epoch:3167\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.161432\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002962\n",
      "Epoch:3168\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.116430\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003520\n",
      "Epoch:3169\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041019\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004154\n",
      "Epoch:3170\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044659\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003206\n",
      "Epoch:3171\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027733\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002989\n",
      "Epoch:3172\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.120825\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002939\n",
      "Epoch:3173\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012498\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004206\n",
      "Epoch:3174\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.164953\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004237\n",
      "Epoch:3175\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024253\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003162\n",
      "Epoch:3176\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.067836\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003071\n",
      "Epoch:3177\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063185\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003532\n",
      "Epoch:3178\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029372\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002970\n",
      "Epoch:3179\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035404\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003439\n",
      "Epoch:3180\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.120146\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003258\n",
      "Epoch:3181\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.056473\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004452\n",
      "Epoch:3182\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.091745\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003227\n",
      "Epoch:3183\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.074726\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002778\n",
      "Epoch:3184\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.006644\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003085\n",
      "Epoch:3185\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064796\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003648\n",
      "Epoch:3186\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021080\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002867\n",
      "Epoch:3187\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052245\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003324\n",
      "Epoch:3188\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034694\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003157\n",
      "Epoch:3189\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069875\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003390\n",
      "Epoch:3190\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018412\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003083\n",
      "Epoch:3191\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.004366\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003053\n",
      "Epoch:3192\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062707\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003014\n",
      "Epoch:3193\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.100181\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003150\n",
      "Epoch:3194\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030970\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003730\n",
      "Epoch:3195\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.002049\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003432\n",
      "Epoch:3196\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039834\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002877\n",
      "Epoch:3197\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069435\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003213\n",
      "Epoch:3198\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.012623\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003846\n",
      "Epoch:3199\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.104179\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003316\n",
      "Epoch:3200\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053379\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003773\n",
      "Epoch:3201\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023113\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003215\n",
      "Epoch:3202\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054059\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003249\n",
      "Epoch:3203\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.071781\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003062\n",
      "Epoch:3204\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.057235\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002916\n",
      "Epoch:3205\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020809\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003478\n",
      "Epoch:3206\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041261\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003306\n",
      "Epoch:3207\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037212\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002788\n",
      "Epoch:3208\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018077\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003375\n",
      "Epoch:3209\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.003734\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003308\n",
      "Epoch:3210\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.085381\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003115\n",
      "Epoch:3211\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054616\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003000\n",
      "Epoch:3212\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040912\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002917\n",
      "Epoch:3213\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050998\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002996\n",
      "Epoch:3214\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034718\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002820\n",
      "Epoch:3215\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017685\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003634\n",
      "Epoch:3216\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022662\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003529\n",
      "Epoch:3217\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.127175\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003126\n",
      "Epoch:3218\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030764\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003276\n",
      "Epoch:3219\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.122147\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003325\n",
      "Epoch:3220\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050790\n",
      "Testing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:100.000000 loss:0.003619\n",
      "Epoch:3221\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.120135\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003706\n",
      "Epoch:3222\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.098509\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003200\n",
      "Epoch:3223\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046590\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003505\n",
      "Epoch:3224\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.109021\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003391\n",
      "Epoch:3225\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.133143\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003745\n",
      "Epoch:3226\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.009651\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003873\n",
      "Epoch:3227\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023141\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003565\n",
      "Epoch:3228\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020863\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003086\n",
      "Epoch:3229\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018278\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003593\n",
      "Epoch:3230\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021668\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003522\n",
      "Epoch:3231\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.135076\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003087\n",
      "Epoch:3232\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.144487\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002822\n",
      "Epoch:3233\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063596\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003877\n",
      "Epoch:3234\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.130900\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003319\n",
      "Epoch:3235\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.082035\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003805\n",
      "Epoch:3236\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027903\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002951\n",
      "Epoch:3237\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.009985\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002959\n",
      "Epoch:3238\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.029691\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003161\n",
      "Epoch:3239\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036773\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003407\n",
      "Epoch:3240\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041576\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003550\n",
      "Epoch:3241\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036987\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003345\n",
      "Epoch:3242\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055570\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002983\n",
      "Epoch:3243\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.009733\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002914\n",
      "Epoch:3244\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040106\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003186\n",
      "Epoch:3245\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.165204\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003193\n",
      "Epoch:3246\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024702\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003781\n",
      "Epoch:3247\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.158989\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003810\n",
      "Epoch:3248\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.114596\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003059\n",
      "Epoch:3249\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.131643\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003054\n",
      "Epoch:3250\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.079053\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003355\n",
      "Epoch:3251\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.130321\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002785\n",
      "Epoch:3252\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.056848\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002968\n",
      "Epoch:3253\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.143426\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003674\n",
      "Epoch:3254\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050564\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003999\n",
      "Epoch:3255\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.028839\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003301\n",
      "Epoch:3256\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.133905\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002743\n",
      "Epoch:3257\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042963\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003141\n",
      "Epoch:3258\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.151501\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003495\n",
      "Epoch:3259\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047090\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003919\n",
      "Epoch:3260\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034529\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003106\n",
      "Epoch:3261\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039917\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002901\n",
      "Epoch:3262\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032252\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003093\n",
      "Epoch:3263\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010356\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003383\n",
      "Epoch:3264\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.091884\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003353\n",
      "Epoch:3265\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.175378\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002753\n",
      "Epoch:3266\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047051\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003754\n",
      "Epoch:3267\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.095775\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003879\n",
      "Epoch:3268\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031550\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003966\n",
      "Epoch:3269\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013021\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003338\n",
      "Epoch:3270\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044274\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003325\n",
      "Epoch:3271\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.104217\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003256\n",
      "Epoch:3272\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.149898\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003309\n",
      "Epoch:3273\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039032\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003452\n",
      "Epoch:3274\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030164\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003725\n",
      "Epoch:3275\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048763\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003065\n",
      "Epoch:3276\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.071080\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003502\n",
      "Epoch:3277\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027211\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003167\n",
      "Epoch:3278\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.001844\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003122\n",
      "Epoch:3279\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011025\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003168\n",
      "Epoch:3280\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.109371\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002934\n",
      "Epoch:3281\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.011735\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003814\n",
      "Epoch:3282\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037538\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004082\n",
      "Epoch:3283\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064695\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003389\n",
      "Epoch:3284\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.163303\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002982\n",
      "Epoch:3285\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047024\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003686\n",
      "Epoch:3286\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021639\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003606\n",
      "Epoch:3287\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.095587\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003110\n",
      "Epoch:3288\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057054\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003411\n",
      "Epoch:3289\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043297\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003499\n",
      "Epoch:3290\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020258\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003432\n",
      "Epoch:3291\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044728\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003178\n",
      "Epoch:3292\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.003948\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002751\n",
      "Epoch:3293\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052211\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002839\n",
      "Epoch:3294\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026517\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003578\n",
      "Epoch:3295\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027039\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003499\n",
      "Epoch:3296\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.113465\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003445\n",
      "Epoch:3297\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.010159\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003144\n",
      "Epoch:3298\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.008534\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003106\n",
      "Epoch:3299\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024435\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003700\n",
      "Epoch:3300\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.111452\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003514\n",
      "Epoch:3301\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.112103\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002643\n",
      "Epoch:3302\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.103117\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002834\n",
      "Epoch:3303\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057282\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003866\n",
      "Epoch:3304\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.129157\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002956\n",
      "Epoch:3305\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.024068\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003293\n",
      "Epoch:3306\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019632\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003718\n",
      "Epoch:3307\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.097198\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002963\n",
      "Epoch:3308\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.141072\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003189\n",
      "Epoch:3309\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.113876\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003739\n",
      "Epoch:3310\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.109569\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3311\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.107716\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003276\n",
      "Epoch:3312\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.011802\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003154\n",
      "Epoch:3313\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013322\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002882\n",
      "Epoch:3314\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.122610\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003061\n",
      "Epoch:3315\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.111353\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003173\n",
      "Epoch:3316\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036096\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003483\n",
      "Epoch:3317\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041635\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003740\n",
      "Epoch:3318\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.081899\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003795\n",
      "Epoch:3319\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042550\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003138\n",
      "Epoch:3320\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.024219\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003030\n",
      "Epoch:3321\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072674\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003442\n",
      "Epoch:3322\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017614\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003237\n",
      "Epoch:3323\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037809\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003384\n",
      "Epoch:3324\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020049\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002992\n",
      "Epoch:3325\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.021999\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003268\n",
      "Epoch:3326\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036420\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003493\n",
      "Epoch:3327\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021331\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003497\n",
      "Epoch:3328\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027102\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003093\n",
      "Epoch:3329\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040298\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002890\n",
      "Epoch:3330\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.131531\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003243\n",
      "Epoch:3331\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.117106\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003505\n",
      "Epoch:3332\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045109\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003508\n",
      "Epoch:3333\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.003257\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002802\n",
      "Epoch:3334\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.107939\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002783\n",
      "Epoch:3335\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.144201\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003630\n",
      "Epoch:3336\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051668\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003472\n",
      "Epoch:3337\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.151333\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003416\n",
      "Epoch:3338\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.090246\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003972\n",
      "Epoch:3339\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.038430\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004041\n",
      "Epoch:3340\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040051\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002953\n",
      "Epoch:3341\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.029998\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003043\n",
      "Epoch:3342\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019939\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003453\n",
      "Epoch:3343\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.006300\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003253\n",
      "Epoch:3344\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054030\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003226\n",
      "Epoch:3345\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.005958\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003076\n",
      "Epoch:3346\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038066\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003189\n",
      "Epoch:3347\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.119171\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003664\n",
      "Epoch:3348\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.077379\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002761\n",
      "Epoch:3349\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.174383\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002713\n",
      "Epoch:3350\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057561\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003726\n",
      "Epoch:3351\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.004256\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003402\n",
      "Epoch:3352\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.097302\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003031\n",
      "Epoch:3353\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.011780\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002576\n",
      "Epoch:3354\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064810\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002968\n",
      "Epoch:3355\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.074050\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003658\n",
      "Epoch:3356\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017339\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002780\n",
      "Epoch:3357\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.131788\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002845\n",
      "Epoch:3358\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019618\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004341\n",
      "Epoch:3359\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048071\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003644\n",
      "Epoch:3360\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.106553\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002652\n",
      "Epoch:3361\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043874\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002915\n",
      "Epoch:3362\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034314\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003537\n",
      "Epoch:3363\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032585\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003517\n",
      "Epoch:3364\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.159523\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002841\n",
      "Epoch:3365\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022096\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004003\n",
      "Epoch:3366\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043699\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003521\n",
      "Epoch:3367\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016092\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003235\n",
      "Epoch:3368\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044625\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002917\n",
      "Epoch:3369\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046328\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002665\n",
      "Epoch:3370\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072208\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003375\n",
      "Epoch:3371\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072516\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003547\n",
      "Epoch:3372\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.074247\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003073\n",
      "Epoch:3373\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.152005\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002804\n",
      "Epoch:3374\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021234\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003954\n",
      "Epoch:3375\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030184\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003392\n",
      "Epoch:3376\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031173\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003266\n",
      "Epoch:3377\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.007497\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003252\n",
      "Epoch:3378\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.106355\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003324\n",
      "Epoch:3379\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.008638\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003815\n",
      "Epoch:3380\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018862\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003190\n",
      "Epoch:3381\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.067619\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003189\n",
      "Epoch:3382\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.056030\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003528\n",
      "Epoch:3383\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.028667\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003125\n",
      "Epoch:3384\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047033\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003333\n",
      "Epoch:3385\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.107678\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003286\n",
      "Epoch:3386\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.135875\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003137\n",
      "Epoch:3387\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064569\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004221\n",
      "Epoch:3388\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039222\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002786\n",
      "Epoch:3389\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.113403\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002786\n",
      "Epoch:3390\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.154023\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002971\n",
      "Epoch:3391\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029344\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004400\n",
      "Epoch:3392\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036027\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003773\n",
      "Epoch:3393\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.181202\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002715\n",
      "Epoch:3394\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.085606\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003498\n",
      "Epoch:3395\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068599\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003508\n",
      "Epoch:3396\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.003204\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003167\n",
      "Epoch:3397\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024396\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003122\n",
      "Epoch:3398\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.130426\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002885\n",
      "Epoch:3399\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034074\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003283\n",
      "Epoch:3400\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.103885\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003364\n",
      "Epoch:3401\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.111959\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003460\n",
      "Epoch:3402\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.105202\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003533\n",
      "Epoch:3403\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.086365\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003555\n",
      "Epoch:3404\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.060361\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002795\n",
      "Epoch:3405\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040739\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003269\n",
      "Epoch:3406\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.022121\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003446\n",
      "Epoch:3407\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.179218\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003709\n",
      "Epoch:3408\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.138705\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002834\n",
      "Epoch:3409\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003609\n",
      "Epoch:3410\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.118386\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003616\n",
      "Epoch:3411\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015010\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003741\n",
      "Epoch:3412\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.125093\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003153\n",
      "Epoch:3413\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.159233\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003539\n",
      "Epoch:3414\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047541\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003457\n",
      "Epoch:3415\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.097924\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002819\n",
      "Epoch:3416\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.058495\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002659\n",
      "Epoch:3417\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015748\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003176\n",
      "Epoch:3418\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038682\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002959\n",
      "Epoch:3419\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.131283\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002779\n",
      "Epoch:3420\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.142318\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003186\n",
      "Epoch:3421\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.114167\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003682\n",
      "Epoch:3422\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.038662\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004055\n",
      "Epoch:3423\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.124555\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003344\n",
      "Epoch:3424\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055405\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003061\n",
      "Epoch:3425\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041334\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003691\n",
      "Epoch:3426\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.127681\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003009\n",
      "Epoch:3427\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.029680\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002917\n",
      "Epoch:3428\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030405\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003277\n",
      "Epoch:3429\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015785\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003054\n",
      "Epoch:3430\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.119310\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003073\n",
      "Epoch:3431\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019749\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003478\n",
      "Epoch:3432\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037807\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003032\n",
      "Epoch:3433\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011845\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003156\n",
      "Epoch:3434\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022502\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003439\n",
      "Epoch:3435\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024246\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003664\n",
      "Epoch:3436\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054711\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003357\n",
      "Epoch:3437\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.100266\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003698\n",
      "Epoch:3438\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035655\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002913\n",
      "Epoch:3439\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.070479\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003297\n",
      "Epoch:3440\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.008472\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003146\n",
      "Epoch:3441\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.018399\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003020\n",
      "Epoch:3442\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029012\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002819\n",
      "Epoch:3443\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.058351\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003006\n",
      "Epoch:3444\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.135908\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002813\n",
      "Epoch:3445\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.109261\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003525\n",
      "Epoch:3446\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027120\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003825\n",
      "Epoch:3447\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.127978\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003130\n",
      "Epoch:3448\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.155649\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002876\n",
      "Epoch:3449\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.109129\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003299\n",
      "Epoch:3450\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.114253\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002594\n",
      "Epoch:3451\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.061865\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002934\n",
      "Epoch:3452\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.069255\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003524\n",
      "Epoch:3453\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013478\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002973\n",
      "Epoch:3454\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035312\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002992\n",
      "Epoch:3455\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.095684\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003150\n",
      "Epoch:3456\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033775\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003409\n",
      "Epoch:3457\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.116405\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003321\n",
      "Epoch:3458\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043530\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003607\n",
      "Epoch:3459\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041837\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003043\n",
      "Epoch:3460\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026301\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002820\n",
      "Epoch:3461\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051137\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002892\n",
      "Epoch:3462\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029715\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003393\n",
      "Epoch:3463\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.077268\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003331\n",
      "Epoch:3464\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027780\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002760\n",
      "Epoch:3465\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043411\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002672\n",
      "Epoch:3466\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024968\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003103\n",
      "Epoch:3467\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010118\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003770\n",
      "Epoch:3468\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037660\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004142\n",
      "Epoch:3469\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.165967\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002877\n",
      "Epoch:3470\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010138\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003213\n",
      "Epoch:3471\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016743\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003187\n",
      "Epoch:3472\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.038535\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003457\n",
      "Epoch:3473\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.011331\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003108\n",
      "Epoch:3474\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.107173\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002733\n",
      "Epoch:3475\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073784\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003328\n",
      "Epoch:3476\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022625\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003983\n",
      "Epoch:3477\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.101783\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003136\n",
      "Epoch:3478\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024071\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003794\n",
      "Epoch:3479\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.012605\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003121\n",
      "Epoch:3480\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.011521\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003212\n",
      "Epoch:3481\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137844\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002883\n",
      "Epoch:3482\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.102644\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003333\n",
      "Epoch:3483\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043959\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003377\n",
      "Epoch:3484\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047938\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002907\n",
      "Epoch:3485\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.143876\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002751\n",
      "Epoch:3486\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053112\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003759\n",
      "Epoch:3487\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.056631\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003100\n",
      "Epoch:3488\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046588\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002777\n",
      "Epoch:3489\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137005\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003084\n",
      "Epoch:3490\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.120846\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003942\n",
      "Epoch:3491\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.121744\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003567\n",
      "Epoch:3492\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.010389\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002959\n",
      "Epoch:3493\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.163744\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002647\n",
      "Epoch:3494\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.136496\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002879\n",
      "Epoch:3495\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059917\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003941\n",
      "Epoch:3496\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.007569\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003123\n",
      "Epoch:3497\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.148366\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002692\n",
      "Epoch:3498\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.008029\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003505\n",
      "Epoch:3499\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050246\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003879\n",
      "Epoch:3500\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013607\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003513\n",
      "Epoch:3501\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.117230\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002857\n",
      "Epoch:3502\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033624\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002972\n",
      "Epoch:3503\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034899\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003315\n",
      "Epoch:3504\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.128638\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003083\n",
      "Epoch:3505\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.101846\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003378\n",
      "Epoch:3506\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.101359\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003792\n",
      "Epoch:3507\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.012357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002914\n",
      "Epoch:3508\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036449\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002686\n",
      "Epoch:3509\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015805\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003133\n",
      "Epoch:3510\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073041\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003154\n",
      "Epoch:3511\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.055358\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003754\n",
      "Epoch:3512\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046860\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003189\n",
      "Epoch:3513\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.104979\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003195\n",
      "Epoch:3514\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029602\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003411\n",
      "Epoch:3515\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031773\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002969\n",
      "Epoch:3516\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048777\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002761\n",
      "Epoch:3517\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021445\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003304\n",
      "Epoch:3518\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.028254\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003332\n",
      "Epoch:3519\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.065524\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002729\n",
      "Epoch:3520\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055478\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003132\n",
      "Epoch:3521\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041345\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002981\n",
      "Epoch:3522\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048915\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002748\n",
      "Epoch:3523\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031141\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002961\n",
      "Epoch:3524\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.130294\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002943\n",
      "Epoch:3525\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.007078\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002410\n",
      "Epoch:3526\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045808\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003108\n",
      "Epoch:3527\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.120553\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003014\n",
      "Epoch:3528\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.106563\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003300\n",
      "Epoch:3529\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050531\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003891\n",
      "Epoch:3530\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.149225\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002714\n",
      "Epoch:3531\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032827\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003420\n",
      "Epoch:3532\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.073788\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003655\n",
      "Epoch:3533\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012122\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003017\n",
      "Epoch:3534\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.141702\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002936\n",
      "Epoch:3535\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057956\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003718\n",
      "Epoch:3536\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051592\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003155\n",
      "Epoch:3537\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.143397\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002735\n",
      "Epoch:3538\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028840\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003675\n",
      "Epoch:3539\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051338\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003790\n",
      "Epoch:3540\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038757\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002867\n",
      "Epoch:3541\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053350\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003095\n",
      "Epoch:3542\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067297\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003187\n",
      "Epoch:3543\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059927\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002960\n",
      "Epoch:3544\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.160050\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002702\n",
      "Epoch:3545\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.115286\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003441\n",
      "Epoch:3546\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030263\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003951\n",
      "Epoch:3547\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.150949\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003071\n",
      "Epoch:3548\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018258\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002970\n",
      "Epoch:3549\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.112219\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002972\n",
      "Epoch:3550\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038284\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003612\n",
      "Epoch:3551\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032678\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003630\n",
      "Epoch:3552\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026784\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002883\n",
      "Epoch:3553\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.108188\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002740\n",
      "Epoch:3554\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049531\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003369\n",
      "Epoch:3555\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.007031\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003532\n",
      "Epoch:3556\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.156337\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003505\n",
      "Epoch:3557\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.004441\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003156\n",
      "Epoch:3558\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038306\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003386\n",
      "Epoch:3559\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.126381\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003099\n",
      "Epoch:3560\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027891\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003506\n",
      "Epoch:3561\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021976\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004309\n",
      "Epoch:3562\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.086602\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002950\n",
      "Epoch:3563\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033092\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002689\n",
      "Epoch:3564\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033141\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003140\n",
      "Epoch:3565\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.130319\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003748\n",
      "Epoch:3566\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.128305\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003164\n",
      "Epoch:3567\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.157223\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002693\n",
      "Epoch:3568\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.029342\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003667\n",
      "Epoch:3569\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.114797\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003733\n",
      "Epoch:3570\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.128661\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002963\n",
      "Epoch:3571\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047176\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003260\n",
      "Epoch:3572\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.011827\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003226\n",
      "Epoch:3573\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.128698\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003184\n",
      "Epoch:3574\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036022\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003082\n",
      "Epoch:3575\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.105814\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002973\n",
      "Epoch:3576\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028822\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003671\n",
      "Epoch:3577\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040275\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002963\n",
      "Epoch:3578\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.003262\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003133\n",
      "Epoch:3579\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.126324\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003368\n",
      "Epoch:3580\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029414\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003765\n",
      "Epoch:3581\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046868\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003005\n",
      "Epoch:3582\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.012004\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002671\n",
      "Epoch:3583\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042297\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003217\n",
      "Epoch:3584\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044444\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003511\n",
      "Epoch:3585\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.061306\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003986\n",
      "Epoch:3586\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020357\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003529\n",
      "Epoch:3587\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.155093\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002986\n",
      "Epoch:3588\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033637\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003112\n",
      "Epoch:3589\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035722\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003321\n",
      "Epoch:3590\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078719\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003796\n",
      "Epoch:3591\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038112\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002921\n",
      "Epoch:3592\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051095\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003152\n",
      "Epoch:3593\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003178\n",
      "Epoch:3594\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.102923\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003270\n",
      "Epoch:3595\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030987\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003757\n",
      "Epoch:3596\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.156082\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003337\n",
      "Epoch:3597\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.080131\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003033\n",
      "Epoch:3598\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061619\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003276\n",
      "Epoch:3599\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027063\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003210\n",
      "Epoch:3600\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031930\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003541\n",
      "Epoch:3601\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036499\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002962\n",
      "Epoch:3602\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.002275\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002641\n",
      "Epoch:3603\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028118\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002914\n",
      "Epoch:3604\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060435\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003293\n",
      "Epoch:3605\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064472\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003520\n",
      "Epoch:3606\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.057675\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002663\n",
      "Epoch:3607\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.070374\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003441\n",
      "Epoch:3608\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036716\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003066\n",
      "Epoch:3609\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.009497\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002688\n",
      "Epoch:3610\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054445\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003216\n",
      "Epoch:3611\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.122801\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003571\n",
      "Epoch:3612\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048144\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003347\n",
      "Epoch:3613\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047119\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002621\n",
      "Epoch:3614\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064568\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002903\n",
      "Epoch:3615\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.089350\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003267\n",
      "Epoch:3616\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.065813\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003269\n",
      "Epoch:3617\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.147067\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002588\n",
      "Epoch:3618\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.148122\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002887\n",
      "Epoch:3619\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.085444\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004056\n",
      "Epoch:3620\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.061879\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003163\n",
      "Epoch:3621\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053760\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002923\n",
      "Epoch:3622\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.038420\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002877\n",
      "Epoch:3623\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.114775\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002969\n",
      "Epoch:3624\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.106982\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003152\n",
      "Epoch:3625\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039042\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003439\n",
      "Epoch:3626\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.074369\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003088\n",
      "Epoch:3627\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032209\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002991\n",
      "Epoch:3628\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022604\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003105\n",
      "Epoch:3629\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061709\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003082\n",
      "Epoch:3630\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.021444\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003034\n",
      "Epoch:3631\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042526\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002953\n",
      "Epoch:3632\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054891\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003075\n",
      "Epoch:3633\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029925\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002562\n",
      "Epoch:3634\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039691\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003061\n",
      "Epoch:3635\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.120591\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003669\n",
      "Epoch:3636\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.149413\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003927\n",
      "Epoch:3637\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.012277\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003292\n",
      "Epoch:3638\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.012061\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002987\n",
      "Epoch:3639\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.050202\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002587\n",
      "Epoch:3640\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012109\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003400\n",
      "Epoch:3641\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045487\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003610\n",
      "Epoch:3642\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048967\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003141\n",
      "Epoch:3643\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053568\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003346\n",
      "Epoch:3644\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.076458\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002863\n",
      "Epoch:3645\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.124575\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002677\n",
      "Epoch:3646\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020300\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003447\n",
      "Epoch:3647\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068437\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003576\n",
      "Epoch:3648\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066586\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002873\n",
      "Epoch:3649\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063523\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002776\n",
      "Epoch:3650\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.172116\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002744\n",
      "Epoch:3651\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060762\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003968\n",
      "Epoch:3652\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043523\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003617\n",
      "Epoch:3653\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050336\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002857\n",
      "Epoch:3654\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021302\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002813\n",
      "Epoch:3655\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035361\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002802\n",
      "Epoch:3656\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.113321\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002831\n",
      "Epoch:3657\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042722\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003242\n",
      "Epoch:3658\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052094\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002826\n",
      "Epoch:3659\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.007029\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003375\n",
      "Epoch:3660\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.124153\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003319\n",
      "Epoch:3661\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.098962\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003623\n",
      "Epoch:3662\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021169\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002526\n",
      "Epoch:3663\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026803\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002650\n",
      "Epoch:3664\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.182207\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002652\n",
      "Epoch:3665\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.088375\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004219\n",
      "Epoch:3666\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040782\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003181\n",
      "Epoch:3667\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031212\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002822\n",
      "Epoch:3668\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.066773\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003142\n",
      "Epoch:3669\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.002350\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002793\n",
      "Epoch:3670\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022096\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003175\n",
      "Epoch:3671\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013445\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003128\n",
      "Epoch:3672\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064841\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003344\n",
      "Epoch:3673\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036306\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002640\n",
      "Epoch:3674\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.001595\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002889\n",
      "Epoch:3675\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.145603\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003540\n",
      "Epoch:3676\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.070935\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003742\n",
      "Epoch:3677\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051119\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002776\n",
      "Epoch:3678\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.111150\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002282\n",
      "Epoch:3679\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.085324\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003071\n",
      "Epoch:3680\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.038408\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003181\n",
      "Epoch:3681\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033108\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002831\n",
      "Epoch:3682\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044565\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002809\n",
      "Epoch:3683\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.108446\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002713\n",
      "Epoch:3684\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035692\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003344\n",
      "Epoch:3685\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.109896\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003558\n",
      "Epoch:3686\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.146900\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003220\n",
      "Epoch:3687\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023067\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002603\n",
      "Epoch:3688\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050906\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002845\n",
      "Epoch:3689\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.002668\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003027\n",
      "Epoch:3690\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032973\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003529\n",
      "Epoch:3691\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.168020\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003197\n",
      "Epoch:3692\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048583\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003382\n",
      "Epoch:3693\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003396\n",
      "Epoch:3694\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024857\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002933\n",
      "Epoch:3695\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036609\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002826\n",
      "Epoch:3696\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053715\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002817\n",
      "Epoch:3697\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010481\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002784\n",
      "Epoch:3698\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013159\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003111\n",
      "Epoch:3699\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.005883\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003430\n",
      "Epoch:3700\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024432\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003089\n",
      "Epoch:3701\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.118563\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003024\n",
      "Epoch:3702\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.115488\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003642\n",
      "Epoch:3703\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.081736\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003718\n",
      "Epoch:3704\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029208\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002762\n",
      "Epoch:3705\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042362\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002777\n",
      "Epoch:3706\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.106163\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002603\n",
      "Epoch:3707\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026196\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003244\n",
      "Epoch:3708\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.138630\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003548\n",
      "Epoch:3709\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029431\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003690\n",
      "Epoch:3710\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019956\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002884\n",
      "Epoch:3711\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.122091\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002784\n",
      "Epoch:3712\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043169\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003296\n",
      "Epoch:3713\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.140236\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003608\n",
      "Epoch:3714\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025944\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002477\n",
      "Epoch:3715\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.008421\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002377\n",
      "Epoch:3716\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026182\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003233\n",
      "Epoch:3717\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078765\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003479\n",
      "Epoch:3718\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.014224\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002552\n",
      "Epoch:3719\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041238\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002545\n",
      "Epoch:3720\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015958\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002707\n",
      "Epoch:3721\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061254\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002844\n",
      "Epoch:3722\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.155741\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002859\n",
      "Epoch:3723\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063776\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003589\n",
      "Epoch:3724\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016781\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003280\n",
      "Epoch:3725\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022220\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002849\n",
      "Epoch:3726\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.067918\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002765\n",
      "Epoch:3727\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062629\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003104\n",
      "Epoch:3728\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.144055\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002545\n",
      "Epoch:3729\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.004150\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003454\n",
      "Epoch:3730\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.158429\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003266\n",
      "Epoch:3731\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.109413\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003373\n",
      "Epoch:3732\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023849\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003015\n",
      "Epoch:3733\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041240\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002786\n",
      "Epoch:3734\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068220\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003084\n",
      "Epoch:3735\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044962\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002757\n",
      "Epoch:3736\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.029958\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002632\n",
      "Epoch:3737\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.073392\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002866\n",
      "Epoch:3738\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.067389\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002580\n",
      "Epoch:3739\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.004623\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003470\n",
      "Epoch:3740\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.099452\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003243\n",
      "Epoch:3741\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.154999\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003461\n",
      "Epoch:3742\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.005349\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002786\n",
      "Epoch:3743\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046016\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002681\n",
      "Epoch:3744\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.029180\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003196\n",
      "Epoch:3745\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.008007\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003191\n",
      "Epoch:3746\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.117064\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002883\n",
      "Epoch:3747\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033596\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003480\n",
      "Epoch:3748\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.136850\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003663\n",
      "Epoch:3749\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043551\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002935\n",
      "Epoch:3750\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.011261\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002898\n",
      "Epoch:3751\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.106858\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003052\n",
      "Epoch:3752\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.063619\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002458\n",
      "Epoch:3753\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.145740\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002399\n",
      "Epoch:3754\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.036021\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004407\n",
      "Epoch:3755\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027554\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003744\n",
      "Epoch:3756\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053776\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002982\n",
      "Epoch:3757\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.119933\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002721\n",
      "Epoch:3758\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.098211\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003269\n",
      "Epoch:3759\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.128689\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003333\n",
      "Epoch:3760\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.132573\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003504\n",
      "Epoch:3761\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049747\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003510\n",
      "Epoch:3762\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.007556\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003160\n",
      "Epoch:3763\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032715\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002836\n",
      "Epoch:3764\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042523\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003488\n",
      "Epoch:3765\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.110699\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002789\n",
      "Epoch:3766\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027912\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002985\n",
      "Epoch:3767\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.101477\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003603\n",
      "Epoch:3768\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.085624\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003625\n",
      "Epoch:3769\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.009473\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003412\n",
      "Epoch:3770\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025421\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003126\n",
      "Epoch:3771\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.061779\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003289\n",
      "Epoch:3772\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.050441\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002732\n",
      "Epoch:3773\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.120752\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002704\n",
      "Epoch:3774\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.131643\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003256\n",
      "Epoch:3775\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.123292\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003180\n",
      "Epoch:3776\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.146731\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003151\n",
      "Epoch:3777\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044610\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003882\n",
      "Epoch:3778\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018008\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002749\n",
      "Epoch:3779\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026133\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003184\n",
      "Epoch:3780\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.113709\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002846\n",
      "Epoch:3781\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.098581\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003233\n",
      "Epoch:3782\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034825\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003168\n",
      "Epoch:3783\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027696\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002952\n",
      "Epoch:3784\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.123119\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002934\n",
      "Epoch:3785\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031513\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003310\n",
      "Epoch:3786\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064457\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002766\n",
      "Epoch:3787\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.120202\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003004\n",
      "Epoch:3788\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127695\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002994\n",
      "Epoch:3789\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035643\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003737\n",
      "Epoch:3790\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067000\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3791\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.074454\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002579\n",
      "Epoch:3792\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.105111\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002532\n",
      "Epoch:3793\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.147599\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003007\n",
      "Epoch:3794\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029636\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003588\n",
      "Epoch:3795\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.010464\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002873\n",
      "Epoch:3796\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.097968\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002722\n",
      "Epoch:3797\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013159\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003038\n",
      "Epoch:3798\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.060991\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003071\n",
      "Epoch:3799\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048660\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003171\n",
      "Epoch:3800\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.061421\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003516\n",
      "Epoch:3801\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048820\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003083\n",
      "Epoch:3802\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.028858\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002736\n",
      "Epoch:3803\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034419\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002685\n",
      "Epoch:3804\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048161\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003131\n",
      "Epoch:3805\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.038974\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004049\n",
      "Epoch:3806\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.018377\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003123\n",
      "Epoch:3807\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053684\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002735\n",
      "Epoch:3808\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023618\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002629\n",
      "Epoch:3809\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.120085\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002615\n",
      "Epoch:3810\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030230\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003847\n",
      "Epoch:3811\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.114013\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003579\n",
      "Epoch:3812\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028562\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002988\n",
      "Epoch:3813\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041531\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003169\n",
      "Epoch:3814\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.118258\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002792\n",
      "Epoch:3815\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040322\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002950\n",
      "Epoch:3816\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035602\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003406\n",
      "Epoch:3817\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.018906\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003394\n",
      "Epoch:3818\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027942\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003004\n",
      "Epoch:3819\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.009501\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003139\n",
      "Epoch:3820\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.159119\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002908\n",
      "Epoch:3821\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040374\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003082\n",
      "Epoch:3822\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.096659\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003097\n",
      "Epoch:3823\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025281\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003247\n",
      "Epoch:3824\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.006825\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003242\n",
      "Epoch:3825\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044456\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003065\n",
      "Epoch:3826\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.098671\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002530\n",
      "Epoch:3827\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028693\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003209\n",
      "Epoch:3828\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.076766\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003222\n",
      "Epoch:3829\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054854\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002693\n",
      "Epoch:3830\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.125420\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002886\n",
      "Epoch:3831\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019515\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002940\n",
      "Epoch:3832\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.077581\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003551\n",
      "Epoch:3833\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030478\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002844\n",
      "Epoch:3834\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.147668\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002938\n",
      "Epoch:3835\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.098390\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003272\n",
      "Epoch:3836\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.135340\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003171\n",
      "Epoch:3837\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.077565\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004476\n",
      "Epoch:3838\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025491\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002977\n",
      "Epoch:3839\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.010304\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002474\n",
      "Epoch:3840\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068629\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002645\n",
      "Epoch:3841\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017972\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002520\n",
      "Epoch:3842\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.095095\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002717\n",
      "Epoch:3843\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.107819\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003374\n",
      "Epoch:3844\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.133883\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003873\n",
      "Epoch:3845\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035890\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002822\n",
      "Epoch:3846\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037190\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002601\n",
      "Epoch:3847\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062333\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002982\n",
      "Epoch:3848\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.009238\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003156\n",
      "Epoch:3849\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.129345\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002845\n",
      "Epoch:3850\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041988\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002926\n",
      "Epoch:3851\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.155914\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003225\n",
      "Epoch:3852\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027346\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003327\n",
      "Epoch:3853\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.088735\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003503\n",
      "Epoch:3854\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.119693\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003307\n",
      "Epoch:3855\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026438\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003042\n",
      "Epoch:3856\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036935\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002609\n",
      "Epoch:3857\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053331\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002843\n",
      "Epoch:3858\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.107179\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002798\n",
      "Epoch:3859\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.146917\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003552\n",
      "Epoch:3860\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043827\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002434\n",
      "Epoch:3861\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044456\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002648\n",
      "Epoch:3862\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.007156\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003193\n",
      "Epoch:3863\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.141419\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003055\n",
      "Epoch:3864\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.047177\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002774\n",
      "Epoch:3865\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.083178\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002919\n",
      "Epoch:3866\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.129540\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002559\n",
      "Epoch:3867\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.108707\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003071\n",
      "Epoch:3868\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.103212\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003667\n",
      "Epoch:3869\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.003166\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002923\n",
      "Epoch:3870\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.069414\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002700\n",
      "Epoch:3871\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.104746\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002697\n",
      "Epoch:3872\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059154\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003119\n",
      "Epoch:3873\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.134913\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003015\n",
      "Epoch:3874\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025013\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003677\n",
      "Epoch:3875\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.002282\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003531\n",
      "Epoch:3876\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054423\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003046\n",
      "Epoch:3877\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016284\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002500\n",
      "Epoch:3878\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.076752\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002621\n",
      "Epoch:3879\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.004141\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004140\n",
      "Epoch:3880\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047187\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003876\n",
      "Epoch:3881\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.055291\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002757\n",
      "Epoch:3882\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062606\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002330\n",
      "Epoch:3883\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031950\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002763\n",
      "Epoch:3884\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057781\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002857\n",
      "Epoch:3885\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059722\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003556\n",
      "Epoch:3886\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.104081\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002685\n",
      "Epoch:3887\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.071524\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002806\n",
      "Epoch:3888\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016867\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3889\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015777\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002857\n",
      "Epoch:3890\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015845\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002716\n",
      "Epoch:3891\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018275\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002863\n",
      "Epoch:3892\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017169\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003163\n",
      "Epoch:3893\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043987\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003303\n",
      "Epoch:3894\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.132476\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002954\n",
      "Epoch:3895\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.092522\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003033\n",
      "Epoch:3896\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.010500\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002646\n",
      "Epoch:3897\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037032\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002779\n",
      "Epoch:3898\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017565\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003102\n",
      "Epoch:3899\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.007089\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003158\n",
      "Epoch:3900\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034014\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002510\n",
      "Epoch:3901\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066534\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002600\n",
      "Epoch:3902\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035554\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002442\n",
      "Epoch:3903\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068368\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002992\n",
      "Epoch:3904\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022126\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002692\n",
      "Epoch:3905\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011141\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002707\n",
      "Epoch:3906\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.090203\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003136\n",
      "Epoch:3907\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051103\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003873\n",
      "Epoch:3908\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030221\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003050\n",
      "Epoch:3909\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.079566\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003261\n",
      "Epoch:3910\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027893\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002783\n",
      "Epoch:3911\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045343\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002714\n",
      "Epoch:3912\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.071407\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003249\n",
      "Epoch:3913\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033523\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002639\n",
      "Epoch:3914\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.151752\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002332\n",
      "Epoch:3915\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046505\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003136\n",
      "Epoch:3916\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010048\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003392\n",
      "Epoch:3917\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.005787\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003306\n",
      "Epoch:3918\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.165771\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002997\n",
      "Epoch:3919\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.103957\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003481\n",
      "Epoch:3920\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040638\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003758\n",
      "Epoch:3921\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021763\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003024\n",
      "Epoch:3922\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.002404\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002998\n",
      "Epoch:3923\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.001944\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003181\n",
      "Epoch:3924\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.094267\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002760\n",
      "Epoch:3925\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.058186\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003042\n",
      "Epoch:3926\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078090\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003331\n",
      "Epoch:3927\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.005970\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002577\n",
      "Epoch:3928\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.009589\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002374\n",
      "Epoch:3929\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.060691\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003071\n",
      "Epoch:3930\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027529\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002865\n",
      "Epoch:3931\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.133861\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002750\n",
      "Epoch:3932\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062458\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003463\n",
      "Epoch:3933\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.001150\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002808\n",
      "Epoch:3934\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.038984\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002593\n",
      "Epoch:3935\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.092589\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002712\n",
      "Epoch:3936\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.068147\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002456\n",
      "Epoch:3937\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062738\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002970\n",
      "Epoch:3938\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062954\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003416\n",
      "Epoch:3939\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053072\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003162\n",
      "Epoch:3940\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015530\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002746\n",
      "Epoch:3941\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045103\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002917\n",
      "Epoch:3942\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022771\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002800\n",
      "Epoch:3943\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040313\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002513\n",
      "Epoch:3944\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010305\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002919\n",
      "Epoch:3945\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023921\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003295\n",
      "Epoch:3946\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054940\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003559\n",
      "Epoch:3947\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.141856\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002635\n",
      "Epoch:3948\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026886\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003379\n",
      "Epoch:3949\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.102129\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003571\n",
      "Epoch:3950\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.011496\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003583\n",
      "Epoch:3951\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015185\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002885\n",
      "Epoch:3952\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013780\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002747\n",
      "Epoch:3953\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039273\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002750\n",
      "Epoch:3954\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047297\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002950\n",
      "Epoch:3955\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.095598\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002709\n",
      "Epoch:3956\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.065784\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003180\n",
      "Epoch:3957\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021335\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003041\n",
      "Epoch:3958\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.105126\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002969\n",
      "Epoch:3959\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.084821\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003500\n",
      "Epoch:3960\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017453\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002884\n",
      "Epoch:3961\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.008211\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002380\n",
      "Epoch:3962\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.128018\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002611\n",
      "Epoch:3963\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024491\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003070\n",
      "Epoch:3964\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023595\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003024\n",
      "Epoch:3965\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.115417\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002669\n",
      "Epoch:3966\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025805\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003206\n",
      "Epoch:3967\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.101411\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002876\n",
      "Epoch:3968\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.097162\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002885\n",
      "Epoch:3969\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053893\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003058\n",
      "Epoch:3970\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.038609\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003149\n",
      "Epoch:3971\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033373\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002771\n",
      "Epoch:3972\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.006570\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002818\n",
      "Epoch:3973\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.004650\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002877\n",
      "Epoch:3974\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030814\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002762\n",
      "Epoch:3975\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.132792\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002743\n",
      "Epoch:3976\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019986\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004057\n",
      "Epoch:3977\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.065233\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003491\n",
      "Epoch:3978\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049661\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002798\n",
      "Epoch:3979\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.009966\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003031\n",
      "Epoch:3980\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.052348\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003300\n",
      "Epoch:3981\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034905\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002979\n",
      "Epoch:3982\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045351\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003334\n",
      "Epoch:3983\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.043624\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003174\n",
      "Epoch:3984\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022264\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003010\n",
      "Epoch:3985\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.122402\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002837\n",
      "Epoch:3986\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.004737\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003201\n",
      "Epoch:3987\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019440\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003059\n",
      "Epoch:3988\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010257\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002595\n",
      "Epoch:3989\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020315\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002835\n",
      "Epoch:3990\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.001907\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003597\n",
      "Epoch:3991\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.109886\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003082\n",
      "Epoch:3992\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025747\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003232\n",
      "Epoch:3993\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019981\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002727\n",
      "Epoch:3994\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.177856\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002759\n",
      "Epoch:3995\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.105837\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003012\n",
      "Epoch:3996\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023567\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003381\n",
      "Epoch:3997\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041631\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002807\n",
      "Epoch:3998\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053502\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:3999\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.014946\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002913\n",
      "Epoch:4000\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.162599\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002598\n",
      "Epoch:4001\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023215\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003150\n",
      "Epoch:4002\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.007189\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003272\n",
      "Epoch:4003\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.012329\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003061\n",
      "Epoch:4004\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066510\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002792\n",
      "Epoch:4005\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045020\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002705\n",
      "Epoch:4006\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046511\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003093\n",
      "Epoch:4007\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.079635\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003356\n",
      "Epoch:4008\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.126598\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002680\n",
      "Epoch:4009\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.149896\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002628\n",
      "Epoch:4010\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041069\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003856\n",
      "Epoch:4011\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031090\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003339\n",
      "Epoch:4012\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057754\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002907\n",
      "Epoch:4013\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033350\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002726\n",
      "Epoch:4014\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.158625\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002405\n",
      "Epoch:4015\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.065485\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003392\n",
      "Epoch:4016\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.104136\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003124\n",
      "Epoch:4017\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016576\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002312\n",
      "Epoch:4018\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.118546\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002721\n",
      "Epoch:4019\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.065238\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003428\n",
      "Epoch:4020\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.131183\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002748\n",
      "Epoch:4021\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.160653\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003155\n",
      "Epoch:4022\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.103042\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002965\n",
      "Epoch:4023\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.008608\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003110\n",
      "Epoch:4024\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.154823\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003097\n",
      "Epoch:4025\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.130546\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002971\n",
      "Epoch:4026\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.081883\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003312\n",
      "Epoch:4027\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050752\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003158\n",
      "Epoch:4028\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022656\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002789\n",
      "Epoch:4029\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013617\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003064\n",
      "Epoch:4030\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023384\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003334\n",
      "Epoch:4031\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013507\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002729\n",
      "Epoch:4032\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.121332\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002503\n",
      "Epoch:4033\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030324\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003000\n",
      "Epoch:4034\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.170758\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003191\n",
      "Epoch:4035\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030423\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003764\n",
      "Epoch:4036\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066657\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003430\n",
      "Epoch:4037\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.003155\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002447\n",
      "Epoch:4038\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.075396\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002695\n",
      "Epoch:4039\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.101393\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003605\n",
      "Epoch:4040\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.112206\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002655\n",
      "Epoch:4041\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059288\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003347\n",
      "Epoch:4042\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.111841\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003193\n",
      "Epoch:4043\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037101\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003263\n",
      "Epoch:4044\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.189674\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002242\n",
      "Epoch:4045\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057323\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003124\n",
      "Epoch:4046\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068456\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003431\n",
      "Epoch:4047\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.056089\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002944\n",
      "Epoch:4048\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.170579\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002324\n",
      "Epoch:4049\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023574\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003174\n",
      "Epoch:4050\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.106873\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003045\n",
      "Epoch:4051\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032176\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003235\n",
      "Epoch:4052\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.126148\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003271\n",
      "Epoch:4053\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.150881\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003017\n",
      "Epoch:4054\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.091227\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002773\n",
      "Epoch:4055\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031998\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002735\n",
      "Epoch:4056\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.111468\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002752\n",
      "Epoch:4057\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036534\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002817\n",
      "Epoch:4058\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020466\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003100\n",
      "Epoch:4059\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.071438\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003250\n",
      "Epoch:4060\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033512\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002741\n",
      "Epoch:4061\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010503\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002489\n",
      "Epoch:4062\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051273\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002704\n",
      "Epoch:4063\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015112\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002734\n",
      "Epoch:4064\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.092437\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002827\n",
      "Epoch:4065\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041368\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003795\n",
      "Epoch:4066\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.139803\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002636\n",
      "Epoch:4067\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.124266\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003195\n",
      "Epoch:4068\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015569\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003485\n",
      "Epoch:4069\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019719\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002895\n",
      "Epoch:4070\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.143667\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002727\n",
      "Epoch:4071\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.086593\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003452\n",
      "Epoch:4072\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.018723\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002895\n",
      "Epoch:4073\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.116994\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002717\n",
      "Epoch:4074\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039709\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002767\n",
      "Epoch:4075\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.118513\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003018\n",
      "Epoch:4076\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.052903\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003504\n",
      "Epoch:4077\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.089561\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003063\n",
      "Epoch:4078\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.056370\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002832\n",
      "Epoch:4079\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034183\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003529\n",
      "Epoch:4080\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.123134\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002955\n",
      "Epoch:4081\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028639\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002721\n",
      "Epoch:4082\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035712\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003033\n",
      "Epoch:4083\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022958\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003321\n",
      "Epoch:4084\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.053569\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002597\n",
      "Epoch:4085\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.006323\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002971\n",
      "Epoch:4086\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.011014\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003193\n",
      "Epoch:4087\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013276\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003118\n",
      "Epoch:4088\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035851\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003180\n",
      "Epoch:4089\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067204\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003133\n",
      "Epoch:4090\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023292\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002645\n",
      "Epoch:4091\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.089946\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002617\n",
      "Epoch:4092\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.104547\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002991\n",
      "Epoch:4093\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.008128\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003124\n",
      "Epoch:4094\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050294\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002795\n",
      "Epoch:4095\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030230\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002649\n",
      "Epoch:4096\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025490\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002712\n",
      "Epoch:4097\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003012\n",
      "Epoch:4098\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046325\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003036\n",
      "Epoch:4099\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.006055\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003092\n",
      "Epoch:4100\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023067\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002934\n",
      "Epoch:4101\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025427\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002889\n",
      "Epoch:4102\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.115331\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002938\n",
      "Epoch:4103\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.104725\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003179\n",
      "Epoch:4104\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023506\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003182\n",
      "Epoch:4105\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.134597\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002786\n",
      "Epoch:4106\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035285\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002737\n",
      "Epoch:4107\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034222\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002910\n",
      "Epoch:4108\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.096373\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002686\n",
      "Epoch:4109\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.128794\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003100\n",
      "Epoch:4110\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022729\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003249\n",
      "Epoch:4111\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078087\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002566\n",
      "Epoch:4112\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024896\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002286\n",
      "Epoch:4113\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.124713\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002906\n",
      "Epoch:4114\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037880\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003374\n",
      "Epoch:4115\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.094896\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003065\n",
      "Epoch:4116\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.131736\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002792\n",
      "Epoch:4117\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.117306\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003585\n",
      "Epoch:4118\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.001080\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003363\n",
      "Epoch:4119\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027082\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002554\n",
      "Epoch:4120\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019937\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002698\n",
      "Epoch:4121\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.099528\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003015\n",
      "Epoch:4122\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.058866\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003560\n",
      "Epoch:4123\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059451\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002681\n",
      "Epoch:4124\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051297\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002905\n",
      "Epoch:4125\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031374\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003320\n",
      "Epoch:4126\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.123936\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002871\n",
      "Epoch:4127\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.153759\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002722\n",
      "Epoch:4128\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.112091\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003153\n",
      "Epoch:4129\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027284\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002859\n",
      "Epoch:4130\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032472\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002776\n",
      "Epoch:4131\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034092\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002519\n",
      "Epoch:4132\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069163\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003437\n",
      "Epoch:4133\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059074\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002740\n",
      "Epoch:4134\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021294\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002117\n",
      "Epoch:4135\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.016605\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002642\n",
      "Epoch:4136\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060618\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002799\n",
      "Epoch:4137\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072477\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002892\n",
      "Epoch:4138\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.104494\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002541\n",
      "Epoch:4139\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.075114\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003335\n",
      "Epoch:4140\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023081\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002929\n",
      "Epoch:4141\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015756\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002401\n",
      "Epoch:4142\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.091177\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002663\n",
      "Epoch:4143\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010832\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002821\n",
      "Epoch:4144\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.111132\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002917\n",
      "Epoch:4145\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.142759\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002883\n",
      "Epoch:4146\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067262\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003822\n",
      "Epoch:4147\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060005\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002803\n",
      "Epoch:4148\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.075684\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002425\n",
      "Epoch:4149\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.131244\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002606\n",
      "Epoch:4150\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.109257\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003670\n",
      "Epoch:4151\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013667\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002631\n",
      "Epoch:4152\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017120\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002649\n",
      "Epoch:4153\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.110607\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002257\n",
      "Epoch:4154\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.094721\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002999\n",
      "Epoch:4155\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068284\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003587\n",
      "Epoch:4156\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.090296\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002704\n",
      "Epoch:4157\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050273\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002845\n",
      "Epoch:4158\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010219\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003174\n",
      "Epoch:4159\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024629\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003385\n",
      "Epoch:4160\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.071987\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003426\n",
      "Epoch:4161\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010745\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002666\n",
      "Epoch:4162\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019412\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002817\n",
      "Epoch:4163\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037152\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003237\n",
      "Epoch:4164\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.141634\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002449\n",
      "Epoch:4165\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032369\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003372\n",
      "Epoch:4166\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019756\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003701\n",
      "Epoch:4167\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.056872\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002921\n",
      "Epoch:4168\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030908\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002575\n",
      "Epoch:4169\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.093627\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002994\n",
      "Epoch:4170\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017599\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002788\n",
      "Epoch:4171\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043232\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002827\n",
      "Epoch:4172\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.152136\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002869\n",
      "Epoch:4173\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045414\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003451\n",
      "Epoch:4174\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.004867\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002773\n",
      "Epoch:4175\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.143806\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002206\n",
      "Epoch:4176\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.128013\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003256\n",
      "Epoch:4177\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.093655\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003576\n",
      "Epoch:4178\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.008713\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002362\n",
      "Epoch:4179\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.121471\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002546\n",
      "Epoch:4180\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.067756\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003289\n",
      "Epoch:4181\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033099\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002776\n",
      "Epoch:4182\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033133\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002961\n",
      "Epoch:4183\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.094745\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002993\n",
      "Epoch:4184\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.018964\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003177\n",
      "Epoch:4185\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.008007\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002714\n",
      "Epoch:4186\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013958\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003000\n",
      "Epoch:4187\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.122529\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003466\n",
      "Epoch:4188\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.173207\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003259\n",
      "Epoch:4189\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.123938\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002765\n",
      "Epoch:4190\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.100415\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003260\n",
      "Epoch:4191\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.117576\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003346\n",
      "Epoch:4192\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062701\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003434\n",
      "Epoch:4193\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046336\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002959\n",
      "Epoch:4194\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.113370\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002796\n",
      "Epoch:4195\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.092055\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002967\n",
      "Epoch:4196\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.094750\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003012\n",
      "Epoch:4197\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.120003\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003339\n",
      "Epoch:4198\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.094227\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003293\n",
      "Epoch:4199\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.026694\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4200\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.119755\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002958\n",
      "Epoch:4201\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.129499\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003066\n",
      "Epoch:4202\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022985\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004058\n",
      "Epoch:4203\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043855\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003387\n",
      "Epoch:4204\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.095069\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003212\n",
      "Epoch:4205\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.073912\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002571\n",
      "Epoch:4206\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031633\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002489\n",
      "Epoch:4207\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045106\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002832\n",
      "Epoch:4208\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.009795\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002813\n",
      "Epoch:4209\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.079997\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003496\n",
      "Epoch:4210\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.002282\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002223\n",
      "Epoch:4211\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.051109\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002209\n",
      "Epoch:4212\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.103403\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003230\n",
      "Epoch:4213\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.095155\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003397\n",
      "Epoch:4214\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.058262\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003114\n",
      "Epoch:4215\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047743\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002579\n",
      "Epoch:4216\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.007224\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002993\n",
      "Epoch:4217\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.166726\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003102\n",
      "Epoch:4218\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020518\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003727\n",
      "Epoch:4219\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.061874\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002828\n",
      "Epoch:4220\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.056676\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002695\n",
      "Epoch:4221\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035905\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002590\n",
      "Epoch:4222\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049261\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002633\n",
      "Epoch:4223\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.080272\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002908\n",
      "Epoch:4224\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.100821\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002413\n",
      "Epoch:4225\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024942\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003304\n",
      "Epoch:4226\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013962\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002753\n",
      "Epoch:4227\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022324\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002398\n",
      "Epoch:4228\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.021564\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002573\n",
      "Epoch:4229\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.137635\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002860\n",
      "Epoch:4230\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027855\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003579\n",
      "Epoch:4231\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.091532\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002847\n",
      "Epoch:4232\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.065467\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002286\n",
      "Epoch:4233\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030452\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002587\n",
      "Epoch:4234\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.097047\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003276\n",
      "Epoch:4235\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042325\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002671\n",
      "Epoch:4236\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.139603\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002368\n",
      "Epoch:4237\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.122342\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003021\n",
      "Epoch:4238\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.089134\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003770\n",
      "Epoch:4239\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.074811\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003979\n",
      "Epoch:4240\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040095\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002729\n",
      "Epoch:4241\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013597\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002269\n",
      "Epoch:4242\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.135790\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002386\n",
      "Epoch:4243\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.188634\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002904\n",
      "Epoch:4244\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051672\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004476\n",
      "Epoch:4245\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032126\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003208\n",
      "Epoch:4246\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.105435\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002682\n",
      "Epoch:4247\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.022854\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003207\n",
      "Epoch:4248\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.095478\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002795\n",
      "Epoch:4249\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.119234\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002076\n",
      "Epoch:4250\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012354\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002780\n",
      "Epoch:4251\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025401\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003900\n",
      "Epoch:4252\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.082680\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002987\n",
      "Epoch:4253\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.006698\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002780\n",
      "Epoch:4254\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054155\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002767\n",
      "Epoch:4255\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.071804\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002648\n",
      "Epoch:4256\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030244\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003099\n",
      "Epoch:4257\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021081\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002898\n",
      "Epoch:4258\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.153378\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002585\n",
      "Epoch:4259\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.097346\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002667\n",
      "Epoch:4260\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.008997\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003219\n",
      "Epoch:4261\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.153789\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003442\n",
      "Epoch:4262\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068913\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002962\n",
      "Epoch:4263\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034433\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002714\n",
      "Epoch:4264\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.079031\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002253\n",
      "Epoch:4265\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.087087\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003185\n",
      "Epoch:4266\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.100940\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003648\n",
      "Epoch:4267\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064945\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002538\n",
      "Epoch:4268\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018390\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002554\n",
      "Epoch:4269\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.097684\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002976\n",
      "Epoch:4270\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.058100\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002637\n",
      "Epoch:4271\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.112123\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002828\n",
      "Epoch:4272\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067920\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003468\n",
      "Epoch:4273\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041116\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002561\n",
      "Epoch:4274\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035286\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002536\n",
      "Epoch:4275\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019610\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002990\n",
      "Epoch:4276\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.114931\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003166\n",
      "Epoch:4277\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046689\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002889\n",
      "Epoch:4278\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043842\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002753\n",
      "Epoch:4279\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.068992\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002437\n",
      "Epoch:4280\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040720\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002712\n",
      "Epoch:4281\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050654\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003366\n",
      "Epoch:4282\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072202\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002768\n",
      "Epoch:4283\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017707\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002185\n",
      "Epoch:4284\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024411\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002661\n",
      "Epoch:4285\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.100457\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002712\n",
      "Epoch:4286\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036788\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003040\n",
      "Epoch:4287\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052285\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002803\n",
      "Epoch:4288\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.109392\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003135\n",
      "Epoch:4289\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.052403\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003308\n",
      "Epoch:4290\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051893\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003499\n",
      "Epoch:4291\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.012049\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002796\n",
      "Epoch:4292\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040467\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002478\n",
      "Epoch:4293\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025253\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002708\n",
      "Epoch:4294\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.028716\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003025\n",
      "Epoch:4295\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.096644\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003025\n",
      "Epoch:4296\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013608\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002421\n",
      "Epoch:4297\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028952\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002334\n",
      "Epoch:4298\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057624\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002946\n",
      "Epoch:4299\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030630\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003056\n",
      "Epoch:4300\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.100081\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002540\n",
      "Epoch:4301\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.091248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002804\n",
      "Epoch:4302\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064957\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003291\n",
      "Epoch:4303\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.092325\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002416\n",
      "Epoch:4304\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051938\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002538\n",
      "Epoch:4305\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.021159\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003232\n",
      "Epoch:4306\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.038604\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002890\n",
      "Epoch:4307\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033106\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002732\n",
      "Epoch:4308\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.007942\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002635\n",
      "Epoch:4309\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057100\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003017\n",
      "Epoch:4310\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.042995\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002837\n",
      "Epoch:4311\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021727\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003181\n",
      "Epoch:4312\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035549\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002915\n",
      "Epoch:4313\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015281\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002593\n",
      "Epoch:4314\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028626\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002595\n",
      "Epoch:4315\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.098638\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003216\n",
      "Epoch:4316\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.086977\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003376\n",
      "Epoch:4317\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029898\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003170\n",
      "Epoch:4318\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029903\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002970\n",
      "Epoch:4319\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.134556\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002794\n",
      "Epoch:4320\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016116\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003033\n",
      "Epoch:4321\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052183\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002736\n",
      "Epoch:4322\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.007673\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003470\n",
      "Epoch:4323\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.073017\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003321\n",
      "Epoch:4324\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034510\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002534\n",
      "Epoch:4325\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072664\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002858\n",
      "Epoch:4326\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033185\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002573\n",
      "Epoch:4327\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.009216\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002766\n",
      "Epoch:4328\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034923\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002824\n",
      "Epoch:4329\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.075649\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002925\n",
      "Epoch:4330\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033528\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002740\n",
      "Epoch:4331\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.139519\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002323\n",
      "Epoch:4332\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.074945\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003171\n",
      "Epoch:4333\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.012476\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002647\n",
      "Epoch:4334\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019328\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002632\n",
      "Epoch:4335\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011221\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002478\n",
      "Epoch:4336\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.122521\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002902\n",
      "Epoch:4337\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.151118\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002902\n",
      "Epoch:4338\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.100173\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002987\n",
      "Epoch:4339\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032025\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003098\n",
      "Epoch:4340\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027806\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002921\n",
      "Epoch:4341\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032277\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003403\n",
      "Epoch:4342\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043808\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002973\n",
      "Epoch:4343\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.006863\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002339\n",
      "Epoch:4344\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018915\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002805\n",
      "Epoch:4345\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072800\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002956\n",
      "Epoch:4346\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.082818\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002750\n",
      "Epoch:4347\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.126035\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002466\n",
      "Epoch:4348\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045606\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002634\n",
      "Epoch:4349\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040073\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003109\n",
      "Epoch:4350\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.108108\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002526\n",
      "Epoch:4351\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025766\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002912\n",
      "Epoch:4352\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024255\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003430\n",
      "Epoch:4353\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.129441\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002832\n",
      "Epoch:4354\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033521\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002957\n",
      "Epoch:4355\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055700\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002819\n",
      "Epoch:4356\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.014433\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002966\n",
      "Epoch:4357\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.089766\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002606\n",
      "Epoch:4358\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.097858\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003036\n",
      "Epoch:4359\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.127513\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003412\n",
      "Epoch:4360\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028437\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003149\n",
      "Epoch:4361\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051172\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003101\n",
      "Epoch:4362\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019090\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002478\n",
      "Epoch:4363\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.049019\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002440\n",
      "Epoch:4364\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011592\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002620\n",
      "Epoch:4365\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.096632\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002851\n",
      "Epoch:4366\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.125030\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003417\n",
      "Epoch:4367\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.003663\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002440\n",
      "Epoch:4368\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036480\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002705\n",
      "Epoch:4369\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053670\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003334\n",
      "Epoch:4370\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.029506\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002570\n",
      "Epoch:4371\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039328\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002722\n",
      "Epoch:4372\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048388\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002684\n",
      "Epoch:4373\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046074\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002582\n",
      "Epoch:4374\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.130012\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003141\n",
      "Epoch:4375\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.000940\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003888\n",
      "Epoch:4376\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.058966\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002741\n",
      "Epoch:4377\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039687\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002192\n",
      "Epoch:4378\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033545\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002453\n",
      "Epoch:4379\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034588\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003576\n",
      "Epoch:4380\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.010438\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003002\n",
      "Epoch:4381\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020481\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002439\n",
      "Epoch:4382\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057965\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002306\n",
      "Epoch:4383\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031847\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002789\n",
      "Epoch:4384\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.136418\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002648\n",
      "Epoch:4385\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.091616\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003362\n",
      "Epoch:4386\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045668\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003357\n",
      "Epoch:4387\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.087431\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003090\n",
      "Epoch:4388\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028396\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002917\n",
      "Epoch:4389\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017781\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002904\n",
      "Epoch:4390\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.014009\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002565\n",
      "Epoch:4391\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025832\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002550\n",
      "Epoch:4392\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.097223\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002780\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:4393\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.152501\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003100\n",
      "Epoch:4394\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.008766\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003276\n",
      "Epoch:4395\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043527\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002971\n",
      "Epoch:4396\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020316\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002232\n",
      "Epoch:4397\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.167552\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002172\n",
      "Epoch:4398\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.028458\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003612\n",
      "Epoch:4399\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.112059\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003277\n",
      "Epoch:4400\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039358\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003225\n",
      "Epoch:4401\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.065083\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002567\n",
      "Epoch:4402\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.117973\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003208\n",
      "Epoch:4403\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021603\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003162\n",
      "Epoch:4404\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.052558\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003027\n",
      "Epoch:4405\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039495\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002559\n",
      "Epoch:4406\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010976\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002371\n",
      "Epoch:4407\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.107862\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002610\n",
      "Epoch:4408\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.113730\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003809\n",
      "Epoch:4409\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043057\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002628\n",
      "Epoch:4410\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062547\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002298\n",
      "Epoch:4411\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020915\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002341\n",
      "Epoch:4412\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030142\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002666\n",
      "Epoch:4413\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050283\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002827\n",
      "Epoch:4414\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.132897\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002569\n",
      "Epoch:4415\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078163\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003264\n",
      "Epoch:4416\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038994\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002407\n",
      "Epoch:4417\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.141444\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002402\n",
      "Epoch:4418\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030421\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003486\n",
      "Epoch:4419\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.005760\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003197\n",
      "Epoch:4420\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054928\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002710\n",
      "Epoch:4421\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032764\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002549\n",
      "Epoch:4422\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059664\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003198\n",
      "Epoch:4423\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.034482\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003178\n",
      "Epoch:4424\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.055790\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003189\n",
      "Epoch:4425\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.011773\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002274\n",
      "Epoch:4426\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.164335\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002289\n",
      "Epoch:4427\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.082134\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003366\n",
      "Epoch:4428\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023948\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003639\n",
      "Epoch:4429\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.064198\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002758\n",
      "Epoch:4430\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.147504\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003145\n",
      "Epoch:4431\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040091\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003096\n",
      "Epoch:4432\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.119086\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002897\n",
      "Epoch:4433\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062865\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002782\n",
      "Epoch:4434\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018999\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002426\n",
      "Epoch:4435\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.129657\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002526\n",
      "Epoch:4436\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019771\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003840\n",
      "Epoch:4437\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.007638\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003346\n",
      "Epoch:4438\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032523\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002494\n",
      "Epoch:4439\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.054271\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002189\n",
      "Epoch:4440\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.091307\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003145\n",
      "Epoch:4441\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.054648\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003388\n",
      "Epoch:4442\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040213\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002387\n",
      "Epoch:4443\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033879\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002275\n",
      "Epoch:4444\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.131307\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002425\n",
      "Epoch:4445\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.010926\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004224\n",
      "Epoch:4446\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.079687\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003351\n",
      "Epoch:4447\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011023\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002139\n",
      "Epoch:4448\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062202\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002433\n",
      "Epoch:4449\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.002424\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003557\n",
      "Epoch:4450\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032584\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003604\n",
      "Epoch:4451\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017060\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003149\n",
      "Epoch:4452\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.102537\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002643\n",
      "Epoch:4453\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.052172\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002828\n",
      "Epoch:4454\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052658\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002662\n",
      "Epoch:4455\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061963\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002609\n",
      "Epoch:4456\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.032562\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003748\n",
      "Epoch:4457\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054475\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003093\n",
      "Epoch:4458\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.076459\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003027\n",
      "Epoch:4459\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.149609\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002426\n",
      "Epoch:4460\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.021536\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003055\n",
      "Epoch:4461\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.118896\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003306\n",
      "Epoch:4462\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032522\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002938\n",
      "Epoch:4463\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036815\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002451\n",
      "Epoch:4464\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033711\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002999\n",
      "Epoch:4465\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.055601\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003563\n",
      "Epoch:4466\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078089\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002979\n",
      "Epoch:4467\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.011381\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002447\n",
      "Epoch:4468\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015867\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002540\n",
      "Epoch:4469\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.153841\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002627\n",
      "Epoch:4470\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.023707\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004660\n",
      "Epoch:4471\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027157\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003617\n",
      "Epoch:4472\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049288\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002646\n",
      "Epoch:4473\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034662\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002243\n",
      "Epoch:4474\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.110176\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002756\n",
      "Epoch:4475\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051897\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003525\n",
      "Epoch:4476\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.115471\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003009\n",
      "Epoch:4477\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.060218\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002223\n",
      "Epoch:4478\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.108133\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002388\n",
      "Epoch:4479\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.057857\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002795\n",
      "Epoch:4480\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025672\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003277\n",
      "Epoch:4481\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.116211\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002822\n",
      "Epoch:4482\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.092510\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002726\n",
      "Epoch:4483\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024505\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002871\n",
      "Epoch:4484\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013387\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003173\n",
      "Epoch:4485\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.069873\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003002\n",
      "Epoch:4486\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019159\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002922\n",
      "Epoch:4487\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013721\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002459\n",
      "Epoch:4488\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002790\n",
      "Epoch:4489\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.094592\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002923\n",
      "Epoch:4490\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021031\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003186\n",
      "Epoch:4491\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.097091\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002728\n",
      "Epoch:4492\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020258\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002838\n",
      "Epoch:4493\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036003\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002767\n",
      "Epoch:4494\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.109727\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002196\n",
      "Epoch:4495\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027266\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002571\n",
      "Epoch:4496\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.115982\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002764\n",
      "Epoch:4497\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026474\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003482\n",
      "Epoch:4498\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043559\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002689\n",
      "Epoch:4499\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.149560\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002653\n",
      "Epoch:4500\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067802\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002833\n",
      "Epoch:4501\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.122894\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002517\n",
      "Epoch:4502\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.007238\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003177\n",
      "Epoch:4503\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029837\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003109\n",
      "Epoch:4504\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039150\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002665\n",
      "Epoch:4505\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013501\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002401\n",
      "Epoch:4506\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.119628\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002641\n",
      "Epoch:4507\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041960\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002901\n",
      "Epoch:4508\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.001461\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002737\n",
      "Epoch:4509\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.092143\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003134\n",
      "Epoch:4510\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.087379\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003312\n",
      "Epoch:4511\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.106427\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002253\n",
      "Epoch:4512\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.052238\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002694\n",
      "Epoch:4513\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.012908\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003581\n",
      "Epoch:4514\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039702\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003315\n",
      "Epoch:4515\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.117964\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002673\n",
      "Epoch:4516\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.114215\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003012\n",
      "Epoch:4517\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.069688\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003301\n",
      "Epoch:4518\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020320\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003024\n",
      "Epoch:4519\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041423\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002744\n",
      "Epoch:4520\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.038753\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002396\n",
      "Epoch:4521\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023544\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002993\n",
      "Epoch:4522\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.099768\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002645\n",
      "Epoch:4523\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.097311\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003131\n",
      "Epoch:4524\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.172134\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002399\n",
      "Epoch:4525\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.090752\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003222\n",
      "Epoch:4526\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046527\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003618\n",
      "Epoch:4527\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.079236\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002894\n",
      "Epoch:4528\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.072951\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002255\n",
      "Epoch:4529\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.003129\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002963\n",
      "Epoch:4530\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037449\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003434\n",
      "Epoch:4531\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.002761\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002559\n",
      "Epoch:4532\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.073950\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002556\n",
      "Epoch:4533\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.106467\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002183\n",
      "Epoch:4534\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.008265\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003216\n",
      "Epoch:4535\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027515\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003771\n",
      "Epoch:4536\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.004229\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002526\n",
      "Epoch:4537\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040379\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002614\n",
      "Epoch:4538\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.014015\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002990\n",
      "Epoch:4539\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046484\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002754\n",
      "Epoch:4540\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015938\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003003\n",
      "Epoch:4541\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044939\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003156\n",
      "Epoch:4542\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.011114\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002587\n",
      "Epoch:4543\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020917\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002489\n",
      "Epoch:4544\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030043\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002787\n",
      "Epoch:4545\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.118011\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002692\n",
      "Epoch:4546\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.083887\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003045\n",
      "Epoch:4547\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.087156\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003253\n",
      "Epoch:4548\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.149866\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002009\n",
      "Epoch:4549\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.009433\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003051\n",
      "Epoch:4550\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.085519\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002882\n",
      "Epoch:4551\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.070972\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003262\n",
      "Epoch:4552\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029031\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003145\n",
      "Epoch:4553\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.100536\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002646\n",
      "Epoch:4554\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.100458\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002852\n",
      "Epoch:4555\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.007986\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003783\n",
      "Epoch:4556\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.120742\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003144\n",
      "Epoch:4557\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.177254\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002202\n",
      "Epoch:4558\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017308\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002460\n",
      "Epoch:4559\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.003177\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002830\n",
      "Epoch:4560\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.090947\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002634\n",
      "Epoch:4561\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.092700\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002402\n",
      "Epoch:4562\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013754\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002988\n",
      "Epoch:4563\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048215\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002814\n",
      "Epoch:4564\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017910\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003146\n",
      "Epoch:4565\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.106801\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002897\n",
      "Epoch:4566\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.111443\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002685\n",
      "Epoch:4567\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015157\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003203\n",
      "Epoch:4568\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043759\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003023\n",
      "Epoch:4569\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.129715\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002841\n",
      "Epoch:4570\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.065306\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002694\n",
      "Epoch:4571\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017313\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002445\n",
      "Epoch:4572\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.100557\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002787\n",
      "Epoch:4573\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.009204\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003779\n",
      "Epoch:4574\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049744\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003099\n",
      "Epoch:4575\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019889\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002610\n",
      "Epoch:4576\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.116583\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002077\n",
      "Epoch:4577\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.113968\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002590\n",
      "Epoch:4578\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027930\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003037\n",
      "Epoch:4579\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029818\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002837\n",
      "Epoch:4580\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035293\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002618\n",
      "Epoch:4581\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021290\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002838\n",
      "Epoch:4582\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.105680\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002869\n",
      "Epoch:4583\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.108010\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003009\n",
      "Epoch:4584\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.052485\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002931\n",
      "Epoch:4585\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027456\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002347\n",
      "Epoch:4586\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.087962\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002795\n",
      "Epoch:4587\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019719\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002958\n",
      "Epoch:4588\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.095456\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002622\n",
      "Epoch:4589\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078732\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002787\n",
      "Epoch:4590\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.122812\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002460\n",
      "Epoch:4591\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003465\n",
      "Epoch:4592\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054560\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003235\n",
      "Epoch:4593\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.175285\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002378\n",
      "Epoch:4594\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.080554\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002949\n",
      "Epoch:4595\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.093380\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002468\n",
      "Epoch:4596\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.097082\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002924\n",
      "Epoch:4597\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021019\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003523\n",
      "Epoch:4598\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.002178\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002721\n",
      "Epoch:4599\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.035241\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002489\n",
      "Epoch:4600\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.006145\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003120\n",
      "Epoch:4601\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.071054\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003201\n",
      "Epoch:4602\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.038627\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002497\n",
      "Epoch:4603\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048144\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002189\n",
      "Epoch:4604\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039945\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002627\n",
      "Epoch:4605\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.074488\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003682\n",
      "Epoch:4606\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019934\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002956\n",
      "Epoch:4607\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.008637\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002629\n",
      "Epoch:4608\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026887\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002481\n",
      "Epoch:4609\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.076126\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002357\n",
      "Epoch:4610\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.065103\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003311\n",
      "Epoch:4611\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.100546\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003260\n",
      "Epoch:4612\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025166\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002851\n",
      "Epoch:4613\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024174\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002942\n",
      "Epoch:4614\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064137\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002990\n",
      "Epoch:4615\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.124054\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002608\n",
      "Epoch:4616\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023205\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002930\n",
      "Epoch:4617\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.097377\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002868\n",
      "Epoch:4618\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.014946\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003060\n",
      "Epoch:4619\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024159\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002933\n",
      "Epoch:4620\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041075\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002464\n",
      "Epoch:4621\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.136255\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002712\n",
      "Epoch:4622\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.011114\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003653\n",
      "Epoch:4623\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062030\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003420\n",
      "Epoch:4624\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.114725\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002475\n",
      "Epoch:4625\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026313\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002832\n",
      "Epoch:4626\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046903\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002866\n",
      "Epoch:4627\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.009358\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002594\n",
      "Epoch:4628\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.123229\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002653\n",
      "Epoch:4629\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.009759\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002887\n",
      "Epoch:4630\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.011408\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003193\n",
      "Epoch:4631\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.001303\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002532\n",
      "Epoch:4632\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.039502\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002236\n",
      "Epoch:4633\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034538\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002538\n",
      "Epoch:4634\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.150919\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003305\n",
      "Epoch:4635\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.085223\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004338\n",
      "Epoch:4636\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.151041\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002795\n",
      "Epoch:4637\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012355\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002168\n",
      "Epoch:4638\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.092620\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002468\n",
      "Epoch:4639\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.089468\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003133\n",
      "Epoch:4640\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.077613\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002664\n",
      "Epoch:4641\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.094770\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002825\n",
      "Epoch:4642\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019418\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002584\n",
      "Epoch:4643\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.017321\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002683\n",
      "Epoch:4644\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067108\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002799\n",
      "Epoch:4645\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054454\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002378\n",
      "Epoch:4646\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025238\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002136\n",
      "Epoch:4647\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.037921\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002443\n",
      "Epoch:4648\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078982\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003023\n",
      "Epoch:4649\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045341\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002711\n",
      "Epoch:4650\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.038071\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002408\n",
      "Epoch:4651\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.018701\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002557\n",
      "Epoch:4652\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.106720\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003496\n",
      "Epoch:4653\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051563\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003342\n",
      "Epoch:4654\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.031006\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002978\n",
      "Epoch:4655\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.005983\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002559\n",
      "Epoch:4656\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.124877\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002882\n",
      "Epoch:4657\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.086710\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003026\n",
      "Epoch:4658\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.101767\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002359\n",
      "Epoch:4659\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.153672\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002874\n",
      "Epoch:4660\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.091196\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003717\n",
      "Epoch:4661\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021776\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003290\n",
      "Epoch:4662\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.070566\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002906\n",
      "Epoch:4663\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.009919\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002178\n",
      "Epoch:4664\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.063600\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002422\n",
      "Epoch:4665\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.105319\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002763\n",
      "Epoch:4666\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035926\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003351\n",
      "Epoch:4667\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048211\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002682\n",
      "Epoch:4668\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033989\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002417\n",
      "Epoch:4669\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.095991\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002707\n",
      "Epoch:4670\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025961\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003646\n",
      "Epoch:4671\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.028669\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002891\n",
      "Epoch:4672\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.030669\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002398\n",
      "Epoch:4673\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.115991\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002819\n",
      "Epoch:4674\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.123414\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003532\n",
      "Epoch:4675\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024749\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002882\n",
      "Epoch:4676\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.134784\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002830\n",
      "Epoch:4677\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013405\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002790\n",
      "Epoch:4678\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.087837\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002908\n",
      "Epoch:4679\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013883\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002277\n",
      "Epoch:4680\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.016550\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002650\n",
      "Epoch:4681\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.087959\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003134\n",
      "Epoch:4682\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.080085\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002250\n",
      "Epoch:4683\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010819\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002699\n",
      "Epoch:4684\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.043016\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002852\n",
      "Epoch:4685\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024251\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002834\n",
      "Epoch:4686\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044529\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002816\n",
      "Epoch:4687\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.095776\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002479\n",
      "Epoch:4688\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.122906\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002892\n",
      "Epoch:4689\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018923\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003468\n",
      "Epoch:4690\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017044\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002499\n",
      "Epoch:4691\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.055834\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002560\n",
      "Epoch:4692\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.083544\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002671\n",
      "Epoch:4693\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.018734\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002547\n",
      "Epoch:4694\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.104472\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002429\n",
      "Epoch:4695\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027524\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002712\n",
      "Epoch:4696\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002901\n",
      "Epoch:4697\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.111118\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002849\n",
      "Epoch:4698\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.123616\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003262\n",
      "Epoch:4699\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057311\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003115\n",
      "Epoch:4700\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.098109\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002501\n",
      "Epoch:4701\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.096473\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002753\n",
      "Epoch:4702\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067504\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002890\n",
      "Epoch:4703\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026414\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002286\n",
      "Epoch:4704\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.141318\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002366\n",
      "Epoch:4705\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027004\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003285\n",
      "Epoch:4706\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.088176\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003738\n",
      "Epoch:4707\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.115143\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002682\n",
      "Epoch:4708\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.098352\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002411\n",
      "Epoch:4709\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.089870\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002736\n",
      "Epoch:4710\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066128\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003272\n",
      "Epoch:4711\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.143906\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002883\n",
      "Epoch:4712\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026354\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002741\n",
      "Epoch:4713\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.100955\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002622\n",
      "Epoch:4714\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046472\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003260\n",
      "Epoch:4715\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.113786\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003032\n",
      "Epoch:4716\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045465\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002208\n",
      "Epoch:4717\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010751\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002698\n",
      "Epoch:4718\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030977\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003153\n",
      "Epoch:4719\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.097747\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002440\n",
      "Epoch:4720\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.126940\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002755\n",
      "Epoch:4721\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039287\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003777\n",
      "Epoch:4722\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.150461\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002698\n",
      "Epoch:4723\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049918\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003517\n",
      "Epoch:4724\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.074558\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003706\n",
      "Epoch:4725\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.061855\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002209\n",
      "Epoch:4726\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.071545\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002684\n",
      "Epoch:4727\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026441\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002755\n",
      "Epoch:4728\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041583\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002554\n",
      "Epoch:4729\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.063200\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002871\n",
      "Epoch:4730\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127759\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002701\n",
      "Epoch:4731\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015021\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002780\n",
      "Epoch:4732\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.042287\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002431\n",
      "Epoch:4733\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018075\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002260\n",
      "Epoch:4734\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.027512\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003071\n",
      "Epoch:4735\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051639\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003228\n",
      "Epoch:4736\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.004648\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003020\n",
      "Epoch:4737\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020985\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002878\n",
      "Epoch:4738\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050808\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003008\n",
      "Epoch:4739\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.068448\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002851\n",
      "Epoch:4740\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.100560\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002434\n",
      "Epoch:4741\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031514\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002966\n",
      "Epoch:4742\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054197\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003785\n",
      "Epoch:4743\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051530\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002758\n",
      "Epoch:4744\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.045507\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002263\n",
      "Epoch:4745\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.102433\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002528\n",
      "Epoch:4746\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.133583\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002995\n",
      "Epoch:4747\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.100996\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003600\n",
      "Epoch:4748\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032900\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003437\n",
      "Epoch:4749\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.005343\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003030\n",
      "Epoch:4750\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.014249\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002651\n",
      "Epoch:4751\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.096285\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002545\n",
      "Epoch:4752\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.121065\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002740\n",
      "Epoch:4753\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.008689\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003835\n",
      "Epoch:4754\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.049374\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003251\n",
      "Epoch:4755\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020967\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002958\n",
      "Epoch:4756\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059483\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002774\n",
      "Epoch:4757\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.124207\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002493\n",
      "Epoch:4758\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.073356\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003165\n",
      "Epoch:4759\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026569\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002276\n",
      "Epoch:4760\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.034573\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002334\n",
      "Epoch:4761\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.010140\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002793\n",
      "Epoch:4762\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.038329\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002860\n",
      "Epoch:4763\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.014332\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002746\n",
      "Epoch:4764\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.001712\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002636\n",
      "Epoch:4765\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.086845\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002673\n",
      "Epoch:4766\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032297\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003018\n",
      "Epoch:4767\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.137957\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002891\n",
      "Epoch:4768\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.072678\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003012\n",
      "Epoch:4769\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.117829\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002677\n",
      "Epoch:4770\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033365\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002116\n",
      "Epoch:4771\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.055055\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002705\n",
      "Epoch:4772\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.096110\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003236\n",
      "Epoch:4773\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.087326\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003643\n",
      "Epoch:4774\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051861\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002492\n",
      "Epoch:4775\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.008345\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.001962\n",
      "Epoch:4776\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.117036\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002151\n",
      "Epoch:4777\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.058874\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003158\n",
      "Epoch:4778\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.127972\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003362\n",
      "Epoch:4779\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.041854\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002888\n",
      "Epoch:4780\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020969\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002491\n",
      "Epoch:4781\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024338\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002689\n",
      "Epoch:4782\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036890\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002745\n",
      "Epoch:4783\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.048993\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003207\n",
      "Epoch:4784\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.111957\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002513\n",
      "Epoch:4785\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.086788\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.001900\n",
      "Epoch:4786\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015819\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002882\n",
      "Epoch:4787\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017879\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002820\n",
      "Epoch:4788\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.022832\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002933\n",
      "Epoch:4789\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.135682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003004\n",
      "Epoch:4790\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044336\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002778\n",
      "Epoch:4791\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.065210\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003384\n",
      "Epoch:4792\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027947\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002730\n",
      "Epoch:4793\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.008756\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002355\n",
      "Epoch:4794\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.044039\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002981\n",
      "Epoch:4795\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.117804\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002824\n",
      "Epoch:4796\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062797\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002801\n",
      "Epoch:4797\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.074364\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002658\n",
      "Epoch:4798\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.125243\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002176\n",
      "Epoch:4799\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.004304\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003310\n",
      "Epoch:4800\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032996\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003442\n",
      "Epoch:4801\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.138950\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002430\n",
      "Epoch:4802\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016594\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003160\n",
      "Epoch:4803\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.004810\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002942\n",
      "Epoch:4804\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.070597\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003259\n",
      "Epoch:4805\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057017\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002650\n",
      "Epoch:4806\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.171886\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002300\n",
      "Epoch:4807\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.046519\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003221\n",
      "Epoch:4808\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.053158\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003273\n",
      "Epoch:4809\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051728\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002828\n",
      "Epoch:4810\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048961\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002225\n",
      "Epoch:4811\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020343\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002513\n",
      "Epoch:4812\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.073549\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003169\n",
      "Epoch:4813\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.122889\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002677\n",
      "Epoch:4814\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.062179\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002718\n",
      "Epoch:4815\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.123714\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003132\n",
      "Epoch:4816\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.017551\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003165\n",
      "Epoch:4817\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.015653\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002857\n",
      "Epoch:4818\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.046777\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003193\n",
      "Epoch:4819\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.048485\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002613\n",
      "Epoch:4820\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023523\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002768\n",
      "Epoch:4821\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.100823\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002667\n",
      "Epoch:4822\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030632\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002707\n",
      "Epoch:4823\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.114521\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002724\n",
      "Epoch:4824\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.074854\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003067\n",
      "Epoch:4825\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.101159\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002543\n",
      "Epoch:4826\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016812\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003096\n",
      "Epoch:4827\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.011304\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002630\n",
      "Epoch:4828\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.184768\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002445\n",
      "Epoch:4829\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032056\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004013\n",
      "Epoch:4830\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025312\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003296\n",
      "Epoch:4831\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.001930\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002547\n",
      "Epoch:4832\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064157\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002377\n",
      "Epoch:4833\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.067819\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002469\n",
      "Epoch:4834\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030311\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002400\n",
      "Epoch:4835\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.099216\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002604\n",
      "Epoch:4836\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.064348\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003015\n",
      "Epoch:4837\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.024774\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002684\n",
      "Epoch:4838\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030613\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003021\n",
      "Epoch:4839\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.000667\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003488\n",
      "Epoch:4840\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055961\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002828\n",
      "Epoch:4841\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.118312\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002907\n",
      "Epoch:4842\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.062981\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002999\n",
      "Epoch:4843\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.004670\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002340\n",
      "Epoch:4844\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.080257\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002457\n",
      "Epoch:4845\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023030\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002360\n",
      "Epoch:4846\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.005984\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002706\n",
      "Epoch:4847\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024660\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002781\n",
      "Epoch:4848\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044354\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003558\n",
      "Epoch:4849\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.060117\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002653\n",
      "Epoch:4850\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.099295\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002387\n",
      "Epoch:4851\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.077156\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002673\n",
      "Epoch:4852\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.081855\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004045\n",
      "Epoch:4853\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.091965\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003772\n",
      "Epoch:4854\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032178\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002356\n",
      "Epoch:4855\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.055686\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002272\n",
      "Epoch:4856\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.096010\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002155\n",
      "Epoch:4857\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.018303\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003167\n",
      "Epoch:4858\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023828\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003126\n",
      "Epoch:4859\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.044515\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002680\n",
      "Epoch:4860\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.010471\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003141\n",
      "Epoch:4861\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.089488\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002607\n",
      "Epoch:4862\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.108950\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002947\n",
      "Epoch:4863\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.130398\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003835\n",
      "Epoch:4864\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.079986\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002851\n",
      "Epoch:4865\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045789\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002393\n",
      "Epoch:4866\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.124985\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002648\n",
      "Epoch:4867\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054161\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002812\n",
      "Epoch:4868\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.047247\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002668\n",
      "Epoch:4869\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.060302\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002655\n",
      "Epoch:4870\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.157018\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003177\n",
      "Epoch:4871\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.027996\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002916\n",
      "Epoch:4872\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.133237\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002547\n",
      "Epoch:4873\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.020705\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003389\n",
      "Epoch:4874\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.094516\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003136\n",
      "Epoch:4875\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.139630\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002151\n",
      "Epoch:4876\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.101392\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002190\n",
      "Epoch:4877\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.118114\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003492\n",
      "Epoch:4878\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.088661\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003280\n",
      "Epoch:4879\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051842\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002809\n",
      "Epoch:4880\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019599\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002816\n",
      "Epoch:4881\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025829\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003221\n",
      "Epoch:4882\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015379\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002922\n",
      "Epoch:4883\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020896\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002582\n",
      "Epoch:4884\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.100583\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002504\n",
      "Epoch:4885\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.134721\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002773\n",
      "Epoch:4886\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032933\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003968\n",
      "Epoch:4887\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019061\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003138\n",
      "Epoch:4888\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.103794\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002723\n",
      "Epoch:4889\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.002160\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002235\n",
      "Epoch:4890\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035132\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002673\n",
      "Epoch:4891\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.075667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003032\n",
      "Epoch:4892\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.012269\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002385\n",
      "Epoch:4893\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031442\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002257\n",
      "Epoch:4894\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019767\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002464\n",
      "Epoch:4895\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.051057\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002985\n",
      "Epoch:4896\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019180\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003363\n",
      "Epoch:4897\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.015344\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002726\n",
      "Epoch:4898\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.011537\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002533\n",
      "Epoch:4899\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.111135\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002888\n",
      "Epoch:4900\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035614\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003785\n",
      "Epoch:4901\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.051162\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002918\n",
      "Epoch:4902\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.135048\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002393\n",
      "Epoch:4903\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.125072\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002884\n",
      "Epoch:4904\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028834\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003258\n",
      "Epoch:4905\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040017\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002315\n",
      "Epoch:4906\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.186497\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002180\n",
      "Epoch:4907\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.006324\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003727\n",
      "Epoch:4908\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.030531\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003408\n",
      "Epoch:4909\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013702\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002473\n",
      "Epoch:4910\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.066678\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002363\n",
      "Epoch:4911\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035221\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003135\n",
      "Epoch:4912\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035306\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002975\n",
      "Epoch:4913\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.000970\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002307\n",
      "Epoch:4914\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.115050\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002819\n",
      "Epoch:4915\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.084634\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003126\n",
      "Epoch:4916\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.035411\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002894\n",
      "Epoch:4917\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033970\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002272\n",
      "Epoch:4918\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.155691\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002681\n",
      "Epoch:4919\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.095794\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003377\n",
      "Epoch:4920\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066814\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002586\n",
      "Epoch:4921\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.093620\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002233\n",
      "Epoch:4922\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.054710\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003045\n",
      "Epoch:4923\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.123702\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002858\n",
      "Epoch:4924\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.033828\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002449\n",
      "Epoch:4925\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.013485\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002468\n",
      "Epoch:4926\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.037004\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003184\n",
      "Epoch:4927\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.087428\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002582\n",
      "Epoch:4928\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024882\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002937\n",
      "Epoch:4929\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.023361\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002874\n",
      "Epoch:4930\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.011574\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002706\n",
      "Epoch:4931\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.091805\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002762\n",
      "Epoch:4932\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.009634\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002305\n",
      "Epoch:4933\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.004997\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002413\n",
      "Epoch:4934\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026164\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002569\n",
      "Epoch:4935\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.040682\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002536\n",
      "Epoch:4936\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.024851\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002842\n",
      "Epoch:4937\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.006796\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002605\n",
      "Epoch:4938\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.036382\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002451\n",
      "Epoch:4939\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.033164\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002704\n",
      "Epoch:4940\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.124248\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003438\n",
      "Epoch:4941\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.025397\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003168\n",
      "Epoch:4942\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.050930\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002904\n",
      "Epoch:4943\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.059542\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002638\n",
      "Epoch:4944\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.026717\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002594\n",
      "Epoch:4945\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.056384\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002648\n",
      "Epoch:4946\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.012927\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002464\n",
      "Epoch:4947\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.003320\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002407\n",
      "Epoch:4948\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.018975\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002404\n",
      "Epoch:4949\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.057820\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002689\n",
      "Epoch:4950\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127919\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002237\n",
      "Epoch:4951\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.041662\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002813\n",
      "Epoch:4952\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040167\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003071\n",
      "Epoch:4953\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.102761\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002473\n",
      "Epoch:4954\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.021828\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003325\n",
      "Epoch:4955\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.013844\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002717\n",
      "Epoch:4956\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019568\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002222\n",
      "Epoch:4957\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.020252\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002603\n",
      "Epoch:4958\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.104363\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002855\n",
      "Epoch:4959\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.032153\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002807\n",
      "Epoch:4960\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.018487\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002661\n",
      "Epoch:4961\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.087952\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002495\n",
      "Epoch:4962\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.040057\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002384\n",
      "Epoch:4963\n",
      "Training...\n",
      " Accuracy:96.666667 loss:0.209278\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002308\n",
      "Epoch:4964\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.031655\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.004435\n",
      "Epoch:4965\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.088709\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002721\n",
      "Epoch:4966\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.002167\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002895\n",
      "Epoch:4967\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.089686\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003009\n",
      "Epoch:4968\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.019739\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003341\n",
      "Epoch:4969\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.086636\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003282\n",
      "Epoch:4970\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.014505\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002179\n",
      "Epoch:4971\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.013685\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002296\n",
      "Epoch:4972\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.028014\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002571\n",
      "Epoch:4973\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.092933\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003368\n",
      "Epoch:4974\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.039715\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003405\n",
      "Epoch:4975\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.045159\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003072\n",
      "Epoch:4976\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.095939\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002566\n",
      "Epoch:4977\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.059936\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002140\n",
      "Epoch:4978\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.012558\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002859\n",
      "Epoch:4979\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016136\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002881\n",
      "Epoch:4980\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.122169\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002493\n",
      "Epoch:4981\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.143962\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002746\n",
      "Epoch:4982\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036443\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002966\n",
      "Epoch:4983\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036679\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002737\n",
      "Epoch:4984\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.094152\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002578\n",
      "Epoch:4985\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.133867\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003065\n",
      "Epoch:4986\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066032\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002842\n",
      "Epoch:4987\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.036763\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002830\n",
      "Epoch:4988\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.019390\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003058\n",
      "Epoch:4989\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.139566\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002803\n",
      "Epoch:4990\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.078441\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.003004\n",
      "Epoch:4991\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.134831\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002577\n",
      "Epoch:4992\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.096360\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002260\n",
      "Epoch:4993\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.025083\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002598\n",
      "Epoch:4994\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.066929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002408\n",
      "Epoch:4995\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.016546\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002366\n",
      "Epoch:4996\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.100204\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002601\n",
      "Epoch:4997\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.119397\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002768\n",
      "Epoch:4998\n",
      "Training...\n",
      " Accuracy:98.333333 loss:0.029932\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002956\n",
      "Epoch:4999\n",
      "Training...\n",
      " Accuracy:97.500000 loss:0.127758\n",
      "Testing...\n",
      "Accuracy:100.000000 loss:0.002533\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torchvision import transforms, utils\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as data_utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as graph\n",
    "\n",
    "#Creating a model for Iris dataset training and validation\n",
    "class IrisNet(torch.nn.Module):\n",
    "    def __init__(self,input_layer,hidden_1_size,hidden_2_size,output_layer):\n",
    "        super(IrisNet,self).__init__()\n",
    "        self.first_layer=torch.nn.Linear(input_layer,hidden_1_size)\n",
    "        self.first_layer_activation=torch.nn.ReLU()\n",
    "        self.second_layer=torch.nn.Linear(hidden_1_size,hidden_2_size)\n",
    "        self.second_layer_activation=torch.nn.ReLU()\n",
    "        self.third_layer=torch.nn.Linear(hidden_2_size,output_layer)\n",
    "        self.third_layer_activation=torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        output_1=self.first_layer(x)\n",
    "        output_1=self.first_layer_activation(output_1)\n",
    "        output_2=self.second_layer(output_1)\n",
    "        output_2=self.second_layer_activation(output_2)\n",
    "        output_3=self.third_layer(output_2)\n",
    "        return output_3\n",
    "\n",
    "#Specifying the no of neurons in every layer\n",
    "model=IrisNet(4,100,40,3)\n",
    "\n",
    "batch_size=30\n",
    "path_dataset='data\\iris.csv'\n",
    "\n",
    "iris_dataset=pd.read_csv(path_dataset,header=None)\n",
    "\n",
    "#Use data for training\n",
    "\n",
    "train_features_1=iris_dataset.iloc[0:40,0:4]\n",
    "train_features_2=iris_dataset.iloc[50:90,0:4]\n",
    "train_features_3=iris_dataset.iloc[100:140,0:4]\n",
    "train_features=pd.concat([train_features_1,train_features_2,train_features_3])\n",
    "\n",
    "\n",
    "train_label_1=iris_dataset.iloc[0:40,-1]\n",
    "train_label_2=iris_dataset.iloc[50:90,-1]\n",
    "train_label_3=iris_dataset.iloc[100:140,-1]\n",
    "train_label=pd.concat([train_label_1,train_label_2,train_label_3])\n",
    "\n",
    "\n",
    "train_features=torch.Tensor(train_features.values)\n",
    "\n",
    "train_label=torch.LongTensor(train_label.values)\n",
    "\n",
    "train_data=data_utils.TensorDataset(train_features,train_label)\n",
    "\n",
    "train_loader=data_utils.DataLoader(dataset=train_data,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "#Use data for testing\n",
    "\n",
    "test_features_1=iris_dataset.iloc[40:50,0:4]\n",
    "test_features_2=iris_dataset.iloc[90:100,0:4]\n",
    "test_features_3=iris_dataset.iloc[140:150,0:4]\n",
    "test_features=pd.concat([test_features_1,test_features_2,test_features_3])\n",
    "\n",
    "test_label_1=iris_dataset.iloc[40:50,-1]\n",
    "test_label_2=iris_dataset.iloc[90:100,-1]\n",
    "test_label_3=iris_dataset.iloc[140:150,-1]\n",
    "test_label=pd.concat([test_label_1,test_label_2,test_label_3])\n",
    "\n",
    "test_features=torch.Tensor(test_features.values)\n",
    "\n",
    "test_label=torch.LongTensor(test_label.values)\n",
    "\n",
    "test_data=data_utils.TensorDataset(test_features,test_label)\n",
    "\n",
    "test_loader=data_utils.DataLoader(dataset=test_data,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "#Defining the loss function for the model\n",
    "criterion=torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#defining the learning rate\n",
    "learning_rate=0.001\n",
    "\n",
    "#defining the optimizer \n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate,nesterov=True,momentum=0.9)\n",
    "\n",
    "no_of_epoch=5000\n",
    "\n",
    "training_loss=[]\n",
    "training_accuracy=[]\n",
    "testing_loss=[]\n",
    "testing_accuracy=[]\n",
    "epoch_list=[]\n",
    "\n",
    "for epoch in range(no_of_epoch):\n",
    "    \n",
    "    total_trained=0\n",
    "    correctly_trained=0\n",
    "    \n",
    "    for i ,(train_features,train_labels) in enumerate(train_loader):\n",
    "        train_features=Variable(train_features)\n",
    "        train_labels=Variable(train_labels)\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output=model(train_features)\n",
    "        \n",
    "        loss=criterion(output,train_labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_trained += train_labels.size(0)\n",
    "        \n",
    "        _ , predicted_labels = torch.max(output.data,1)\n",
    "        \n",
    "        correctly_trained += (train_labels.data==predicted_labels).sum()\n",
    "    \n",
    "    #Priniting the Accuracy and loss values for training data\n",
    "    print(\"Epoch:%d\"%(epoch))\n",
    "    print(\"Training...\")\n",
    "    print(\" Accuracy:%f loss:%f\"%((correctly_trained/total_trained)*100,loss))\n",
    "    \n",
    "    training_loss.append(loss.data)\n",
    "    training_accuracy.append((correctly_trained/total_trained)*100)\n",
    "    epoch_list.append(epoch)\n",
    "    \n",
    "    output=model(Variable(test_features))\n",
    "    \n",
    "    loss=criterion(output,Variable(test_label))\n",
    "    \n",
    "    _ , predicted_label = torch.max(output.data,1)\n",
    "    \n",
    "    correct_prediction=(predicted_label==test_label).sum()\n",
    "    \n",
    "    #Prinitng the Accuracy and loss values for testing data\n",
    "    print(\"Testing...\")\n",
    "    print(\"Accuracy:%f loss:%f\"%((correct_prediction/test_label.size(0))*100,loss))\n",
    "    \n",
    "    testing_loss.append(loss.data)\n",
    "    testing_accuracy.append((correct_prediction/test_label.size(0))*100)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot of training loss and testing loss\n",
    "graph.plot(epoch_list,training_loss,label='Training loss')\n",
    "graph.plot(epoch_list,testing_loss,label='Testing loss')\n",
    "graph.xlabel('Epoch')\n",
    "graph.ylabel('Loss')\n",
    "graph.title('Loss v/s Epoch')\n",
    "graph.legend()\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VNXdx/HPLwlLEDCBsMkWBKwiQoSICqkLWERAsSpFhYq4UK0rbRX6lKq1rYW2PlTUh5YHRWoV3ErR1g1QW32ssgnuClgUBGQTRBY18Hv+uDdhAjOZCclkEub7fr3mNfeeu50zmdzfnHPPPdfcHRERkf1lpDoDIiJSMylAiIhIVAoQIiISlQKEiIhEpQAhIiJRKUCIiEhUChAiEpeZvWRmV6Q6H1K9FCAkZcKTzudmVi/VeUkVMzvCzNZUcJsHzOxrM/sy4rUsWXmU9KUAISlhZvnAtwEHzqnmY2dV5/HiGAg8exDb/dbdG0a8uld1xkQUICRVLgFeAx4ARkYuMLNsM7vTzD42s21m9oqZZYfLiszsVTPbamarzezSML1ME4iZXWpmr0TMu5ldY2bLgeVh2l3hPr4ws8Vm9u2I9TPN7L/MbKWZbQ+XtzWze83szv3y+5SZ3bh/Ac3sj2b2+/3S5pjZjyKSBgJPh8vGmtmn4fE+MLN+FflAw33kh2UdbWZrzWydmf04Ynk9M/tDuGxtOF0vYvkQM1safiYrzWxAxO7bm9n/hfl73szyKpo/qWXcXS+9qv0FrAB+CPQEvgFaRCy7F3gJaA1kAr2BekA7YDtwEVAHaAoUhNu8BFwRsY9LgVci5h2YCzQBssO0EeE+soAfA+uB+uGym4C3gG8BBnQP1+0FrAUywvXygJ2R+Y845inAasDC+VxgF3BEOF8H2AQ0Co+zOmJZPtAxxmf3APCrGMvyw7LOBA4DjgM2AmeEy28nCMzNgWbAq8Avw2W9gG3Adwh+PLYGjo74fFcCRwHZ4fyEVH+P9EruK+UZ0Cv9XkBRGBTywvn3gTHhdEZ4Eu0eZbufArNj7DORANE3Tr4+Lzku8AEwJMZ67wHfCaevBZ6OsZ4BnwCnhPNXAi9ELO8HzA+nOwEbgDOAOnHy+QCwG9ga8ZoRLisJEEdHrP9b4L5weiUwMGLZmcCqcPpPwKRyPt/xEfM/BJ5N9XdJr+S+1MQkqTASeN7dN4XzD7OvmSkPqE9wIttf2xjpiVodOWNmPzaz98JmrK3A4eHx4x1rBkHtg/D9wWgreXAmnUVQ4wG4GHgoYpXS5iV3XwHcCNwGbDCzWWZ2RDll+b2750S8Ru63PLKsHwMl+zoinI+2LN7nuz5ieifQsJx15RCgACHVKryW8D3gVDNbb2brgTFAdzPrTtDkshvoGGXz1THSAXYADSLmW0ZZp3To4vB6w9gwL7nunkPQvGIJHOsvwJAwv8cAf4uxHgRNPReYWXvgROCJiGUDgX+UZs79YXcvAtqHeZ1Yzn7jaRsx3Y6gWYzwvX2MZeWVWdKQAoRUt3OBPUAXoCB8HQO8DFzi7nuB+4H/DruAZprZyeGF1IeAM8zse2aWZWZNzawg3O9S4Dwza2BmnYDL4+SjEVBM0D6fZWa3AI0jlk8DfmlmnS3QzcyaArj7GmAhQc3hCXffFesg7v5GeIxpwHPuvhXAzDoA9dz9/XD+W2bWNyznboJmtj1xylCen4efxbHAKOCRMH0mMN7MmoUXmW8hCHgA9wGjzKyfmWWYWWszO7oSeZBaTgFCqttIYLq7f+Lu60tewD3A8LAL6k8ILhAvBLYQ/JLOcPdPCH51/zhMX0pw8RhgEvA18BlBE1BkU040zwHPAB8SNLPspmyzzH8DjwLPA18QnDyzI5bPILgAHLV5aT8zCa4tPByRNoiweSlUD5hAUINaT3AR+b/K2efN+90HsWm/5f8k6Agwn6A56vkw/VfAIuBNgs94SZiGuy8gCCaTCGpT/6RsbUPSTEnvChGpADM7heCXd35Y66no9k8D97j703FXrth+84H/EFzoLq7KfUv6UQ1CpILMrA5wAzDtYIJD6CXgxSrLlEgSqAYhUgFmdgxBE80yYIC7f5HiLJWhGoRUJQUIERGJSk1MIiISVU0atKzC8vLyPD8/P9XZEBGpVRYvXrzJ3ZvFW69WB4j8/HwWLVqU6myIiNQqZvZx/LXUxCQiIjEoQIiISFQKECIiEpUChIiIRKUAISIiUSUtQJjZ/Wa2wczejkhrYmZzzWx5+J4bppuZTTazFWb2ppn1SFa+REQkMcmsQTwADNgvbRzBE7Q6E4wyOS5MPwvoHL5GA1OSmC8REUlA0u6DcPd/hePCRBoCnBZOzyAYsGxsmP7n8Alcr5lZjpm1cvd1ycpfqS0fwZPXQ7uTk34oEZEq860B0LpnUg9R3TfKtSg56bv7OjNrHqa3puxY/GvCtAMChJmNJqhl0K5du8rnaPLxwfuql9n3MDERkRquUctDLkDEEu3MHHUUQXefCkwFKCwsrLqRBkc+BR1OqbLdiYjUdtUdID4raToys1bAhjB9DWWfoduGfc/JrR6WWaW7O3/Kq+z+Zg/vrP2Ca0/vxOYdXzFzQVBJeu/2Abz20WZGPbAQgBd+fCp97/wnABf0bMPji9dU6tirJgwCYMP23fT69Xz+Z3gPBh7XKub6+eOCxyKPO+tonly6luy6mTxxde+Y66/ftpuTfjO/zLFE5NBT3QHiSYJHTk4I3+dEpF9rZrMIHuy+rVquP0Syqr1ev/jjz0un73lxRZllm778ilkLPymdf+2jLaXTlQ0Okd5ftx2Ah1//pNwAUeIP8z5k9zfxn3/z7rptlc6biNR8SXsehJnNJLggnUfwnOBbgb8RPOe3HfAJMNTdt5iZETyTeACwExjl7nFH4SssLPRKD9Z32+EArD//b/x1c1t+++wHldtfGmjRuB6fffFVhberXycjoQCUDEe1aMiHn32ZkmOLJMObt/Wncf06B7WtmS1298K469XmBwZVZYAYZbfz4q5OVZArEZHka52Tzf+N63tQ2yYaIHQndWj7bj2dUURqj807Kl6LrygFiJCri6uI1CIdmzVM+jEUIOK4tHf+AWkZiiUicWXXqdqegRXVonG9pB8jr2HsY3Rvc/gBab06NKmS4+Y0qMOkYQVVsq/ypHeA2LsnavLFJwY34P3y3K7cds6xB3Tl/Og3g1j4szMO2G7VhEGsmrBvWV7DuqVpsbqDRi4ved12dhcALjm5/QHLpn5/340xv7ugW+l0z/a5Uffbtkl2mbRI5x3fusz8uQVHlJk/9ai4TyRMGz3a5SS87iOjTyqdblgvi3suPv6gjvm3a/qUTrfJzY76PeraunG5+0i0G/JjV51Mk8PqJpy3o1s2OiDtp2cdXWb+vV8OKPf4//nNwAOWR87vv+yPI3oesHzVhEH07tgUoPT96tM6smrCIF7/rzOiHn9ozzZR8xPtf3HVhEE8MOqEqOs/MOoE/m/c6THLN+faIi7r0wGA8YOOYdWEQTz6g5NL9/uf3wyMut3KO/alR+a/5MfqLYO7sPSW/hzV4sC/QVVL7wCx5T+lkx94cBvGXRcWcEVRBzrkHcaAY1uWLo88GQPkNtjXe+D7J7Xnur6dyizr2roxv7uge9TDDg8D0P77LDGwWyuOzDuMUeGXK9JJ4T8BQP+I/I0dcDQdmx3G9X07cX6Pff8AU4YHAWV6lC/5mO8cVTr9P8N78MPTO9G2STaN6ge9n386cN8/fK/8JvzvJfuuaR3X+nCu69uJC09oy48i9hPL/uvEO7FFc+W3930evfLL/yV2ae98LurVlqNbNuLa0zuR06Bsb4+WjeuXme+V36T0n7l1TjbTIso6/MR2/GxQF5pGnECj/ToE6NOpKce1OZwjmx0GwB+GFfDtTvsCbY92OUw477jS+d8PDb4jx+8XgMYOOLrMSfg3EdsURvwYuGXwsXynSwsARpy0b2SBNrnZDCsMvtOThu37Hn67cx43nfmt0vmurRvTqXlDjj2iMXcO7U63Nodzfd9O9D06GOQgw+CiXsF+Tzpy32d+2znHcuJ+v4bPPb41dTKD6vX3CsuehDMzjIK2ZcsYdF6EIeEPk1+ccywAdw7tTlGnPCD4Xjaom8mReYdxcvjdv6hXuzLfp5vD7/7tQ7rSrkkDLu5VdoSF6/t1LjN/Xd/OHNOqMef1aE1RpzzOO741Nw/4FrEU7vdd697mcDo3b0jP9rnUzczg+HY5fKdLC3p1aFL6N7v34mC80UtObk+7Jg04p/sRB+zXrOxn8pvzjqNn+1wyM4w7vnsc/cK/we1Dgr/xpb3zadekAYO7xe+yXlXSuxfThvfhf07k2q+v4+97T+aCnm1K/2GjKbmhrCSq7z8fT0XXr8g+P/zVWdTNSu94LyKJUS+mRHjQxLQn/BiiVZvL0zH8lVgTmK6LiEgVqyljMaXG3qBra0mAuCxKk06kBf/Vj6+K993o9der+7Dxy90JH+7lm0+nXpJ+5WcoQohIFUvzAFG2BpERp3tS8/3arQ9vUIfDGyR+J2PbJg0qmMHEKTyISFVL8yamoDawpxZ/DA9e3otB3VqpiUlEqpxqEMDeWhwgvt25Gd/urO6oIlL1au+ZsSpEXKTu0qri3S5FRA5l6R0gImoQs6+J/fwDEZF0lN4BYkfwvKLGDepRLyu1wwKIiNQ06R0gSh4SlJn4EAMiIukivQNE2MT0dZauP4iI7E8BAshS85KIyAHSO0CEvZgys9K7t6+ISDRpHSD27AmG2njz0x0pzomISM2T1gFix65gHKXafCe1iEiypPWZ8ZvioAZRm++kFhFJlpScGc3sBjN728zeMbMbw7QmZjbXzJaH77nx9lNZe4rLjuYqIiL7VPuZ0cy6AlcCvYDuwGAz6wyMA+a7e2dgfjifVCU1iIlDD+6RkCIih7JU/HQ+BnjN3Xe6ezHwT+C7wBBgRrjODODcZGdkx8dLAMjMSnzIbhGRdJGKAPE2cIqZNTWzBsBAoC3Qwt3XAYTvzaNtbGajzWyRmS3auHFjpTLy79XBRer3t+yNs6aISPqp9gDh7u8BE4G5wLPAMqC4AttPdfdCdy9s1qxyw1wbsMUbkpWpaxAiIvtLyZnR3e9z9x7ufgqwBVgOfGZmrQDC9w3Jzkerw+vhGN3a5CT7UCIitU6qejE1D9/bAecBM4EngZHhKiOBOcnOR7sm2ThGp+YNk30oEZFaJ1VjTDxhZk2Bb4Br3P1zM5sAPGpmlwOfAEOTngt3HCNTz+sUETlASgKEu387StpmoF/1ZmQvjqHwICJyoPS+OuuOAxmqQYiIHCC9AwRBE5Ol+acgIhJNep8aw2sQqkGIiBworR+E8K11c8Bgp+KDiMgB0rsGEdJlahGRAylAAGphEhE5kAIE6sUkIhKNAgSQofggInIABQhUgxARiUYBAl2DEBGJRgECMEUIEZEDKECIiEhUChAiIhKVAoSIiESlACEiIlEpQIiISFQKECIiEpUChIiIRKUAISIiUSlAiIhIVCkJEGY2xszeMbO3zWymmdU3sw5m9rqZLTezR8ysblIz4Z7U3YuI1HbVHiDMrDVwPVDo7l2BTOBCYCIwyd07A58Dlyc1I743qbsXEantUtXElAVkm1kW0ABYB/QFHg+XzwDOTWoOVIMQESlXtQcId/8U+D3wCUFg2AYsBra6e3G42hqgdZJzktzdi4jUcqloYsoFhgAdgCOAw4Czoqwa9QxuZqPNbJGZLdq4cePBZ0Q1CBGRcqWiiekM4D/uvtHdvwH+CvQGcsImJ4A2wNpoG7v7VHcvdPfCZs2aVSIbChAiIuVJRYD4BDjJzBpY8CCGfsC7wIvABeE6I4E5Sc2FahAiIuVKxTWI1wkuRi8B3grzMBUYC/zIzFYATYH7kpyT5O5eRKSWy4q/StVz91uBW/dL/gjoVY2ZqLZDiYjURml8J7UChIhIedI3QKgGISJSrvQNEKpBiIiUK30DhGoQIiLlSt8AoRqEiEi50jZAeDhY3yvtr0lxTkREaqa0DRB79wY1iOLM7BTnRESkZkrbAOF79wBgKc6HiEhNlbYBoqQGQUZmajMiIlJDpXGACGoQmOoQIiLRpG2A8NInyqXtRyAiUq70PTuGAcIyVIMQEYkmbQPE3r2qQYiIlCdtz46lAUI1CBGRqOIGCDO7NnxM6KFlx2YA6u7ZmeKMiIjUTInUIFoCC83sUTMbED4FrvYLS7Eju3Vq8yEiUkPFDRDuPh7oTPCEt0uB5WZ2h5l1THLekqq0icnStpVNRKRcCZ0d3d2B9eGrGMgFHjez3yYxb0lVcie1bpQTEYku7iNHzex6YCSwCZgG3OTu35hZBrAcuDm5WUyOfTfKqQYhIhJNIs+kzgPOc/ePIxPdfa+ZDU5OtpLP1MQkIlKuRM6OTwNbSmbMrJGZnQjg7u8lK2PJVnINwtTEJCISVSIBYgrwZcT8jjDtoJjZt8xsacTrCzO70cyamNlcM1sevie1a617OJqrahAiIlElcna08CI1EDQtkVjTVFTu/oG7F7h7AdAT2AnMBsYB8929MzA/nE8a1zUIEZFyJXJ2/MjMrjezOuHrBuCjKjp+P2BleH1jCDAjTJ8BnFtFx4jKwyYmVxOTiEhUiQSIq4DewKfAGuBEYHQVHf9CYGY43cLd1wGE782jbWBmo81skZkt2rhx48EfuWSwPtUgRESiittU5O4bCE7kVcrM6gLnAD+tyHbuPhWYClBYWOhxVo+9n5InymUoQIiIRJPIfRD1gcuBY4H6Jenuflklj30WsMTdPwvnPzOzVu6+zsxaARsquf9y7bsPQk1MIiLRJPLz+UGC8ZjOBP4JtAG2V8GxL2Jf8xLAkwQ35BG+z6mCY8RW8sAg1SBERKJK5OzYyd1/Duxw9xnAIOC4yhzUzBoA3wH+GpE8AfiOmS0Pl02ozDHi2qturiIi5Umku+o34ftWM+tKMB5TfmUO6u47gab7pW0m6NVULbz0iXIH3WNXROSQlsjZcWp409p4gmaghsDPk5qrauClQ20cGqOXi4hUtXIDRDgg3xfu/jnwL+DIaslVNVAvJhGR8pV7dgzvmr62mvJSrb4uLgagXt26Kc6JiEjNlMjP57lm9hMzaxuOl9TEzJokPWdJ9NXunRz5zxsAaFBX1yBERKJJ5OxYcr/DNRFpTi1ubnp79u/pGU63aV+rH4wnIpI0idxJ3aE6MlKd9hZ/VTqdc3hOCnMiIlJzJXIn9SXR0t39z1WfneqRnaWeSyIi8STSxHRCxHR9gnsVlgC1NkA0aaDrDiIi8STSxHRd5LyZHU4w/EbtVTLMhoiIxHQwNwHsBDpXdUaqlR/0ILAiImkjkWsQTxH0WoIgoHQBHk1mppLNCB8WZBnoaoSISHSJNMb/PmK6GPjY3dckKT/VI2xichQgRERiSSRAfAKsc/fdAGaWbWb57r4qqTlLppImJo3DJCISUyLXIB4DIq/q7gnTaj039WYSEYklkQCR5e5fl8yE07V6AKMvjjgFgBW9bk9xTkREaq5EAsRGMzunZMbMhgCbkpel5PPwGRBfZzdLcU5ERGquRNpYrgIeMrN7wvk1QNS7q2sLR91cRUTiSeRGuZXASWbWEDB3r4rnUdcQehaEiEgscc+QZnaHmeW4+5fuvt3Mcs3sV9WRORERSZ1EfkKf5e5bS2bCp8sNTF6WRESkJkgkQGSaWb2SGTPLBuqVs36N5xpqQ0QkrkQCxF+A+WZ2uZldDswFZlTmoGaWY2aPm9n7ZvaemZ0cPqlurpktD99zK3OMxPKR7COIiNRecQOEu/8W+BVwDME4TM8C7St53LuAZ939aKA78B4wDpjv7p2B+eG8iIikSKLdeNYT3E19PsHzIN472AOaWWPgFOA+CG68C69xDGFfzWQGcO7BHiMuNTGJiMQVs5urmR0FXAhcBGwGHiHo5np6JY95JLARmG5m3YHFwA1AC3dfB+Du68yseYx8jQZGA7Rr165yOVEbk4hITOXVIN4nqC2c7e5F7n43wThMlZUF9ACmuPvxwA4q0Jzk7lPdvdDdC5s1053QIiLJUl6AOJ+gaelFM/tfM+sHVTI69hpgjbu/Hs4/ThAwPjOzVgDh+4YqOFZU6sUkIhJfzADh7rPdfRhwNPASMAZoYWZTzKz/wR7Q3dcDq83sW2FSP+Bd4ElgZJg2EphzsMdImJqYRERiSmSojR3AQwTjMTUBhhI0CT1fieNeF+6vLvARMIogWD0adqX9JDyOiIikSIUeiODuW4A/ha+D5u5LgcIoi/pVZr8VyEC1HEZEpDZL69HqLL2LLyJSLp0hRUQkqrQMEF7mCaoiIhJNWgaIUurFJCISU3oHCBERiSk9A4R6MYmIxJWeASJkamISEYkprQOEiIjEpgAhIiJRpWeA0DUIEZG40jNAlNA1CBGRmNI7QIiISExpGSDUwiQiEl9aBogS6uYqIhJbWgcIERGJLU0DhAbrExGJJ00DRMCq5BHbIiKHprQOECIiElt6Bgh1YxIRiSs9A0QJ9WISEYkpKxUHNbNVwHZgD1Ds7oVm1gR4BMgHVgHfc/fPU5E/ERFJbQ3idHcvcPfCcH4cMN/dOwPzw/mkcDUxiYjEVZOamIYAM8LpGcC5ST+imphERGJKVYBw4HkzW2xmo8O0Fu6+DiB8bx5tQzMbbWaLzGzRxo0bqym7IiLpJyXXIIA+7r7WzJoDc83s/UQ3dPepwFSAwsJCtRWJiCRJSmoQ7r42fN8AzAZ6AZ+ZWSuA8H1DEjOQtF2LiBwqqj1AmNlhZtaoZBroD7wNPAmMDFcbCcyphswk/RAiIrVVKpqYWgCzw5FUs4CH3f1ZM1sIPGpmlwOfAENTkDcREQlVe4Bw94+A7lHSNwP9qiUPqIlJRCSemtTNtdppsD4RkdjSOkCIiEhs6Rkg1ItJRCSu9AwQIctI6+KLiJRLZ0gREYkqTQOEHjkqIhJPmgaIEurFJCISS5oHCBERiSUtA4Q6MYmIxJeWAaKEaSwmEZGY0jpAiIhIbAoQIiISVXoGCF2EEBGJKz0DRAldgxARiSm9A4SIiMSUngFCTUwiInGl4olyNYa6uUq6+eabb1izZg27d+9OdVakGtSvX582bdpQp06dg9o+rQOESLpZs2YNjRo1Ij8/Xz+QDnHuzubNm1mzZg0dOnQ4qH2kZROTuwbrk/S0e/dumjZtquCQBsyMpk2bVqq2mJYBYh/9k0j6UXBIH5X9W6d5gBARkVhSFiDMLNPM3jCzv4fzHczsdTNbbmaPmFndVOVNRKre5s2bKSgooKCggJYtW9K6devS+a+//jqhfYwaNYoPPvig3HXuvfdeHnrooarIctpL5UXqG4D3gMbh/ERgkrvPMrM/ApcDU5KZAVW1RapP06ZNWbp0KQC33XYbDRs25Cc/+UmZddwddycjxuOAp0+fHvc411xzTeUzW82Ki4vJyqp5fYZSkiMzawMMAn4N/MiCM3Vf4OJwlRnAbSQ5QIiks1889Q7vrv2iSvfZ5YjG3Hr2sRXaZsWKFZx77rkUFRXx+uuv8/e//51f/OIXLFmyhF27djFs2DBuueUWAIqKirjnnnvo2rUreXl5XHXVVTzzzDM0aNCAOXPm0Lx5c8aPH09eXh433ngjRUVFFBUV8cILL7Bt2zamT59O79692bFjB5dccgkrVqygS5cuLF++nGnTplFQUFAmb7feeitPP/00u3btoqioiClTpmBmfPjhh1x11VVs3ryZzMxM/vrXv5Kfn88dd9zBzJkzycjIYPDgwfz6178uzXNBQQHr16+nqKiIFStWMG3aNObNm8eXX37JV199xRNPPMG5557L1q1bKS4u5o477mDw4MFAEBgnTZqEmdGjRw8mTZpEjx49+PDDD8nKymLr1q0cf/zxrFixgszMzKr5Y5K6JqY/ADez79mfTYGt7l4czq8BWkfb0MxGm9kiM1u0cePGgzq460Y5kRrl3Xff5fLLL+eNN96gdevWTJgwgUWLFrFs2TLmzp3Lu+++e8A227Zt49RTT2XZsmWcfPLJ3H///VH37e4sWLCA3/3ud9x+++0A3H333bRs2ZJly5Yxbtw43njjjajb3nDDDSxcuJC33nqLbdu28eyzzwJw0UUXMWbMGJYtW8arr75K8+bNeeqpp3jmmWdYsGABy5Yt48c//nHccv/73//mwQcfZO7cuWRnZzNnzhyWLFnCvHnzGDNmDADLli1j4sSJvPTSSyxbtow777yTnJwc+vTpU5qfhx9+mO9973tVGhwgBTUIMxsMbHD3xWZ2WklylFWjnsXdfSowFaCwsLByZ3rTNXpJXxX9pZ9MHTt25IQTTiidnzlzJvfddx/FxcWsXbuWd999ly5dupTZJjs7m7POOguAnj178vLLL0fd93nnnVe6zqpVqwB45ZVXGDt2LADdu3fn2GOjfxbz58/nd7/7Hbt372bTpk307NmTk046iU2bNnH22WcDwc1oAPPmzeOyyy4jOzsbgCZNmsQtd//+/cnNzQWCQDZ27FheeeUVMjIyWL16NZs2beKFF15g2LBhpfsreb/iiiuYPHkygwcPZvr06Tz44INxj1dRqWhi6gOcY2YDgfoE1yD+AOSYWVZYi2gDrE1B3kQkBQ477LDS6eXLl3PXXXexYMECcnJyGDFiRNS+/HXr7uvHkpmZSXFx8QHrANSrV++AdRJpRdi5cyfXXnstS5YsoXXr1owfP740H9GuX7p71PSsrCz27g0aS/YvR2S5//znP7Nt2zaWLFlCVlYWbdq0Yffu3TH3e+qpp3Lttdfy4osvUqdOHY4++ui4Zaqoav8J7e4/dfc27p4PXAi84O7DgReBC8LVRgJzkpUHQzfKidRUX3zxBY0aNaJx48asW7eO5557rsqPUVRUxKOPPgrAW2+9FbUJa9euXWRkZJCXl8f27dt54oknAMjNzSUvL4+nnnoKCE76O3fupH///tx3333s2rULgC1btgCQn5/P4sWLAXj88cdj5mnbtm00b96crKws5s6dy6effgrAGWecwaxZs0r3V/IOMGLECIYPH86oUaMq9XnEUpPaWMYSXLBeQXBN4r5kH1C9mERqnh52AV51AAANgUlEQVQ9etClSxe6du3KlVdeSZ8+far8GNdddx2ffvop3bp1484776Rr164cfvjhZdZp2rQpI0eOpGvXrnz3u9/lxBNPLF320EMPceedd9KtWzeKiorYuHEjgwcPZsCAARQWFlJQUMCkSZMAuOmmm7jrrrvo3bs3n3/+ecw8ff/73+fVV1+lsLCQxx57jM6dOwPQrVs3br75Zk455RQKCgq46aabSrcZPnw427ZtY9iwYVX58ZSy2nzBtrCw0BctWlTh7d54bgbH//t6PrrgeY7semL8DUQOEe+99x7HHHNMqrORcsXFxRQXF1O/fn2WL19O//79Wb58eY3salqeWbNm8dxzz5Xb/Tfa39zMFrt7Ybz9165PQ0SkCnz55Zf069eP4uJi3J0//elPtS44XH311cybN6+0J1My1K5PpIrU5lqTiFReTk5O6XWB2mrKlOTfJlaTrkFUO12CEBGJLa0DhIiIxJaeAUJNTCIicaVngCihO6lFRGLSGVJEqkVVDPcNcP/997N+/frS+USGAJeDk6a9mFKdA5H0k8hw34m4//776dGjBy1btgQSGwK8pqmpw3vvr+bnMIl0J7WktWfGwfq3qnafLY+DsyZUeLMZM2Zw77338vXXX9O7d2/uuece9u7dy6hRo1i6dCnuzujRo2nRogVLly5l2LBhZGdns2DBAvr27Rt3CPDly5czYsQI3J0zzzyTu+++m61btx6Qj7PPPpu1a9eye/duxowZwxVXXAHAP/7xD37+85+zZ88eWrRowfPPP8/27dtLx2oyM26//XYGDx5MXl5e6b5nzZrFvHnzmDZtGiNGjKBFixYsWbKEE044gfPOO48xY8awe/duGjRowAMPPEDnzp0pLi7mpptuYu7cuWRkZHDVVVfRsWNHpk2bxmOPPQbAM888w/Tp00uHC0mWtA4QIpJ6b7/9NrNnz+bVV18lKyuL0aNHM2vWLDp27MimTZt4660giG3dupWcnBzuvvvu0ucr7K9kCPAJEybwox/9iPvvv59x48Zx3XXX8ZOf/IShQ4dyzz33xMzLjBkzaNKkCTt37qSwsJDzzz+fr776iquvvpqXX36Z9u3bl46FdNttt9GsWTPeeust3D1qwNnfypUrmT9/PhkZGWzbto1XXnmFzMxMnn32WcaPH88jjzzClClTWLt2LcuWLSMzM5MtW7aQk5PD9ddfz+bNm2natCnTp09P2vhLkdI0QGiwPpGD+aWfDPPmzWPhwoUUFgYjP+zatYu2bdty5pln8sEHH3DDDTcwcOBA+vfvH3dfsYYAf/3113n66acBuPjiixk/fnzU7SdNmsSTTz4JwJo1a1i5ciWrV6/m9NNPp3379sC+4bbnzZvH3/72NyBojcjNzY05omyJoUOHlj4tb+vWrVxyySWsXLnygM/jxhtvLH22Q8nxLr74Yh5++GGGDx/O4sWLmTlzZtzPo7LSNEAELOpjKESkOrk7l112Gb/85S8PWPbmm2/yzDPPMHnyZJ544gmmTp1a7r4SHQI8mnnz5vGvf/2L1157jezsbIqKisodbjtaekZGRpmRGsob3vtnP/sZZ555Jj/84Q9ZsWIFAwYMiLlfgMsuu4zzzz8fgGHDhlX5w4GiUS8mEUmpM844g0cffZRNmzYBQW+nTz75hI0bN+LuDB06tPQRpACNGjVi+/btFTpGr169mD17NhBcF4hm27ZtNGnShOzsbN555x0WLlwIQJ8+fXjhhRf4+OOPgX3Dbffv37+0ucrd+fzzz8nIyCA3N5fly5ezd+/e0mPGOl7r1sGDMx944IHS9P79+zNlyhT27NlT5nht27YlLy+PCRMmcOmll1ao/AcrLQPE3g+SN7iViFTMcccdx6233soZZ5xBt27d6N+/P5999hmrV68uHeL6yiuv5I477gCCbq1XXHFFhbrHTp48mYkTJ9KrVy82bNhwwNDeAIMGDWLnzp10796d22+/vXR47xYtWjBlyhSGDBlC9+7dGT58OBA8r/qzzz6ja9euFBQUlDZnTZw4kQEDBtCvXz/atGkTM09jx47lpptuOmA48x/84Ae0bNmSbt260b179zIXoi+++GI6dOjAUUcdlVC5Kys9h/t+/i98/cHzHD96KnXr1U9CzkRqpnQd7nvHjh00aNAAM+Mvf/kLs2fPLn0AUG1y1VVXcfLJJzNy5MiEt9Fw3xV0fP8R0H9EqrMhItVk4cKF3Hjjjezdu5fc3Nxaee9EQUEBubm5TJ48udqOmZYBQkTSy2mnnVZ6k15tlYr8p+U1CJF0VpublaViKvu3VoAQSSP169dn8+bNChJpwN3ZvHkz9esf/HVWNTGJpJE2bdqwZs0aNm7cmOqsSDWoX79+uT2p4lGAEEkjderUoUOHDqnOhtQS1d7EZGb1zWyBmS0zs3fM7Bdhegcze93MlpvZI2ZWN96+REQkeVJxDeIroK+7dwcKgAFmdhIwEZjk7p2Bz4HLU5A3EREJVXuA8MCX4Wyd8OVAX+DxMH0GcG51501ERPZJyTUIM8sEFgOdgHuBlcBWdy8ZWWsN0DrGtqOB0eHsl2Z2sI+SygM2HeS2tZXKnB5U5vRQmTK3T2SllAQId98DFJhZDjAbiHbvf9R+eO4+FSh/SMcEmNmiRG41P5SozOlBZU4P1VHmlN4H4e5bgZeAk4AcMysJWG2AtanKl4iIpKYXU7Ow5oCZZQNnAO8BLwIXhKuNBOZUd95ERGSfVDQxtQJmhNchMoBH3f3vZvYuMMvMfgW8AdyX5HxUupmqFlKZ04PKnB6SXuZaPdy3iIgkj8ZiEhGRqBQgREQkqrQMEGY2wMw+MLMVZjYu1fmpDDO738w2mNnbEWlNzGxuOGzJXDPLDdPNzCaH5X7TzHpEbDMyXH+5mSX+uKpqZmZtzexFM3svHKrlhjD9UC5zhYanMbN64fyKcHl+xL5+GqZ/YGZnpqZEiTOzTDN7w8z+Hs4f0mU2s1Vm9paZLTWzRWFa6r7b7p5WLyCT4Ma8I4G6wDKgS6rzVYnynAL0AN6OSPstMC6cHgdMDKcHAs8ARtC1+PUwvQnwUfieG07nprpsMcrbCugRTjcCPgS6HOJlNqBhOF0HeD0sy6PAhWH6H4Grw+kfAn8Mpy8EHgmnu4Tf93pAh/D/IDPV5YtT9h8BDwN/D+cP6TIDq4C8/dJS9t1OxxpEL2CFu3/k7l8Ds4AhKc7TQXP3fwFb9kseQjBcCZQdtmQI8GcPvEZw70kr4ExgrrtvcffPgbnAgOTnvuLcfZ27LwmntxN0kW7NoV1m94oNTxP5WTwO9DMzC9NnuftX7v4fYAXB/0ONZGZtgEHAtHDeOMTLHEPKvtvpGCBaA6sj5mMO61GLtXD3dRCcUIHmYXqsstfKzyRsRjie4Bf1IV3msKllKbCB4B++vOFpSssWLt8GNKWWlRn4A3AzsDecb8qhX2YHnjezxRYMKwQp/G6n4/MgLEpauvT1jVX2WveZmFlD4AngRnf/IvixGH3VKGm1rsxeseFpan2ZzWwwsMHdF5vZaSXJUVY9ZMoc6uPua82sOTDXzN4vZ92klzkdaxBrgLYR84fisB6fhVVNwvcNYXqssteqz8TM6hAEh4fc/a9h8iFd5hKe2PA0pWULlx9O0AxZm8rcBzjHzFYRNAP3JahRHMplxt3Xhu8bCH4I9CKF3+10DBALgc5hb4i6BBe0nkxxnqrakwTDlUDZYUueBC4Jez+cBGwLq6zPAf3NLDfsIdE/TKtxwnbl+4D33P2/IxYdymWu6PA0kZ/FBcALHly9fBK4MOzx0wHoDCyonlJUjLv/1N3buHs+wf/oC+4+nEO4zGZ2mJk1Kpkm+E6+TSq/26m+ap+KF8HV/w8J2nF/lur8VLIsM4F1wDcEvxwuJ2h7nQ8sD9+bhOsa+4ZXfwsojNjPZQQX8FYAo1JdrnLKW0RQXX4TWBq+Bh7iZe5GMPzMm+EJ45Yw/UiCk90K4DGgXpheP5xfES4/MmJfPws/iw+As1JdtgTLfxr7ejEdsmUOy7YsfL1Tcm5K5XdbQ22IiEhU6djEJCIiCVCAEBGRqBQgREQkKgUIERGJSgFCRESiUoAQKYeZ7QlH1ix5Vdnov2aWbxGj8IrUNOk41IZIRexy94JUZ0IkFVSDEDkI4bj9Ey14TsMCM+sUprc3s/nh+PzzzaxdmN7CzGZb8EyHZWbWO9xVppn9rwXPeXg+vFNapEZQgBApX/Z+TUzDIpZ94e69gHsIxgkinP6zu3cDHgImh+mTgX+6e3eC53e8E6Z3Bu5192OBrcD5SS6PSMJ0J7VIOczsS3dvGCV9FdDX3T8KBw9c7+5NzWwT0MrdvwnT17l7npltBNq4+1cR+8gnGLe/czg/Fqjj7r9KfslE4lMNQuTgeYzpWOtE81XE9B50XVBqEAUIkYM3LOL93+H0qwSjjwIMB14Jp+cDV0Ppw38aV1cmRQ6Wfq2IlC87fJJbiWfdvaSraz0ze53gh9ZFYdr1wP1mdhOwERgVpt8ATDWzywlqClcTjMIrUmPpGoTIQQivQRS6+6ZU50UkWdTEJCIiUakGISIiUakGISIiUSlAiIhIVAoQIiISlQKEiIhEpQAhIiJR/T/wXfWDe42sGAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot of training accuracy and testing accuarcy\n",
    "graph.plot(epoch_list,training_accuracy,label='Training accuracy')\n",
    "graph.plot(epoch_list,testing_accuracy,label='Testing accuracy')\n",
    "graph.xlabel('Epoch')\n",
    "graph.ylabel('Accuracy')\n",
    "graph.title('Accuracy v/s Epoch')\n",
    "graph.legend()\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model state for future use\n",
    "torch.save(model.state_dict(),\"./Iris.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IrisNet(\n",
       "  (first_layer): Linear(in_features=4, out_features=100, bias=True)\n",
       "  (first_layer_activation): ReLU()\n",
       "  (second_layer): Linear(in_features=100, out_features=40, bias=True)\n",
       "  (second_layer_activation): ReLU()\n",
       "  (third_layer): Linear(in_features=40, out_features=3, bias=True)\n",
       "  (third_layer_activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reusing the saved model\n",
    "model=IrisNet(4,100,40,3)\n",
    "model.load_state_dict(torch.load(\"./Iris.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class predicted is:2\n"
     ]
    }
   ],
   "source": [
    "#Testing the model for sample data point\n",
    "test_sample=[[5.8,2.7,5.1,1.9]]\n",
    "#Expected class for above test sample is 2\n",
    "output=model(Variable(torch.Tensor(test_sample)))\n",
    "_,predicted_class=torch.max(output.data,1)\n",
    "print(\"The class predicted is:%d\"%(predicted_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
